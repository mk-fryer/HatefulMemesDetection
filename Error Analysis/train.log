2023-04-09T07:12:07 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T07:12:07 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/defaults.yaml', 'model=concat_vl', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T07:12:07 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T07:12:07 | INFO | mmf_cli.run : Using seed 7938905
2023-04-09T07:12:07 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T07:28:50 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T07:28:50 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/defaults.yaml', 'model=concat_vl', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T07:28:50 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T07:28:50 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-09T07:28:50 | INFO | mmf_cli.run : Using seed 50398023
2023-04-09T07:28:50 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T07:28:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/datasets/processors/processors.py:449: UserWarning: No model file present at /root/.cache/torch/mmf/wiki.en.bin.
  warnings.warn(f"No model file present at {model_file}.")

2023-04-09T07:28:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/datasets/processors/processors.py:449: UserWarning: No model file present at /root/.cache/torch/mmf/wiki.en.bin.
  warnings.warn(f"No model file present at {model_file}.")

2023-04-09T07:28:51 | INFO | mmf.datasets.processors.processors : Downloading FastText bin
2023-04-09T07:29:50 | INFO | mmf.datasets.processors.processors : fastText bin downloaded at /root/.cache/torch/mmf/wiki.en.bin.
2023-04-09T07:29:50 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T07:29:50 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:29:50 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T07:29:50 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:29:50 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T07:29:50 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:29:50 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T07:29:50 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpt0prarxf
2023-04-09T07:29:50 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpt0prarxf/_remote_module_non_scriptable.py
2023-04-09T07:29:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:29:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:29:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:29:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:30:03 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T07:30:03 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T07:30:03 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T07:30:03 | INFO | mmf.trainers.mmf_trainer : LanguageAndVisionConcat(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (language_module): ProjectionEmbedding(
    (layers): Linear(in_features=300, out_features=300, bias=True)
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (fusion): Linear(in_features=2348, out_features=512, bias=True)
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T07:30:03 | INFO | mmf.utils.general : Total Parameters: 59437822. Trained Parameters: 59437822
2023-04-09T07:30:03 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T07:30:03 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:30:49 | INFO | mmf.datasets.processors.processors : Finished loading fasttext model
2023-04-09T07:31:53 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T07:31:53 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/defaults.yaml', 'model=concat_vl', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T07:31:53 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T07:31:53 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-09T07:31:53 | INFO | mmf_cli.run : Using seed 53193246
2023-04-09T07:31:53 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T07:31:53 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T07:31:53 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:31:53 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T07:31:53 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:31:53 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T07:31:53 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:31:53 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T07:31:53 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpyjqy0nnn
2023-04-09T07:31:53 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpyjqy0nnn/_remote_module_non_scriptable.py
2023-04-09T07:31:53 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:31:53 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:31:53 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:31:53 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:32:03 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T07:32:03 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T07:32:03 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T07:32:03 | INFO | mmf.trainers.mmf_trainer : LanguageAndVisionConcat(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (language_module): ProjectionEmbedding(
    (layers): Linear(in_features=300, out_features=300, bias=True)
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (fusion): Linear(in_features=2348, out_features=512, bias=True)
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T07:32:03 | INFO | mmf.utils.general : Total Parameters: 59437822. Trained Parameters: 59437822
2023-04-09T07:32:03 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T07:32:03 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:32:46 | INFO | mmf.datasets.processors.processors : Finished loading fasttext model
2023-04-09T07:35:38 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T07:35:38 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/defaults.yaml', 'model=concat_vl', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'evaluation.predict=true'])
2023-04-09T07:35:38 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T07:35:38 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-09T07:35:38 | INFO | mmf_cli.run : Using seed 38487716
2023-04-09T07:35:38 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T07:36:51 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T07:36:51 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/defaults.yaml', 'model=concat_vl', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'evaluation.predict=true'])
2023-04-09T07:36:51 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T07:36:51 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-09T07:36:51 | INFO | mmf_cli.run : Using seed 51442157
2023-04-09T07:36:51 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T07:36:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T07:36:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T07:36:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:36:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:36:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:36:51 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T07:36:51 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmppup92s93
2023-04-09T07:36:51 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmppup92s93/_remote_module_non_scriptable.py
2023-04-09T07:36:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:36:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:36:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:36:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:37:01 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T07:37:01 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T07:37:01 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-09T07:37:01 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-09T07:37:01 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:37:01 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:37:01 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:37:01 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:39:25 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T07:39:25 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/defaults.yaml', 'model=concat_vl', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'evaluation.predict=true'])
2023-04-09T07:39:25 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T07:39:25 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-09T07:39:25 | INFO | mmf_cli.run : Using seed 25076239
2023-04-09T07:39:25 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T07:39:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T07:39:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T07:39:25 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:39:25 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:39:25 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T07:39:25 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T07:39:25 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp4jzvldhb
2023-04-09T07:39:25 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp4jzvldhb/_remote_module_non_scriptable.py
2023-04-09T07:39:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:39:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T07:39:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:39:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T07:39:34 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T07:39:34 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T07:39:34 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-09T07:39:34 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-09T07:39:34 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:39:34 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:39:34 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T07:39:34 | INFO | mmf.datasets.processors.processors : Loading fasttext model now from /root/.cache/torch/mmf/wiki.en.bin
2023-04-09T14:28:43 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T14:28:43 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_vl', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T14:28:43 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T14:28:43 | INFO | mmf_cli.run : Using seed 43582458
2023-04-09T14:28:43 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T14:28:45 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T14:28:45 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T14:28:45 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T14:28:45 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T14:28:45 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T14:28:45 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T14:28:45 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T14:28:45 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp2h8j_eem
2023-04-09T14:28:45 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp2h8j_eem/_remote_module_non_scriptable.py
2023-04-09T14:28:45 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T14:28:45 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T14:28:45 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T14:28:45 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T14:28:49 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T14:28:49 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T14:28:49 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T14:28:49 | INFO | mmf.trainers.mmf_trainer : LanguageAndVisionConcat(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=512, out_features=2, bias=True)
    )
  )
  (language_module): ProjectionEmbedding(
    (layers): Linear(in_features=300, out_features=300, bias=True)
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (fusion): Linear(in_features=2348, out_features=512, bias=True)
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T14:28:49 | INFO | mmf.utils.general : Total Parameters: 59437822. Trained Parameters: 59437822
2023-04-09T14:28:49 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T14:41:18 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T14:41:18 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T14:41:18 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T14:41:18 | INFO | mmf_cli.run : Using seed 18483525
2023-04-09T14:41:18 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T14:41:19 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T14:41:19 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T14:41:19 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T14:41:19 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T14:41:19 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T14:41:19 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T14:41:19 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T14:41:19 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T14:41:19 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:02:42 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T15:02:42 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T15:02:42 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T15:02:42 | INFO | mmf_cli.run : Using seed 42751311
2023-04-09T15:02:42 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T15:02:44 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:02:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:02:44 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:02:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:02:44 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:02:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:02:44 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T15:02:44 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:02:44 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:09:53 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T15:09:53 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T15:09:53 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T15:09:53 | INFO | mmf_cli.run : Using seed 53005668
2023-04-09T15:09:53 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T15:09:56 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:09:56 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:09:56 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:09:56 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:09:56 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:09:56 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:09:56 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T15:09:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:09:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:09:56 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpqqsz8v3o
2023-04-09T15:09:56 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpqqsz8v3o/_remote_module_non_scriptable.py
2023-04-09T15:11:24 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T15:11:24 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T15:11:24 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T15:11:24 | INFO | mmf_cli.run : Using seed 24745280
2023-04-09T15:11:24 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T15:11:26 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:11:26 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:11:26 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:11:26 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:11:26 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:11:26 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:11:26 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T15:11:26 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:11:26 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:11:26 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmphi9iben1
2023-04-09T15:11:26 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmphi9iben1/_remote_module_non_scriptable.py
2023-04-09T15:38:48 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T15:38:49 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T15:38:49 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T15:38:49 | INFO | mmf_cli.run : Using seed 48618389
2023-04-09T15:38:49 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T15:38:51 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:38:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:38:51 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:38:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:38:51 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:38:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:38:51 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T15:38:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:38:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/trainers/mmf_trainer.py:90: UserWarning: Model concat_bert_ex's config not present. Continuing with empty config
  warnings.warn(

2023-04-09T15:38:51 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp8_thri05
2023-04-09T15:38:51 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp8_thri05/_remote_module_non_scriptable.py
2023-04-09T15:45:02 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T15:45:02 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T15:45:02 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T15:45:02 | INFO | mmf_cli.run : Using seed 2978861
2023-04-09T15:45:02 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T15:45:04 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:45:04 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:45:04 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:45:04 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:45:04 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T15:45:04 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:45:04 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T15:45:04 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp6589r4rc
2023-04-09T15:45:04 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp6589r4rc/_remote_module_non_scriptable.py
2023-04-09T15:45:04 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T15:45:04 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T15:45:04 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T15:45:04 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T15:45:19 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T15:45:19 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T15:45:19 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T15:45:19 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T15:45:19 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T15:45:19 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T15:52:08 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T15:52:08 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train', 'dataset=hateful_memes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T15:52:08 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T15:52:08 | INFO | mmf_cli.run : Using seed 8600542
2023-04-09T15:52:08 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T15:52:10 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T15:52:10 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T15:52:10 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:52:10 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:52:10 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:52:10 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T15:52:10 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp92jzkon4
2023-04-09T15:52:10 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp92jzkon4/_remote_module_non_scriptable.py
2023-04-09T15:52:10 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T15:52:10 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T15:52:10 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T15:52:10 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T15:52:16 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T15:52:16 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T15:52:17 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T15:52:17 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T15:52:17 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T15:52:17 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T15:57:34 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T15:57:34 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train', 'dataset=hateful_memes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T15:57:34 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T15:57:34 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-09T15:57:34 | INFO | mmf_cli.run : Using seed 34052632
2023-04-09T15:57:34 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T15:57:36 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T15:57:36 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-09T15:57:36 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:57:36 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:57:36 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T15:57:36 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T15:57:36 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpu81ozi3p
2023-04-09T15:57:36 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpu81ozi3p/_remote_module_non_scriptable.py
2023-04-09T15:57:36 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T15:57:36 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T15:57:36 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T15:57:36 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T15:57:59 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T15:57:59 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T15:57:59 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T15:57:59 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T15:57:59 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T15:57:59 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T16:05:15 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:05:16 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train', 'dataset=hateful_memes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T16:05:16 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:05:16 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-09T16:05:16 | INFO | mmf_cli.run : Using seed 15383206
2023-04-09T16:05:16 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:05:20 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:05:20 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:05:20 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:05:20 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:05:20 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp1zxgjftv
2023-04-09T16:05:20 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp1zxgjftv/_remote_module_non_scriptable.py
2023-04-09T16:05:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:05:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:05:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:05:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:05:37 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:05:37 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:05:38 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T16:05:38 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T16:05:38 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T16:05:38 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T16:10:48 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:10:48 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train', 'dataset=hateful_memes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T16:10:48 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:10:48 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2023-04-09T16:10:48 | INFO | mmf_cli.run : Using seed 47715228
2023-04-09T16:10:48 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:10:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:10:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:10:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:10:51 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:10:51 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpeg9i46lb
2023-04-09T16:10:51 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpeg9i46lb/_remote_module_non_scriptable.py
2023-04-09T16:10:52 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:10:52 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:10:52 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:10:52 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:11:13 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:11:13 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:11:14 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T16:11:14 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T16:11:14 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T16:11:14 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T16:11:32 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:11:32 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/visual_bert_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-09T16:11:32 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:11:32 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2023-04-09T16:11:32 | INFO | mmf_cli.run : Using seed 32432620
2023-04-09T16:11:32 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:11:34 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:11:34 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:11:34 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:11:34 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:11:34 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpnoa9jjhq
2023-04-09T16:11:34 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpnoa9jjhq/_remote_module_non_scriptable.py
2023-04-09T16:11:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:11:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:11:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:11:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:11:40 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:11:40 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:13:58 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:13:58 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T16:13:58 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:13:58 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla V100-SXM2-16GB
2023-04-09T16:13:58 | INFO | mmf_cli.run : Using seed 58128817
2023-04-09T16:13:58 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:13:59 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:13:59 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:13:59 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:13:59 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:13:59 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:13:59 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:13:59 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:13:59 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp73xet_vo
2023-04-09T16:13:59 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp73xet_vo/_remote_module_non_scriptable.py
2023-04-09T16:13:59 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:13:59 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:13:59 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:13:59 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:14:06 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:14:06 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:14:06 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T16:14:06 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T16:14:06 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T16:14:06 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T16:20:25 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:20:25 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T16:20:25 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:20:25 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-09T16:20:25 | INFO | mmf_cli.run : Using seed 25014511
2023-04-09T16:20:25 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:20:27 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:20:27 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:20:27 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:20:27 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:20:27 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:20:27 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:20:27 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:20:27 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp7z6521zn
2023-04-09T16:20:27 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp7z6521zn/_remote_module_non_scriptable.py
2023-04-09T16:20:27 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:20:27 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:20:27 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:20:27 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:20:48 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:20:48 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:20:48 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T16:20:48 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T16:20:49 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T16:20:49 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T16:23:23 | INFO | mmf.trainers.callbacks.logistics : progress: 100/22000, train/hateful_memes/cross_entropy: 0.8095, train/hateful_memes/cross_entropy/avg: 0.8095, train/total_loss: 0.8095, train/total_loss/avg: 0.8095, max mem: 19030.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 0.65, time: 02m 34s 093ms, time_since_start: 02m 34s 208ms, eta: 09h 26m 56s 505ms
2023-04-09T16:25:39 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:25:39 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T16:25:39 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:25:39 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-09T16:25:39 | INFO | mmf_cli.run : Using seed 39383701
2023-04-09T16:25:39 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:25:40 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:25:40 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:25:40 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:25:40 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:25:40 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:25:40 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:25:40 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:25:40 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpger5bz1z
2023-04-09T16:25:40 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpger5bz1z/_remote_module_non_scriptable.py
2023-04-09T16:25:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:25:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:25:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:25:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:25:47 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:25:47 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:25:47 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T16:25:47 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T16:25:47 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T16:25:47 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T16:28:17 | INFO | mmf.trainers.callbacks.logistics : progress: 100/500, train/hateful_memes/cross_entropy: 0.6222, train/hateful_memes/cross_entropy/avg: 0.6222, train/total_loss: 0.6222, train/total_loss/avg: 0.6222, max mem: 19030.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 500, lr: 0., ups: 0.67, time: 02m 29s 798ms, time_since_start: 02m 29s 860ms, eta: 10m 03s 987ms
2023-04-09T16:30:45 | INFO | mmf.trainers.callbacks.logistics : progress: 200/500, train/hateful_memes/cross_entropy: 0.6222, train/hateful_memes/cross_entropy/avg: 0.6664, train/total_loss: 0.6222, train/total_loss/avg: 0.6664, max mem: 19030.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 500, lr: 0.00001, ups: 0.68, time: 02m 27s 808ms, time_since_start: 04m 57s 669ms, eta: 07m 26s 973ms
2023-04-09T16:33:12 | INFO | mmf.trainers.callbacks.logistics : progress: 300/500, train/hateful_memes/cross_entropy: 0.7106, train/hateful_memes/cross_entropy/avg: 0.6890, train/total_loss: 0.7106, train/total_loss/avg: 0.6890, max mem: 19030.0, experiment: run, epoch: 3, num_updates: 300, iterations: 300, max_updates: 500, lr: 0.00001, ups: 0.68, time: 02m 26s 961ms, time_since_start: 07m 24s 631ms, eta: 04m 56s 275ms
2023-04-09T16:35:38 | INFO | mmf.trainers.callbacks.logistics : progress: 400/500, train/hateful_memes/cross_entropy: 0.6709, train/hateful_memes/cross_entropy/avg: 0.6845, train/total_loss: 0.6709, train/total_loss/avg: 0.6845, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 400, iterations: 400, max_updates: 500, lr: 0.00001, ups: 0.68, time: 02m 26s 317ms, time_since_start: 09m 50s 948ms, eta: 02m 27s 487ms
2023-04-09T16:38:05 | INFO | mmf.trainers.callbacks.logistics : progress: 500/500, train/hateful_memes/cross_entropy: 0.6709, train/hateful_memes/cross_entropy/avg: 0.6650, train/total_loss: 0.6709, train/total_loss/avg: 0.6650, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 500, iterations: 500, max_updates: 500, lr: 0.00001, ups: 0.68, time: 02m 26s 932ms, time_since_start: 12m 17s 881ms, eta: 0ms
2023-04-09T16:38:05 | INFO | mmf.trainers.core.training_loop : Stepping into final validation check
2023-04-09T16:38:05 | INFO | mmf.utils.checkpoint : Restoring checkpoint
2023-04-09T16:40:40 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:40:40 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-09T16:40:40 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:40:40 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-09T16:40:40 | INFO | mmf_cli.run : Using seed 40976226
2023-04-09T16:40:40 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:40:41 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:40:41 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:40:41 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:40:41 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:40:41 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpn6t1sma0
2023-04-09T16:40:41 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpn6t1sma0/_remote_module_non_scriptable.py
2023-04-09T16:40:41 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:40:41 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:40:41 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:40:41 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:40:48 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:40:48 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:40:49 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-09T16:40:49 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-09T16:40:49 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-09T16:40:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-09T16:40:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-09T16:40:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-09T16:40:50 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-09T16:40:50 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-09T16:40:50 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-09T16:40:50 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-09T16:40:50 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-09T16:40:50 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-09T16:40:50 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-09T16:40:56 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_40976226/reports/hateful_memes_run_test_2023-04-09T16:40:56.csv
2023-04-09T16:40:56 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 16
2023-04-09T16:40:56 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-09T16:41:19 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:41:19 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-09T16:41:19 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:41:19 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-09T16:41:19 | INFO | mmf_cli.run : Using seed 19243558
2023-04-09T16:41:19 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:41:20 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:41:20 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:41:20 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:41:20 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:41:20 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:41:20 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:41:20 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:41:20 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpnq4gfzln
2023-04-09T16:41:20 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpnq4gfzln/_remote_module_non_scriptable.py
2023-04-09T16:41:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:41:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:41:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:41:20 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:41:27 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:41:27 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:41:27 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-09T16:41:27 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-09T16:41:27 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-09T16:41:27 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-09T16:43:56 | INFO | mmf.trainers.callbacks.logistics : progress: 100/500, train/hateful_memes/cross_entropy: 0.9874, train/hateful_memes/cross_entropy/avg: 0.9874, train/total_loss: 0.9874, train/total_loss/avg: 0.9874, max mem: 19030.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 500, lr: 0., ups: 0.68, time: 02m 28s 498ms, time_since_start: 02m 28s 611ms, eta: 09m 58s 747ms
2023-04-09T16:46:22 | INFO | mmf.trainers.callbacks.logistics : progress: 200/500, train/hateful_memes/cross_entropy: 0.7555, train/hateful_memes/cross_entropy/avg: 0.8714, train/total_loss: 0.7555, train/total_loss/avg: 0.8714, max mem: 19030.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 500, lr: 0.00001, ups: 0.68, time: 02m 26s 491ms, time_since_start: 04m 55s 102ms, eta: 07m 22s 989ms
2023-04-09T16:48:47 | INFO | mmf.trainers.callbacks.logistics : progress: 300/500, train/hateful_memes/cross_entropy: 0.7782, train/hateful_memes/cross_entropy/avg: 0.8404, train/total_loss: 0.7782, train/total_loss/avg: 0.8404, max mem: 19030.0, experiment: run, epoch: 3, num_updates: 300, iterations: 300, max_updates: 500, lr: 0.00001, ups: 0.69, time: 02m 25s 252ms, time_since_start: 07m 20s 355ms, eta: 04m 52s 829ms
2023-04-09T16:51:13 | INFO | mmf.trainers.callbacks.logistics : progress: 400/500, train/hateful_memes/cross_entropy: 0.7555, train/hateful_memes/cross_entropy/avg: 0.7870, train/total_loss: 0.7555, train/total_loss/avg: 0.7870, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 400, iterations: 400, max_updates: 500, lr: 0.00001, ups: 0.69, time: 02m 25s 904ms, time_since_start: 09m 46s 260ms, eta: 02m 27s 071ms
2023-04-09T16:53:39 | INFO | mmf.trainers.callbacks.logistics : progress: 500/500, train/hateful_memes/cross_entropy: 0.7555, train/hateful_memes/cross_entropy/avg: 0.7576, train/total_loss: 0.7555, train/total_loss/avg: 0.7576, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 500, iterations: 500, max_updates: 500, lr: 0.00001, ups: 0.69, time: 02m 25s 794ms, time_since_start: 12m 12s 054ms, eta: 0ms
2023-04-09T16:53:39 | INFO | mmf.trainers.core.training_loop : Stepping into final validation check
2023-04-09T16:53:39 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-09T16:53:39 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:53:47 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-09T16:53:47 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-09T16:53:47 | INFO | mmf.trainers.callbacks.logistics : progress: 500/500, val/hateful_memes/cross_entropy: 0.7364, val/total_loss: 0.7364, val/hateful_memes/accuracy: 0.5760, val/hateful_memes/binary_f1: 0.4778, val/hateful_memes/roc_auc: 0.6007, num_updates: 500, epoch: 4, iterations: 500, max_updates: 500, val_time: 12m 20s 185ms, best_update: 0, best_iteration: 0, best_val/hateful_memes/roc_auc: -inf
2023-04-09T16:53:47 | INFO | mmf.utils.checkpoint : Restoring checkpoint
2023-04-09T16:53:49 | INFO | mmf.trainers.mmf_trainer : Starting inference on val set
2023-04-09T16:53:49 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-09T16:53:49 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-09T16:53:57 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-09T16:53:57 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-09T16:53:57 | INFO | mmf.trainers.callbacks.logistics : progress: 500/500, val/hateful_memes/cross_entropy: 0.7364, val/total_loss: 0.7364, val/hateful_memes/accuracy: 0.5760, val/hateful_memes/binary_f1: 0.4778, val/hateful_memes/roc_auc: 0.6007
2023-04-09T16:53:57 | INFO | mmf.trainers.callbacks.logistics : Finished run in 12m 30s 415ms
2023-04-09T16:55:39 | INFO | mmf : Logging to: ./save/train.log
2023-04-09T16:55:39 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-09T16:55:39 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-09T16:55:39 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-09T16:55:39 | INFO | mmf_cli.run : Using seed 39381729
2023-04-09T16:55:39 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-09T16:55:40 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:55:40 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:55:40 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-09T16:55:40 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-09T16:55:40 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmps_3gt5da
2023-04-09T16:55:40 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmps_3gt5da/_remote_module_non_scriptable.py
2023-04-09T16:55:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:55:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-09T16:55:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:55:40 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-09T16:55:47 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-09T16:55:47 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-09T16:55:47 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-09T16:55:48 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-09T16:55:48 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-09T16:55:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-09T16:55:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-09T16:55:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-09T16:55:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-09T16:55:48 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-09T16:55:48 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-09T16:55:48 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-09T16:55:48 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-09T16:55:48 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-09T16:55:48 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-09T16:55:55 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_39381729/reports/hateful_memes_run_test_2023-04-09T16:55:55.csv
2023-04-09T16:55:55 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 16
2023-04-09T16:55:55 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T21:00:39 | INFO | mmf : Logging to: ./save/train.log
2023-04-13T21:00:39 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-13T21:00:39 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-13T21:00:39 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-13T21:00:39 | INFO | mmf_cli.run : Using seed 39238067
2023-04-13T21:00:39 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-13T21:00:42 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-13T21:00:42 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:00:42 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-13T21:00:42 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:00:42 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-13T21:00:42 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:00:42 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-13T21:00:42 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp8hb2dm7f
2023-04-13T21:00:42 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp8hb2dm7f/_remote_module_non_scriptable.py
2023-04-13T21:00:42 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:00:42 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:00:42 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:00:42 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:01:05 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-13T21:01:05 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-13T21:01:05 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-13T21:01:05 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-13T21:01:05 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-13T21:01:05 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-13T21:02:55 | INFO | mmf : Logging to: ./save/train.log
2023-04-13T21:02:55 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-13T21:02:55 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-13T21:02:55 | INFO | mmf.utils.general : CUDA Device 0 is: Tesla T4
2023-04-13T21:02:55 | INFO | mmf_cli.run : Using seed 55155266
2023-04-13T21:02:55 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-13T21:02:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-13T21:02:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(

2023-04-13T21:02:56 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:02:56 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:02:56 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:02:56 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-13T21:02:56 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpshmqwh5v
2023-04-13T21:02:56 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpshmqwh5v/_remote_module_non_scriptable.py
2023-04-13T21:02:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:02:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:02:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:02:56 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:07:25 | INFO | mmf : Logging to: ./save/train.log
2023-04-13T21:07:25 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-13T21:07:25 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-13T21:07:25 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-13T21:07:25 | INFO | mmf_cli.run : Using seed 25112523
2023-04-13T21:07:25 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-13T21:07:28 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:07:28 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:07:28 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:07:28 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-13T21:07:28 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpg9krjum5
2023-04-13T21:07:28 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpg9krjum5/_remote_module_non_scriptable.py
2023-04-13T21:07:28 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:07:28 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:07:28 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:07:28 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:07:46 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-13T21:07:46 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-13T21:07:46 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-13T21:07:46 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-13T21:07:46 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-13T21:07:46 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-13T21:08:47 | INFO | mmf.trainers.callbacks.logistics : progress: 100/500, train/hateful_memes/cross_entropy: 0.7573, train/hateful_memes/cross_entropy/avg: 0.7573, train/total_loss: 0.7573, train/total_loss/avg: 0.7573, max mem: 19030.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 500, lr: 0., ups: 1.67, time: 01m 519ms, time_since_start: 01m 601ms, eta: 04m 04s 015ms
2023-04-13T21:10:46 | INFO | mmf : Logging to: ./save/train.log
2023-04-13T21:10:46 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-13T21:10:46 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-13T21:10:46 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-13T21:10:46 | INFO | mmf_cli.run : Using seed 46350354
2023-04-13T21:10:46 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-13T21:10:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:10:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:10:48 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-13T21:10:48 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-13T21:10:48 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmprbb_f_sv
2023-04-13T21:10:48 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmprbb_f_sv/_remote_module_non_scriptable.py
2023-04-13T21:10:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:10:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-13T21:10:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:10:48 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-13T21:10:55 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-13T21:10:55 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-13T21:10:55 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-13T21:10:55 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-13T21:10:55 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-13T21:10:55 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-13T21:11:50 | INFO | mmf.trainers.callbacks.logistics : progress: 100/22000, train/hateful_memes/cross_entropy: 0.7420, train/hateful_memes/cross_entropy/avg: 0.7420, train/total_loss: 0.7420, train/total_loss/avg: 0.7420, max mem: 19030.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.82, time: 55s 465ms, time_since_start: 55s 510ms, eta: 03h 24m 04s 158ms
2023-04-13T21:12:43 | INFO | mmf.trainers.callbacks.logistics : progress: 200/22000, train/hateful_memes/cross_entropy: 0.6722, train/hateful_memes/cross_entropy/avg: 0.7071, train/total_loss: 0.6722, train/total_loss/avg: 0.7071, max mem: 19030.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 352ms, time_since_start: 01m 47s 863ms, eta: 03h 11m 44s 127ms
2023-04-13T21:13:35 | INFO | mmf.trainers.callbacks.logistics : progress: 300/22000, train/hateful_memes/cross_entropy: 0.6722, train/hateful_memes/cross_entropy/avg: 0.6942, train/total_loss: 0.6722, train/total_loss/avg: 0.6942, max mem: 19030.0, experiment: run, epoch: 3, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 364ms, time_since_start: 02m 40s 228ms, eta: 03h 10m 54s 083ms
2023-04-13T21:14:27 | INFO | mmf.trainers.callbacks.logistics : progress: 400/22000, train/hateful_memes/cross_entropy: 0.6684, train/hateful_memes/cross_entropy/avg: 0.6684, train/total_loss: 0.6684, train/total_loss/avg: 0.6684, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 312ms, time_since_start: 03m 32s 541ms, eta: 03h 09m 50s 005ms
2023-04-13T21:15:19 | INFO | mmf.trainers.callbacks.logistics : progress: 500/22000, train/hateful_memes/cross_entropy: 0.6684, train/hateful_memes/cross_entropy/avg: 0.6492, train/total_loss: 0.6684, train/total_loss/avg: 0.6492, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 439ms, time_since_start: 04m 23s 980ms, eta: 03h 05m 47s 888ms
2023-04-13T21:16:11 | INFO | mmf.trainers.callbacks.logistics : progress: 600/22000, train/hateful_memes/cross_entropy: 0.5909, train/hateful_memes/cross_entropy/avg: 0.6271, train/total_loss: 0.5909, train/total_loss/avg: 0.6271, max mem: 19030.0, experiment: run, epoch: 5, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 343ms, time_since_start: 05m 16s 323ms, eta: 03h 08m 11s 113ms
2023-04-13T21:17:03 | INFO | mmf.trainers.callbacks.logistics : progress: 700/22000, train/hateful_memes/cross_entropy: 0.5909, train/hateful_memes/cross_entropy/avg: 0.5978, train/total_loss: 0.5909, train/total_loss/avg: 0.5978, max mem: 19030.0, experiment: run, epoch: 6, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 388ms, time_since_start: 06m 08s 712ms, eta: 03h 07m 28s 103ms
2023-04-13T21:17:56 | INFO | mmf.trainers.callbacks.logistics : progress: 800/22000, train/hateful_memes/cross_entropy: 0.5726, train/hateful_memes/cross_entropy/avg: 0.5586, train/total_loss: 0.5726, train/total_loss/avg: 0.5586, max mem: 19030.0, experiment: run, epoch: 7, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 425ms, time_since_start: 07m 01s 138ms, eta: 03h 06m 43s 148ms
2023-04-13T21:18:47 | INFO | mmf.trainers.callbacks.logistics : progress: 900/22000, train/hateful_memes/cross_entropy: 0.5726, train/hateful_memes/cross_entropy/avg: 0.5292, train/total_loss: 0.5726, train/total_loss/avg: 0.5292, max mem: 19030.0, experiment: run, epoch: 7, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 558ms, time_since_start: 07m 52s 696ms, eta: 03h 02m 45s 873ms
2023-04-13T21:19:40 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T21:19:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:19:45 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:19:50 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:19:50 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, train/hateful_memes/cross_entropy: 0.5162, train/hateful_memes/cross_entropy/avg: 0.4881, train/total_loss: 0.5162, train/total_loss/avg: 0.4881, max mem: 19030.0, experiment: run, epoch: 8, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00003, ups: 1.61, time: 01m 02s 439ms, time_since_start: 08m 55s 135ms, eta: 03h 40m 17s 110ms
2023-04-13T21:19:50 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T21:19:50 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T21:19:53 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T21:19:53 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T21:19:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:19:59 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-13T21:20:04 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:20:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:20:11 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, val/hateful_memes/cross_entropy: 1.2332, val/total_loss: 1.2332, val/hateful_memes/accuracy: 0.5760, val/hateful_memes/binary_f1: 0.4332, val/hateful_memes/roc_auc: 0.6234, num_updates: 1000, epoch: 8, iterations: 1000, max_updates: 22000, val_time: 21s 154ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.623360
2023-04-13T21:21:04 | INFO | mmf.trainers.callbacks.logistics : progress: 1100/22000, train/hateful_memes/cross_entropy: 0.5162, train/hateful_memes/cross_entropy/avg: 0.4525, train/total_loss: 0.5162, train/total_loss/avg: 0.4525, max mem: 19033.0, experiment: run, epoch: 9, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 1.89, time: 53s 215ms, time_since_start: 10m 09s 508ms, eta: 03h 06m 51s 111ms
2023-04-13T21:21:57 | INFO | mmf.trainers.callbacks.logistics : progress: 1200/22000, train/hateful_memes/cross_entropy: 0.4224, train/hateful_memes/cross_entropy/avg: 0.4176, train/total_loss: 0.4224, train/total_loss/avg: 0.4176, max mem: 19033.0, experiment: run, epoch: 10, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 475ms, time_since_start: 11m 01s 983ms, eta: 03h 03m 22s 180ms
2023-04-13T21:22:48 | INFO | mmf.trainers.callbacks.logistics : progress: 1300/22000, train/hateful_memes/cross_entropy: 0.4224, train/hateful_memes/cross_entropy/avg: 0.3876, train/total_loss: 0.4224, train/total_loss/avg: 0.3876, max mem: 19033.0, experiment: run, epoch: 10, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 483ms, time_since_start: 11m 53s 466ms, eta: 02h 59m 02s 248ms
2023-04-13T21:23:41 | INFO | mmf.trainers.callbacks.logistics : progress: 1400/22000, train/hateful_memes/cross_entropy: 0.2942, train/hateful_memes/cross_entropy/avg: 0.3625, train/total_loss: 0.2942, train/total_loss/avg: 0.3625, max mem: 19033.0, experiment: run, epoch: 11, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 475ms, time_since_start: 12m 45s 942ms, eta: 03h 01m 36s 450ms
2023-04-13T21:24:33 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/22000, train/hateful_memes/cross_entropy: 0.2942, train/hateful_memes/cross_entropy/avg: 0.3470, train/total_loss: 0.2942, train/total_loss/avg: 0.3470, max mem: 19033.0, experiment: run, epoch: 12, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 431ms, time_since_start: 13m 38s 373ms, eta: 03h 34s 356ms
2023-04-13T21:25:26 | INFO | mmf.trainers.callbacks.logistics : progress: 1600/22000, train/hateful_memes/cross_entropy: 0.2842, train/hateful_memes/cross_entropy/avg: 0.3340, train/total_loss: 0.2842, train/total_loss/avg: 0.3340, max mem: 19033.0, experiment: run, epoch: 13, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 484ms, time_since_start: 14m 30s 857ms, eta: 02h 59m 52s 406ms
2023-04-13T21:26:17 | INFO | mmf.trainers.callbacks.logistics : progress: 1700/22000, train/hateful_memes/cross_entropy: 0.2842, train/hateful_memes/cross_entropy/avg: 0.3244, train/total_loss: 0.2842, train/total_loss/avg: 0.3244, max mem: 19033.0, experiment: run, epoch: 13, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 508ms, time_since_start: 15m 22s 366ms, eta: 02h 55m 39s 954ms
2023-04-13T21:27:10 | INFO | mmf.trainers.callbacks.logistics : progress: 1800/22000, train/hateful_memes/cross_entropy: 0.1710, train/hateful_memes/cross_entropy/avg: 0.3094, train/total_loss: 0.1710, train/total_loss/avg: 0.3094, max mem: 19033.0, experiment: run, epoch: 14, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 389ms, time_since_start: 16m 14s 755ms, eta: 02h 57m 47s 369ms
2023-04-13T21:28:02 | INFO | mmf.trainers.callbacks.logistics : progress: 1900/22000, train/hateful_memes/cross_entropy: 0.1710, train/hateful_memes/cross_entropy/avg: 0.2940, train/total_loss: 0.1710, train/total_loss/avg: 0.2940, max mem: 19033.0, experiment: run, epoch: 15, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 509ms, time_since_start: 17m 07s 265ms, eta: 02h 57m 18s 878ms
2023-04-13T21:28:55 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T21:28:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:28:59 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:29:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:29:04 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, train/hateful_memes/cross_entropy: 0.1388, train/hateful_memes/cross_entropy/avg: 0.2802, train/total_loss: 0.1388, train/total_loss/avg: 0.2802, max mem: 19033.0, experiment: run, epoch: 16, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 1.61, time: 01m 02s 357ms, time_since_start: 18m 09s 623ms, eta: 03h 29m 31s 303ms
2023-04-13T21:29:04 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T21:29:04 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T21:29:07 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T21:29:07 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T21:29:07 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:29:13 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:29:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:29:18 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, val/hateful_memes/cross_entropy: 2.0833, val/total_loss: 2.0833, val/hateful_memes/accuracy: 0.5600, val/hateful_memes/binary_f1: 0.3293, val/hateful_memes/roc_auc: 0.6233, num_updates: 2000, epoch: 16, iterations: 2000, max_updates: 22000, val_time: 13s 556ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.623360
2023-04-13T21:30:10 | INFO | mmf.trainers.callbacks.logistics : progress: 2100/22000, train/hateful_memes/cross_entropy: 0.1299, train/hateful_memes/cross_entropy/avg: 0.2698, train/total_loss: 0.1299, train/total_loss/avg: 0.2698, max mem: 19033.0, experiment: run, epoch: 16, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 172ms, time_since_start: 19m 15s 354ms, eta: 02h 54m 25s 326ms
2023-04-13T21:31:03 | INFO | mmf.trainers.callbacks.logistics : progress: 2200/22000, train/hateful_memes/cross_entropy: 0.1181, train/hateful_memes/cross_entropy/avg: 0.2596, train/total_loss: 0.1181, train/total_loss/avg: 0.2596, max mem: 19033.0, experiment: run, epoch: 17, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 412ms, time_since_start: 20m 07s 767ms, eta: 02h 54m 20s 777ms
2023-04-13T21:31:55 | INFO | mmf.trainers.callbacks.logistics : progress: 2300/22000, train/hateful_memes/cross_entropy: 0.0968, train/hateful_memes/cross_entropy/avg: 0.2519, train/total_loss: 0.0968, train/total_loss/avg: 0.2519, max mem: 19033.0, experiment: run, epoch: 18, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 507ms, time_since_start: 21m 275ms, eta: 02h 53m 46s 807ms
2023-04-13T21:32:47 | INFO | mmf.trainers.callbacks.logistics : progress: 2400/22000, train/hateful_memes/cross_entropy: 0.0820, train/hateful_memes/cross_entropy/avg: 0.2416, train/total_loss: 0.0820, train/total_loss/avg: 0.2416, max mem: 19033.0, experiment: run, epoch: 19, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 355ms, time_since_start: 21m 52s 630ms, eta: 02h 52m 23s 808ms
2023-04-13T21:33:39 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/22000, train/hateful_memes/cross_entropy: 0.0610, train/hateful_memes/cross_entropy/avg: 0.2336, train/total_loss: 0.0610, train/total_loss/avg: 0.2336, max mem: 19033.0, experiment: run, epoch: 19, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 479ms, time_since_start: 22m 44s 110ms, eta: 02h 48m 38s 874ms
2023-04-13T21:34:31 | INFO | mmf.trainers.callbacks.logistics : progress: 2600/22000, train/hateful_memes/cross_entropy: 0.0541, train/hateful_memes/cross_entropy/avg: 0.2252, train/total_loss: 0.0541, train/total_loss/avg: 0.2252, max mem: 19033.0, experiment: run, epoch: 20, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 395ms, time_since_start: 23m 36s 505ms, eta: 02h 50m 45s 984ms
2023-04-13T21:35:24 | INFO | mmf.trainers.callbacks.logistics : progress: 2700/22000, train/hateful_memes/cross_entropy: 0.0457, train/hateful_memes/cross_entropy/avg: 0.2172, train/total_loss: 0.0457, train/total_loss/avg: 0.2172, max mem: 19033.0, experiment: run, epoch: 21, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 486ms, time_since_start: 24m 28s 992ms, eta: 02h 50m 10s 856ms
2023-04-13T21:36:16 | INFO | mmf.trainers.callbacks.logistics : progress: 2800/22000, train/hateful_memes/cross_entropy: 0.0429, train/hateful_memes/cross_entropy/avg: 0.2098, train/total_loss: 0.0429, train/total_loss/avg: 0.2098, max mem: 19033.0, experiment: run, epoch: 22, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 381ms, time_since_start: 25m 21s 374ms, eta: 02h 48m 57s 801ms
2023-04-13T21:37:08 | INFO | mmf.trainers.callbacks.logistics : progress: 2900/22000, train/hateful_memes/cross_entropy: 0.0429, train/hateful_memes/cross_entropy/avg: 0.2047, train/total_loss: 0.0429, train/total_loss/avg: 0.2047, max mem: 19033.0, experiment: run, epoch: 22, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 372ms, time_since_start: 26m 12s 746ms, eta: 02h 44m 50s 719ms
2023-04-13T21:38:00 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T21:38:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:38:05 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:38:10 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:38:10 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, train/hateful_memes/cross_entropy: 0.0429, train/hateful_memes/cross_entropy/avg: 0.2070, train/total_loss: 0.0429, train/total_loss/avg: 0.2070, max mem: 19033.0, experiment: run, epoch: 23, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 1.61, time: 01m 02s 777ms, time_since_start: 27m 15s 524ms, eta: 03h 20m 23s 117ms
2023-04-13T21:38:10 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T21:38:10 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T21:38:13 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T21:38:13 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T21:38:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:38:19 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-13T21:38:24 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:38:30 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:38:30 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, val/hateful_memes/cross_entropy: 2.3293, val/total_loss: 2.3293, val/hateful_memes/accuracy: 0.5720, val/hateful_memes/binary_f1: 0.3851, val/hateful_memes/roc_auc: 0.6585, num_updates: 3000, epoch: 23, iterations: 3000, max_updates: 22000, val_time: 20s 187ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.658480
2023-04-13T21:39:24 | INFO | mmf.trainers.callbacks.logistics : progress: 3100/22000, train/hateful_memes/cross_entropy: 0.0368, train/hateful_memes/cross_entropy/avg: 0.2015, train/total_loss: 0.0368, train/total_loss/avg: 0.2015, max mem: 19033.0, experiment: run, epoch: 24, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 1.89, time: 53s 303ms, time_since_start: 28m 29s 016ms, eta: 02h 49m 14s 872ms
2023-04-13T21:40:17 | INFO | mmf.trainers.callbacks.logistics : progress: 3200/22000, train/hateful_memes/cross_entropy: 0.0429, train/hateful_memes/cross_entropy/avg: 0.1999, train/total_loss: 0.0429, train/total_loss/avg: 0.1999, max mem: 19033.0, experiment: run, epoch: 25, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 795ms, time_since_start: 29m 21s 812ms, eta: 02h 46m 45s 010ms
2023-04-13T21:41:08 | INFO | mmf.trainers.callbacks.logistics : progress: 3300/22000, train/hateful_memes/cross_entropy: 0.0457, train/hateful_memes/cross_entropy/avg: 0.1976, train/total_loss: 0.0457, train/total_loss/avg: 0.1976, max mem: 19033.0, experiment: run, epoch: 25, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 550ms, time_since_start: 30m 13s 363ms, eta: 02h 41m 57s 072ms
2023-04-13T21:42:01 | INFO | mmf.trainers.callbacks.logistics : progress: 3400/22000, train/hateful_memes/cross_entropy: 0.0457, train/hateful_memes/cross_entropy/avg: 0.1924, train/total_loss: 0.0457, train/total_loss/avg: 0.1924, max mem: 19033.0, experiment: run, epoch: 26, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 400ms, time_since_start: 31m 05s 763ms, eta: 02h 43m 44s 529ms
2023-04-13T21:42:53 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/22000, train/hateful_memes/cross_entropy: 0.0429, train/hateful_memes/cross_entropy/avg: 0.1870, train/total_loss: 0.0429, train/total_loss/avg: 0.1870, max mem: 19033.0, experiment: run, epoch: 27, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 533ms, time_since_start: 31m 58s 297ms, eta: 02h 43m 16s 533ms
2023-04-13T21:43:45 | INFO | mmf.trainers.callbacks.logistics : progress: 3600/22000, train/hateful_memes/cross_entropy: 0.0365, train/hateful_memes/cross_entropy/avg: 0.1820, train/total_loss: 0.0365, train/total_loss/avg: 0.1820, max mem: 19033.0, experiment: run, epoch: 28, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 434ms, time_since_start: 32m 50s 732ms, eta: 02h 42m 05s 085ms
2023-04-13T21:44:37 | INFO | mmf.trainers.callbacks.logistics : progress: 3700/22000, train/hateful_memes/cross_entropy: 0.0197, train/hateful_memes/cross_entropy/avg: 0.1772, train/total_loss: 0.0197, train/total_loss/avg: 0.1772, max mem: 19033.0, experiment: run, epoch: 28, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 576ms, time_since_start: 33m 42s 308ms, eta: 02h 38m 34s 020ms
2023-04-13T21:45:30 | INFO | mmf.trainers.callbacks.logistics : progress: 3800/22000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.1727, train/total_loss: 0.0179, train/total_loss/avg: 0.1727, max mem: 19033.0, experiment: run, epoch: 29, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 477ms, time_since_start: 34m 34s 786ms, eta: 02h 40m 27s 384ms
2023-04-13T21:46:22 | INFO | mmf.trainers.callbacks.logistics : progress: 3900/22000, train/hateful_memes/cross_entropy: 0.0179, train/hateful_memes/cross_entropy/avg: 0.1683, train/total_loss: 0.0179, train/total_loss/avg: 0.1683, max mem: 19033.0, experiment: run, epoch: 30, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 572ms, time_since_start: 35m 27s 359ms, eta: 02h 39m 51s 786ms
2023-04-13T21:47:15 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T21:47:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:47:19 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:47:28 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:47:28 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.1642, train/total_loss: 0.0141, train/total_loss/avg: 0.1642, max mem: 19033.0, experiment: run, epoch: 31, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 1.54, time: 01m 05s 384ms, time_since_start: 36m 32s 744ms, eta: 03h 17m 43s 451ms
2023-04-13T21:47:28 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T21:47:28 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T21:47:30 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T21:47:30 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T21:47:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:47:36 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-13T21:47:43 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:47:51 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:47:51 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, val/hateful_memes/cross_entropy: 2.0326, val/total_loss: 2.0326, val/hateful_memes/accuracy: 0.6040, val/hateful_memes/binary_f1: 0.4975, val/hateful_memes/roc_auc: 0.6679, num_updates: 4000, epoch: 31, iterations: 4000, max_updates: 22000, val_time: 23s 370ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T21:48:43 | INFO | mmf.trainers.callbacks.logistics : progress: 4100/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.1608, train/total_loss: 0.0141, train/total_loss/avg: 0.1608, max mem: 19033.0, experiment: run, epoch: 31, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 575ms, time_since_start: 37m 48s 692ms, eta: 02h 38m 06s 390ms
2023-04-13T21:49:36 | INFO | mmf.trainers.callbacks.logistics : progress: 4200/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.1600, train/total_loss: 0.0141, train/total_loss/avg: 0.1600, max mem: 19033.0, experiment: run, epoch: 32, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 548ms, time_since_start: 38m 41s 241ms, eta: 02h 37m 08s 414ms
2023-04-13T21:50:29 | INFO | mmf.trainers.callbacks.logistics : progress: 4300/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.1568, train/total_loss: 0.0141, train/total_loss/avg: 0.1568, max mem: 19033.0, experiment: run, epoch: 33, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 572ms, time_since_start: 39m 33s 814ms, eta: 02h 36m 19s 867ms
2023-04-13T21:51:21 | INFO | mmf.trainers.callbacks.logistics : progress: 4400/22000, train/hateful_memes/cross_entropy: 0.0141, train/hateful_memes/cross_entropy/avg: 0.1535, train/total_loss: 0.0141, train/total_loss/avg: 0.1535, max mem: 19033.0, experiment: run, epoch: 34, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 479ms, time_since_start: 40m 26s 293ms, eta: 02h 35m 10s 267ms
2023-04-13T21:52:13 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/22000, train/hateful_memes/cross_entropy: 0.0129, train/hateful_memes/cross_entropy/avg: 0.1503, train/total_loss: 0.0129, train/total_loss/avg: 0.1503, max mem: 19033.0, experiment: run, epoch: 34, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 522ms, time_since_start: 41m 17s 816ms, eta: 02h 31m 28s 625ms
2023-04-13T21:53:05 | INFO | mmf.trainers.callbacks.logistics : progress: 4600/22000, train/hateful_memes/cross_entropy: 0.0129, train/hateful_memes/cross_entropy/avg: 0.1477, train/total_loss: 0.0129, train/total_loss/avg: 0.1477, max mem: 19033.0, experiment: run, epoch: 35, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 514ms, time_since_start: 42m 10s 330ms, eta: 02h 33m 30s 551ms
2023-04-13T21:53:58 | INFO | mmf.trainers.callbacks.logistics : progress: 4700/22000, train/hateful_memes/cross_entropy: 0.0129, train/hateful_memes/cross_entropy/avg: 0.1446, train/total_loss: 0.0129, train/total_loss/avg: 0.1446, max mem: 19033.0, experiment: run, epoch: 36, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 454ms, time_since_start: 43m 02s 784ms, eta: 02h 32m 27s 219ms
2023-04-13T21:54:50 | INFO | mmf.trainers.callbacks.logistics : progress: 4800/22000, train/hateful_memes/cross_entropy: 0.0197, train/hateful_memes/cross_entropy/avg: 0.1423, train/total_loss: 0.0197, train/total_loss/avg: 0.1423, max mem: 19033.0, experiment: run, epoch: 37, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 468ms, time_since_start: 43m 55s 253ms, eta: 02h 31m 36s 710ms
2023-04-13T21:55:42 | INFO | mmf.trainers.callbacks.logistics : progress: 4900/22000, train/hateful_memes/cross_entropy: 0.0197, train/hateful_memes/cross_entropy/avg: 0.1398, train/total_loss: 0.0197, train/total_loss/avg: 0.1398, max mem: 19033.0, experiment: run, epoch: 37, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 621ms, time_since_start: 44m 46s 874ms, eta: 02h 28m 17s 864ms
2023-04-13T21:56:34 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T21:56:34 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:56:39 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:56:44 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:56:44 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, train/hateful_memes/cross_entropy: 0.0197, train/hateful_memes/cross_entropy/avg: 0.1375, train/total_loss: 0.0197, train/total_loss/avg: 0.1375, max mem: 19033.0, experiment: run, epoch: 38, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 1.61, time: 01m 02s 750ms, time_since_start: 45m 49s 625ms, eta: 02h 59m 13s 004ms
2023-04-13T21:56:44 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T21:56:44 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T21:56:47 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T21:56:47 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T21:56:48 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T21:56:55 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T21:57:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T21:57:00 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, val/hateful_memes/cross_entropy: 2.5811, val/total_loss: 2.5811, val/hateful_memes/accuracy: 0.5820, val/hateful_memes/binary_f1: 0.4146, val/hateful_memes/roc_auc: 0.6308, num_updates: 5000, epoch: 38, iterations: 5000, max_updates: 22000, val_time: 16s 052ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T21:57:54 | INFO | mmf.trainers.callbacks.logistics : progress: 5100/22000, train/hateful_memes/cross_entropy: 0.0129, train/hateful_memes/cross_entropy/avg: 0.1349, train/total_loss: 0.0129, train/total_loss/avg: 0.1349, max mem: 19033.0, experiment: run, epoch: 39, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 1.89, time: 53s 410ms, time_since_start: 46m 59s 089ms, eta: 02h 31m 38s 595ms
2023-04-13T21:58:46 | INFO | mmf.trainers.callbacks.logistics : progress: 5200/22000, train/hateful_memes/cross_entropy: 0.0102, train/hateful_memes/cross_entropy/avg: 0.1324, train/total_loss: 0.0102, train/total_loss/avg: 0.1324, max mem: 19033.0, experiment: run, epoch: 40, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 494ms, time_since_start: 47m 51s 584ms, eta: 02h 28m 09s 579ms
2023-04-13T21:59:38 | INFO | mmf.trainers.callbacks.logistics : progress: 5300/22000, train/hateful_memes/cross_entropy: 0.0077, train/hateful_memes/cross_entropy/avg: 0.1299, train/total_loss: 0.0077, train/total_loss/avg: 0.1299, max mem: 19033.0, experiment: run, epoch: 40, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 544ms, time_since_start: 48m 43s 128ms, eta: 02h 24m 36s 826ms
2023-04-13T22:00:30 | INFO | mmf.trainers.callbacks.logistics : progress: 5400/22000, train/hateful_memes/cross_entropy: 0.0061, train/hateful_memes/cross_entropy/avg: 0.1276, train/total_loss: 0.0061, train/total_loss/avg: 0.1276, max mem: 19033.0, experiment: run, epoch: 41, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 532ms, time_since_start: 49m 35s 661ms, eta: 02h 26m 30s 174ms
2023-04-13T22:01:23 | INFO | mmf.trainers.callbacks.logistics : progress: 5500/22000, train/hateful_memes/cross_entropy: 0.0045, train/hateful_memes/cross_entropy/avg: 0.1253, train/total_loss: 0.0045, train/total_loss/avg: 0.1253, max mem: 19033.0, experiment: run, epoch: 42, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 656ms, time_since_start: 50m 28s 318ms, eta: 02h 25m 57s 846ms
2023-04-13T22:02:16 | INFO | mmf.trainers.callbacks.logistics : progress: 5600/22000, train/hateful_memes/cross_entropy: 0.0045, train/hateful_memes/cross_entropy/avg: 0.1232, train/total_loss: 0.0045, train/total_loss/avg: 0.1232, max mem: 19033.0, experiment: run, epoch: 43, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 569ms, time_since_start: 51m 20s 887ms, eta: 02h 24m 50s 388ms
2023-04-13T22:03:07 | INFO | mmf.trainers.callbacks.logistics : progress: 5700/22000, train/hateful_memes/cross_entropy: 0.0102, train/hateful_memes/cross_entropy/avg: 0.1215, train/total_loss: 0.0102, train/total_loss/avg: 0.1215, max mem: 19033.0, experiment: run, epoch: 43, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 562ms, time_since_start: 52m 12s 450ms, eta: 02h 21m 11s 981ms
2023-04-13T22:04:00 | INFO | mmf.trainers.callbacks.logistics : progress: 5800/22000, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1199, train/total_loss: 0.0112, train/total_loss/avg: 0.1199, max mem: 19033.0, experiment: run, epoch: 44, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 600ms, time_since_start: 53m 05s 051ms, eta: 02h 23m 09s 525ms
2023-04-13T22:04:52 | INFO | mmf.trainers.callbacks.logistics : progress: 5900/22000, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1179, train/total_loss: 0.0112, train/total_loss/avg: 0.1179, max mem: 19033.0, experiment: run, epoch: 45, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 515ms, time_since_start: 53m 57s 567ms, eta: 02h 22m 02s 679ms
2023-04-13T22:05:45 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T22:05:45 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:05:50 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:05:57 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:05:57 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, train/hateful_memes/cross_entropy: 0.0129, train/hateful_memes/cross_entropy/avg: 0.1170, train/total_loss: 0.0129, train/total_loss/avg: 0.1170, max mem: 19033.0, experiment: run, epoch: 46, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 1.56, time: 01m 04s 255ms, time_since_start: 55m 01s 822ms, eta: 02h 52m 43s 065ms
2023-04-13T22:05:57 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T22:05:57 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T22:06:00 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T22:06:00 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T22:06:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:06:06 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:06:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:06:13 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, val/hateful_memes/cross_entropy: 2.8358, val/total_loss: 2.8358, val/hateful_memes/accuracy: 0.5600, val/hateful_memes/binary_f1: 0.3714, val/hateful_memes/roc_auc: 0.6409, num_updates: 6000, epoch: 46, iterations: 6000, max_updates: 22000, val_time: 16s 321ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T22:07:05 | INFO | mmf.trainers.callbacks.logistics : progress: 6100/22000, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1151, train/total_loss: 0.0112, train/total_loss/avg: 0.1151, max mem: 19033.0, experiment: run, epoch: 46, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 250ms, time_since_start: 56m 10s 396ms, eta: 02h 19m 34s 349ms
2023-04-13T22:07:58 | INFO | mmf.trainers.callbacks.logistics : progress: 6200/22000, train/hateful_memes/cross_entropy: 0.0112, train/hateful_memes/cross_entropy/avg: 0.1138, train/total_loss: 0.0112, train/total_loss/avg: 0.1138, max mem: 19033.0, experiment: run, epoch: 47, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 399ms, time_since_start: 57m 02s 796ms, eta: 02h 19m 05s 379ms
2023-04-13T22:08:50 | INFO | mmf.trainers.callbacks.logistics : progress: 6300/22000, train/hateful_memes/cross_entropy: 0.0102, train/hateful_memes/cross_entropy/avg: 0.1120, train/total_loss: 0.0102, train/total_loss/avg: 0.1120, max mem: 19033.0, experiment: run, epoch: 48, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 606ms, time_since_start: 57m 55s 402ms, eta: 02h 18m 45s 321ms
2023-04-13T22:09:43 | INFO | mmf.trainers.callbacks.logistics : progress: 6400/22000, train/hateful_memes/cross_entropy: 0.0045, train/hateful_memes/cross_entropy/avg: 0.1103, train/total_loss: 0.0045, train/total_loss/avg: 0.1103, max mem: 19033.0, experiment: run, epoch: 49, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 515ms, time_since_start: 58m 47s 918ms, eta: 02h 17m 37s 923ms
2023-04-13T22:10:34 | INFO | mmf.trainers.callbacks.logistics : progress: 6500/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1086, train/total_loss: 0.0037, train/total_loss/avg: 0.1086, max mem: 19033.0, experiment: run, epoch: 49, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 621ms, time_since_start: 59m 39s 540ms, eta: 02h 14m 25s 417ms
2023-04-13T22:11:27 | INFO | mmf.trainers.callbacks.logistics : progress: 6600/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1075, train/total_loss: 0.0037, train/total_loss/avg: 0.1075, max mem: 19033.0, experiment: run, epoch: 50, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 433ms, time_since_start: 01h 31s 974ms, eta: 02h 15m 39s 426ms
2023-04-13T22:12:19 | INFO | mmf.trainers.callbacks.logistics : progress: 6700/22000, train/hateful_memes/cross_entropy: 0.0045, train/hateful_memes/cross_entropy/avg: 0.1073, train/total_loss: 0.0045, train/total_loss/avg: 0.1073, max mem: 19033.0, experiment: run, epoch: 51, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 542ms, time_since_start: 01h 01m 24s 516ms, eta: 02h 15m 03s 256ms
2023-04-13T22:13:12 | INFO | mmf.trainers.callbacks.logistics : progress: 6800/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1058, train/total_loss: 0.0037, train/total_loss/avg: 0.1058, max mem: 19033.0, experiment: run, epoch: 52, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 494ms, time_since_start: 01h 02m 17s 010ms, eta: 02h 14m 02s 952ms
2023-04-13T22:14:03 | INFO | mmf.trainers.callbacks.logistics : progress: 6900/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1043, train/total_loss: 0.0037, train/total_loss/avg: 0.1043, max mem: 19033.0, experiment: run, epoch: 52, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 536ms, time_since_start: 01h 03m 08s 547ms, eta: 02h 10m 44s 275ms
2023-04-13T22:14:56 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T22:14:56 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:15:01 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:15:06 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:15:06 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.1028, train/total_loss: 0.0037, train/total_loss/avg: 0.1028, max mem: 19033.0, experiment: run, epoch: 53, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 1.61, time: 01m 02s 716ms, time_since_start: 01h 04m 11s 263ms, eta: 02h 38m 02s 706ms
2023-04-13T22:15:06 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T22:15:06 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T22:15:09 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T22:15:09 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T22:15:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:15:15 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:15:20 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:15:20 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, val/hateful_memes/cross_entropy: 2.5138, val/total_loss: 2.5138, val/hateful_memes/accuracy: 0.5920, val/hateful_memes/binary_f1: 0.4822, val/hateful_memes/roc_auc: 0.6381, num_updates: 7000, epoch: 53, iterations: 7000, max_updates: 22000, val_time: 13s 756ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T22:16:13 | INFO | mmf.trainers.callbacks.logistics : progress: 7100/22000, train/hateful_memes/cross_entropy: 0.0029, train/hateful_memes/cross_entropy/avg: 0.1014, train/total_loss: 0.0029, train/total_loss/avg: 0.1014, max mem: 19033.0, experiment: run, epoch: 54, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 1.89, time: 53s 151ms, time_since_start: 01h 05m 18s 172ms, eta: 02h 13m 02s 871ms
2023-04-13T22:17:05 | INFO | mmf.trainers.callbacks.logistics : progress: 7200/22000, train/hateful_memes/cross_entropy: 0.0029, train/hateful_memes/cross_entropy/avg: 0.1000, train/total_loss: 0.0029, train/total_loss/avg: 0.1000, max mem: 19033.0, experiment: run, epoch: 55, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 473ms, time_since_start: 01h 06m 10s 645ms, eta: 02h 10m 28s 144ms
2023-04-13T22:17:57 | INFO | mmf.trainers.callbacks.logistics : progress: 7300/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.0986, train/total_loss: 0.0026, train/total_loss/avg: 0.0986, max mem: 19033.0, experiment: run, epoch: 55, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 543ms, time_since_start: 01h 07m 02s 189ms, eta: 02h 07m 17s 564ms
2023-04-13T22:18:49 | INFO | mmf.trainers.callbacks.logistics : progress: 7400/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.0973, train/total_loss: 0.0026, train/total_loss/avg: 0.0973, max mem: 19033.0, experiment: run, epoch: 56, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 456ms, time_since_start: 01h 07m 54s 645ms, eta: 02h 08m 39s 854ms
2023-04-13T22:19:42 | INFO | mmf.trainers.callbacks.logistics : progress: 7500/22000, train/hateful_memes/cross_entropy: 0.0026, train/hateful_memes/cross_entropy/avg: 0.0960, train/total_loss: 0.0026, train/total_loss/avg: 0.0960, max mem: 19033.0, experiment: run, epoch: 57, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 505ms, time_since_start: 01h 08m 47s 151ms, eta: 02h 07m 54s 216ms
2023-04-13T22:20:34 | INFO | mmf.trainers.callbacks.logistics : progress: 7600/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0948, train/total_loss: 0.0025, train/total_loss/avg: 0.0948, max mem: 19033.0, experiment: run, epoch: 58, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 413ms, time_since_start: 01h 09m 39s 565ms, eta: 02h 06m 47s 966ms
2023-04-13T22:21:26 | INFO | mmf.trainers.callbacks.logistics : progress: 7700/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.0936, train/total_loss: 0.0022, train/total_loss/avg: 0.0936, max mem: 19033.0, experiment: run, epoch: 58, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 582ms, time_since_start: 01h 10m 31s 147ms, eta: 02h 03m 55s 306ms
2023-04-13T22:22:18 | INFO | mmf.trainers.callbacks.logistics : progress: 7800/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.0925, train/total_loss: 0.0022, train/total_loss/avg: 0.0925, max mem: 19033.0, experiment: run, epoch: 59, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 523ms, time_since_start: 01h 11m 23s 671ms, eta: 02h 05m 18s 068ms
2023-04-13T22:23:11 | INFO | mmf.trainers.callbacks.logistics : progress: 7900/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.0913, train/total_loss: 0.0022, train/total_loss/avg: 0.0913, max mem: 19033.0, experiment: run, epoch: 60, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 446ms, time_since_start: 01h 12m 16s 118ms, eta: 02h 04m 14s 146ms
2023-04-13T22:24:03 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T22:24:03 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:24:08 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:24:14 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:24:14 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, train/hateful_memes/cross_entropy: 0.0022, train/hateful_memes/cross_entropy/avg: 0.0902, train/total_loss: 0.0022, train/total_loss/avg: 0.0902, max mem: 19033.0, experiment: run, epoch: 61, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00003, ups: 1.61, time: 01m 02s 776ms, time_since_start: 01h 13m 18s 894ms, eta: 02h 27m 38s 959ms
2023-04-13T22:24:14 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T22:24:14 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T22:24:17 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T22:24:17 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T22:24:17 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:24:22 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:24:28 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:24:28 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, val/hateful_memes/cross_entropy: 2.7922, val/total_loss: 2.7922, val/hateful_memes/accuracy: 0.5820, val/hateful_memes/binary_f1: 0.4305, val/hateful_memes/roc_auc: 0.6378, num_updates: 8000, epoch: 61, iterations: 8000, max_updates: 22000, val_time: 14s 170ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T22:25:20 | INFO | mmf.trainers.callbacks.logistics : progress: 8100/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0891, train/total_loss: 0.0017, train/total_loss/avg: 0.0891, max mem: 19033.0, experiment: run, epoch: 61, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 358ms, time_since_start: 01h 14m 25s 426ms, eta: 02h 02m 16s 096ms
2023-04-13T22:26:13 | INFO | mmf.trainers.callbacks.logistics : progress: 8200/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0881, train/total_loss: 0.0017, train/total_loss/avg: 0.0881, max mem: 19033.0, experiment: run, epoch: 62, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 496ms, time_since_start: 01h 15m 17s 923ms, eta: 02h 01m 42s 508ms
2023-04-13T22:27:05 | INFO | mmf.trainers.callbacks.logistics : progress: 8300/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0870, train/total_loss: 0.0015, train/total_loss/avg: 0.0870, max mem: 19033.0, experiment: run, epoch: 63, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 416ms, time_since_start: 01h 16m 10s 340ms, eta: 02h 38s 557ms
2023-04-13T22:27:58 | INFO | mmf.trainers.callbacks.logistics : progress: 8400/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0860, train/total_loss: 0.0015, train/total_loss/avg: 0.0860, max mem: 19033.0, experiment: run, epoch: 64, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 517ms, time_since_start: 01h 17m 02s 857ms, eta: 01h 59m 59s 530ms
2023-04-13T22:28:49 | INFO | mmf.trainers.callbacks.logistics : progress: 8500/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0850, train/total_loss: 0.0012, train/total_loss/avg: 0.0850, max mem: 19033.0, experiment: run, epoch: 64, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 608ms, time_since_start: 01h 17m 54s 465ms, eta: 01h 57m 02s 838ms
2023-04-13T22:29:42 | INFO | mmf.trainers.callbacks.logistics : progress: 8600/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0840, train/total_loss: 0.0010, train/total_loss/avg: 0.0840, max mem: 19033.0, experiment: run, epoch: 65, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 359ms, time_since_start: 01h 18m 46s 825ms, eta: 01h 57m 52s 340ms
2023-04-13T22:30:34 | INFO | mmf.trainers.callbacks.logistics : progress: 8700/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0831, train/total_loss: 0.0010, train/total_loss/avg: 0.0831, max mem: 19033.0, experiment: run, epoch: 66, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 500ms, time_since_start: 01h 19m 39s 326ms, eta: 01h 57m 18s 421ms
2023-04-13T22:31:27 | INFO | mmf.trainers.callbacks.logistics : progress: 8800/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0821, train/total_loss: 0.0008, train/total_loss/avg: 0.0821, max mem: 19033.0, experiment: run, epoch: 67, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 486ms, time_since_start: 01h 20m 31s 812ms, eta: 01h 56m 23s 611ms
2023-04-13T22:32:18 | INFO | mmf.trainers.callbacks.logistics : progress: 8900/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0813, train/total_loss: 0.0008, train/total_loss/avg: 0.0813, max mem: 19033.0, experiment: run, epoch: 67, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 551ms, time_since_start: 01h 21m 23s 363ms, eta: 01h 53m 27s 279ms
2023-04-13T22:33:11 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T22:33:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:33:16 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:33:21 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:33:21 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0804, train/total_loss: 0.0010, train/total_loss/avg: 0.0804, max mem: 19033.0, experiment: run, epoch: 68, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 1.61, time: 01m 02s 779ms, time_since_start: 01h 22m 26s 143ms, eta: 02h 17m 06s 576ms
2023-04-13T22:33:21 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T22:33:21 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T22:33:24 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T22:33:24 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T22:33:24 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, val/hateful_memes/cross_entropy: 3.0367, val/total_loss: 3.0367, val/hateful_memes/accuracy: 0.5700, val/hateful_memes/binary_f1: 0.4236, val/hateful_memes/roc_auc: 0.6288, num_updates: 9000, epoch: 68, iterations: 9000, max_updates: 22000, val_time: 03s 054ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T22:34:17 | INFO | mmf.trainers.callbacks.logistics : progress: 9100/22000, train/hateful_memes/cross_entropy: 0.0012, train/hateful_memes/cross_entropy/avg: 0.0795, train/total_loss: 0.0012, train/total_loss/avg: 0.0795, max mem: 19033.0, experiment: run, epoch: 69, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 1.89, time: 53s 269ms, time_since_start: 01h 23m 22s 469ms, eta: 01h 55m 26s 800ms
2023-04-13T22:35:10 | INFO | mmf.trainers.callbacks.logistics : progress: 9200/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0791, train/total_loss: 0.0015, train/total_loss/avg: 0.0791, max mem: 19033.0, experiment: run, epoch: 70, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 442ms, time_since_start: 01h 24m 14s 912ms, eta: 01h 52m 46s 349ms
2023-04-13T22:36:01 | INFO | mmf.trainers.callbacks.logistics : progress: 9300/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0783, train/total_loss: 0.0015, train/total_loss/avg: 0.0783, max mem: 19033.0, experiment: run, epoch: 70, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 469ms, time_since_start: 01h 25m 06s 381ms, eta: 01h 49m 48s 924ms
2023-04-13T22:36:54 | INFO | mmf.trainers.callbacks.logistics : progress: 9400/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0775, train/total_loss: 0.0017, train/total_loss/avg: 0.0775, max mem: 19033.0, experiment: run, epoch: 71, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 435ms, time_since_start: 01h 25m 58s 817ms, eta: 01h 50m 59s 725ms
2023-04-13T22:37:46 | INFO | mmf.trainers.callbacks.logistics : progress: 9500/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0767, train/total_loss: 0.0017, train/total_loss/avg: 0.0767, max mem: 19033.0, experiment: run, epoch: 72, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 529ms, time_since_start: 01h 26m 51s 346ms, eta: 01h 50m 18s 661ms
2023-04-13T22:38:39 | INFO | mmf.trainers.callbacks.logistics : progress: 9600/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0762, train/total_loss: 0.0020, train/total_loss/avg: 0.0762, max mem: 19033.0, experiment: run, epoch: 73, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 504ms, time_since_start: 01h 27m 43s 850ms, eta: 01h 49m 22s 617ms
2023-04-13T22:39:30 | INFO | mmf.trainers.callbacks.logistics : progress: 9700/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0754, train/total_loss: 0.0020, train/total_loss/avg: 0.0754, max mem: 19033.0, experiment: run, epoch: 73, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 572ms, time_since_start: 01h 28m 35s 423ms, eta: 01h 46m 34s 223ms
2023-04-13T22:40:23 | INFO | mmf.trainers.callbacks.logistics : progress: 9800/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0746, train/total_loss: 0.0020, train/total_loss/avg: 0.0746, max mem: 19033.0, experiment: run, epoch: 74, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 501ms, time_since_start: 01h 29m 27s 925ms, eta: 01h 47m 36s 443ms
2023-04-13T22:41:15 | INFO | mmf.trainers.callbacks.logistics : progress: 9900/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0740, train/total_loss: 0.0020, train/total_loss/avg: 0.0740, max mem: 19033.0, experiment: run, epoch: 75, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 492ms, time_since_start: 01h 30m 20s 417ms, eta: 01h 46m 42s 398ms
2023-04-13T22:42:08 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T22:42:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:42:13 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:42:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:42:18 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0732, train/total_loss: 0.0020, train/total_loss/avg: 0.0732, max mem: 19033.0, experiment: run, epoch: 76, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 1.61, time: 01m 02s 973ms, time_since_start: 01h 31m 23s 391ms, eta: 02h 06m 57s 277ms
2023-04-13T22:42:18 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T22:42:18 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T22:42:21 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T22:42:21 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T22:42:21 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, val/hateful_memes/cross_entropy: 3.1229, val/total_loss: 3.1229, val/hateful_memes/accuracy: 0.5820, val/hateful_memes/binary_f1: 0.4146, val/hateful_memes/roc_auc: 0.6505, num_updates: 10000, epoch: 76, iterations: 10000, max_updates: 22000, val_time: 03s 031ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T22:43:14 | INFO | mmf.trainers.callbacks.logistics : progress: 10100/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0725, train/total_loss: 0.0020, train/total_loss/avg: 0.0725, max mem: 19033.0, experiment: run, epoch: 76, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 380ms, time_since_start: 01h 32m 18s 804ms, eta: 01h 44m 43s 133ms
2023-04-13T22:44:06 | INFO | mmf.trainers.callbacks.logistics : progress: 10200/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0718, train/total_loss: 0.0020, train/total_loss/avg: 0.0718, max mem: 19033.0, experiment: run, epoch: 77, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 561ms, time_since_start: 01h 33m 11s 366ms, eta: 01h 44m 11s 845ms
2023-04-13T22:44:59 | INFO | mmf.trainers.callbacks.logistics : progress: 10300/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0711, train/total_loss: 0.0020, train/total_loss/avg: 0.0711, max mem: 19033.0, experiment: run, epoch: 78, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 558ms, time_since_start: 01h 34m 03s 924ms, eta: 01h 43m 18s 506ms
2023-04-13T22:45:51 | INFO | mmf.trainers.callbacks.logistics : progress: 10400/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0713, train/total_loss: 0.0020, train/total_loss/avg: 0.0713, max mem: 19033.0, experiment: run, epoch: 79, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 465ms, time_since_start: 01h 34m 56s 390ms, eta: 01h 42m 14s 721ms
2023-04-13T22:46:43 | INFO | mmf.trainers.callbacks.logistics : progress: 10500/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0706, train/total_loss: 0.0020, train/total_loss/avg: 0.0706, max mem: 19033.0, experiment: run, epoch: 79, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 592ms, time_since_start: 01h 35m 47s 982ms, eta: 01h 39m 40s 588ms
2023-04-13T22:47:35 | INFO | mmf.trainers.callbacks.logistics : progress: 10600/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0699, train/total_loss: 0.0020, train/total_loss/avg: 0.0699, max mem: 19033.0, experiment: run, epoch: 80, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 533ms, time_since_start: 01h 36m 40s 516ms, eta: 01h 40m 36s 745ms
2023-04-13T22:48:28 | INFO | mmf.trainers.callbacks.logistics : progress: 10700/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0693, train/total_loss: 0.0013, train/total_loss/avg: 0.0693, max mem: 19033.0, experiment: run, epoch: 81, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 438ms, time_since_start: 01h 37m 32s 954ms, eta: 01h 39m 32s 959ms
2023-04-13T22:49:20 | INFO | mmf.trainers.callbacks.logistics : progress: 10800/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0686, train/total_loss: 0.0013, train/total_loss/avg: 0.0686, max mem: 19033.0, experiment: run, epoch: 82, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 535ms, time_since_start: 01h 38m 25s 490ms, eta: 01h 38m 51s 037ms
2023-04-13T22:50:12 | INFO | mmf.trainers.callbacks.logistics : progress: 10900/22000, train/hateful_memes/cross_entropy: 0.0010, train/hateful_memes/cross_entropy/avg: 0.0680, train/total_loss: 0.0010, train/total_loss/avg: 0.0680, max mem: 19033.0, experiment: run, epoch: 82, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 534ms, time_since_start: 01h 39m 17s 024ms, eta: 01h 36m 06s 094ms
2023-04-13T22:51:04 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T22:51:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T22:51:09 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T22:51:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T22:51:15 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0674, train/total_loss: 0.0009, train/total_loss/avg: 0.0674, max mem: 19033.0, experiment: run, epoch: 83, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 1.61, time: 01m 02s 721ms, time_since_start: 01h 40m 19s 746ms, eta: 01h 55m 54s 594ms
2023-04-13T22:51:15 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T22:51:15 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T22:51:17 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T22:51:17 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T22:51:18 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, val/hateful_memes/cross_entropy: 3.3216, val/total_loss: 3.3216, val/hateful_memes/accuracy: 0.5760, val/hateful_memes/binary_f1: 0.4301, val/hateful_memes/roc_auc: 0.6242, num_updates: 11000, epoch: 83, iterations: 11000, max_updates: 22000, val_time: 03s 104ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T22:52:11 | INFO | mmf.trainers.callbacks.logistics : progress: 11100/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0668, train/total_loss: 0.0007, train/total_loss/avg: 0.0668, max mem: 19034.0, experiment: run, epoch: 84, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 1.89, time: 53s 381ms, time_since_start: 01h 41m 16s 234ms, eta: 01h 37m 45s 154ms
2023-04-13T22:53:03 | INFO | mmf.trainers.callbacks.logistics : progress: 11200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0662, train/total_loss: 0.0006, train/total_loss/avg: 0.0662, max mem: 19034.0, experiment: run, epoch: 85, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 409ms, time_since_start: 01h 42m 08s 644ms, eta: 01h 35m 05s 518ms
2023-04-13T22:53:55 | INFO | mmf.trainers.callbacks.logistics : progress: 11300/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0656, train/total_loss: 0.0006, train/total_loss/avg: 0.0656, max mem: 19034.0, experiment: run, epoch: 85, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 637ms, time_since_start: 01h 43m 281ms, eta: 01h 32m 49s 365ms
2023-04-13T22:54:48 | INFO | mmf.trainers.callbacks.logistics : progress: 11400/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0651, train/total_loss: 0.0006, train/total_loss/avg: 0.0651, max mem: 19034.0, experiment: run, epoch: 86, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 723ms, time_since_start: 01h 43m 53s 005ms, eta: 01h 33m 53s 448ms
2023-04-13T22:55:40 | INFO | mmf.trainers.callbacks.logistics : progress: 11500/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0645, train/total_loss: 0.0006, train/total_loss/avg: 0.0645, max mem: 19034.0, experiment: run, epoch: 87, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 519ms, time_since_start: 01h 44m 45s 524ms, eta: 01h 32m 38s 639ms
2023-04-13T22:56:33 | INFO | mmf.trainers.callbacks.logistics : progress: 11600/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0640, train/total_loss: 0.0006, train/total_loss/avg: 0.0640, max mem: 19034.0, experiment: run, epoch: 88, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 656ms, time_since_start: 01h 45m 38s 180ms, eta: 01h 32m 060ms
2023-04-13T22:57:25 | INFO | mmf.trainers.callbacks.logistics : progress: 11700/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0634, train/total_loss: 0.0006, train/total_loss/avg: 0.0634, max mem: 19034.0, experiment: run, epoch: 88, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 557ms, time_since_start: 01h 46m 29s 738ms, eta: 01h 29m 12s 932ms
2023-04-13T22:58:17 | INFO | mmf.trainers.callbacks.logistics : progress: 11800/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0629, train/total_loss: 0.0004, train/total_loss/avg: 0.0629, max mem: 19034.0, experiment: run, epoch: 89, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 611ms, time_since_start: 01h 47m 22s 350ms, eta: 01h 30m 09s 309ms
2023-04-13T22:59:10 | INFO | mmf.trainers.callbacks.logistics : progress: 11900/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0624, train/total_loss: 0.0004, train/total_loss/avg: 0.0624, max mem: 19034.0, experiment: run, epoch: 90, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 617ms, time_since_start: 01h 48m 14s 968ms, eta: 01h 29m 16s 933ms
2023-04-13T23:00:02 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T23:00:02 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T23:00:07 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T23:00:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T23:00:13 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0618, train/total_loss: 0.0004, train/total_loss/avg: 0.0618, max mem: 19034.0, experiment: run, epoch: 91, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 1.61, time: 01m 02s 955ms, time_since_start: 01h 49m 17s 923ms, eta: 01h 45m 45s 921ms
2023-04-13T23:00:13 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T23:00:13 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T23:00:16 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T23:00:16 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T23:00:16 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, val/hateful_memes/cross_entropy: 3.3993, val/total_loss: 3.3993, val/hateful_memes/accuracy: 0.5720, val/hateful_memes/binary_f1: 0.4088, val/hateful_memes/roc_auc: 0.6434, num_updates: 12000, epoch: 91, iterations: 12000, max_updates: 22000, val_time: 03s 562ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T23:01:09 | INFO | mmf.trainers.callbacks.logistics : progress: 12100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0617, train/total_loss: 0.0006, train/total_loss/avg: 0.0617, max mem: 19034.0, experiment: run, epoch: 91, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 307ms, time_since_start: 01h 50m 13s 796ms, eta: 01h 26m 59s 892ms
2023-04-13T23:02:01 | INFO | mmf.trainers.callbacks.logistics : progress: 12200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0612, train/total_loss: 0.0006, train/total_loss/avg: 0.0612, max mem: 19034.0, experiment: run, epoch: 92, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 698ms, time_since_start: 01h 51m 06s 494ms, eta: 01h 26m 45s 740ms
2023-04-13T23:02:54 | INFO | mmf.trainers.callbacks.logistics : progress: 12300/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0607, train/total_loss: 0.0006, train/total_loss/avg: 0.0607, max mem: 19034.0, experiment: run, epoch: 93, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 525ms, time_since_start: 01h 51m 59s 020ms, eta: 01h 25m 35s 775ms
2023-04-13T23:03:46 | INFO | mmf.trainers.callbacks.logistics : progress: 12400/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0602, train/total_loss: 0.0006, train/total_loss/avg: 0.0602, max mem: 19034.0, experiment: run, epoch: 94, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 483ms, time_since_start: 01h 52m 51s 503ms, eta: 01h 24m 38s 725ms
2023-04-13T23:04:38 | INFO | mmf.trainers.callbacks.logistics : progress: 12500/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0598, train/total_loss: 0.0006, train/total_loss/avg: 0.0598, max mem: 19034.0, experiment: run, epoch: 94, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 606ms, time_since_start: 01h 53m 43s 109ms, eta: 01h 22m 21s 799ms
2023-04-13T23:05:30 | INFO | mmf.trainers.callbacks.logistics : progress: 12600/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0593, train/total_loss: 0.0005, train/total_loss/avg: 0.0593, max mem: 19034.0, experiment: run, epoch: 95, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 349ms, time_since_start: 01h 54m 35s 459ms, eta: 01h 22m 40s 210ms
2023-04-13T23:06:23 | INFO | mmf.trainers.callbacks.logistics : progress: 12700/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0589, train/total_loss: 0.0006, train/total_loss/avg: 0.0589, max mem: 19034.0, experiment: run, epoch: 96, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 610ms, time_since_start: 01h 55m 28s 069ms, eta: 01h 22m 11s 910ms
2023-04-13T23:07:15 | INFO | mmf.trainers.callbacks.logistics : progress: 12800/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0584, train/total_loss: 0.0006, train/total_loss/avg: 0.0584, max mem: 19034.0, experiment: run, epoch: 97, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 632ms, time_since_start: 01h 56m 20s 702ms, eta: 01h 21m 20s 947ms
2023-04-13T23:08:07 | INFO | mmf.trainers.callbacks.logistics : progress: 12900/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0580, train/total_loss: 0.0007, train/total_loss/avg: 0.0580, max mem: 19034.0, experiment: run, epoch: 97, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 845ms, time_since_start: 01h 57m 12s 548ms, eta: 01h 19m 15s 729ms
2023-04-13T23:09:00 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T23:09:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T23:09:05 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T23:09:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T23:09:13 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0575, train/total_loss: 0.0007, train/total_loss/avg: 0.0575, max mem: 19034.0, experiment: run, epoch: 98, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 1.52, time: 01m 06s 142ms, time_since_start: 01h 58m 18s 690ms, eta: 01h 40m 434ms
2023-04-13T23:09:13 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T23:09:13 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T23:09:17 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T23:09:17 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T23:09:17 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, val/hateful_memes/cross_entropy: 3.3501, val/total_loss: 3.3501, val/hateful_memes/accuracy: 0.5660, val/hateful_memes/binary_f1: 0.4151, val/hateful_memes/roc_auc: 0.6342, num_updates: 13000, epoch: 98, iterations: 13000, max_updates: 22000, val_time: 03s 225ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T23:10:10 | INFO | mmf.trainers.callbacks.logistics : progress: 13100/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0571, train/total_loss: 0.0007, train/total_loss/avg: 0.0571, max mem: 19034.0, experiment: run, epoch: 99, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 1.89, time: 53s 236ms, time_since_start: 01h 59m 15s 168ms, eta: 01h 19m 35s 998ms
2023-04-13T23:11:02 | INFO | mmf.trainers.callbacks.logistics : progress: 13200/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0567, train/total_loss: 0.0007, train/total_loss/avg: 0.0567, max mem: 19034.0, experiment: run, epoch: 100, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 491ms, time_since_start: 02h 07s 659ms, eta: 01h 17m 36s 214ms
2023-04-13T23:11:54 | INFO | mmf.trainers.callbacks.logistics : progress: 13300/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0563, train/total_loss: 0.0007, train/total_loss/avg: 0.0563, max mem: 19034.0, experiment: run, epoch: 100, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 450ms, time_since_start: 02h 59s 110ms, eta: 01h 15m 12s 040ms
2023-04-13T23:12:47 | INFO | mmf.trainers.callbacks.logistics : progress: 13400/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0559, train/total_loss: 0.0007, train/total_loss/avg: 0.0559, max mem: 19034.0, experiment: run, epoch: 101, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 741ms, time_since_start: 02h 01m 51s 852ms, eta: 01h 16m 12s 051ms
2023-04-13T23:13:39 | INFO | mmf.trainers.callbacks.logistics : progress: 13500/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0555, train/total_loss: 0.0007, train/total_loss/avg: 0.0555, max mem: 19034.0, experiment: run, epoch: 102, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 529ms, time_since_start: 02h 02m 44s 381ms, eta: 01h 15m 703ms
2023-04-13T23:14:32 | INFO | mmf.trainers.callbacks.logistics : progress: 13600/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0551, train/total_loss: 0.0007, train/total_loss/avg: 0.0551, max mem: 19034.0, experiment: run, epoch: 103, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 689ms, time_since_start: 02h 03m 37s 070ms, eta: 01h 14m 21s 330ms
2023-04-13T23:15:24 | INFO | mmf.trainers.callbacks.logistics : progress: 13700/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0547, train/total_loss: 0.0007, train/total_loss/avg: 0.0547, max mem: 19034.0, experiment: run, epoch: 104, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 437ms, time_since_start: 02h 04m 29s 508ms, eta: 01h 13m 07s 145ms
2023-04-13T23:16:16 | INFO | mmf.trainers.callbacks.logistics : progress: 13800/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0544, train/total_loss: 0.0007, train/total_loss/avg: 0.0544, max mem: 19034.0, experiment: run, epoch: 104, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 567ms, time_since_start: 02h 05m 21s 076ms, eta: 01h 11m 02s 368ms
2023-04-13T23:17:08 | INFO | mmf.trainers.callbacks.logistics : progress: 13900/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0540, train/total_loss: 0.0007, train/total_loss/avg: 0.0540, max mem: 19034.0, experiment: run, epoch: 105, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 525ms, time_since_start: 02h 06m 13s 601ms, eta: 01h 11m 28s 586ms
2023-04-13T23:18:01 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T23:18:01 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T23:18:06 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T23:18:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T23:18:11 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0536, train/total_loss: 0.0007, train/total_loss/avg: 0.0536, max mem: 19034.0, experiment: run, epoch: 106, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0.00002, ups: 1.61, time: 01m 02s 785ms, time_since_start: 02h 07m 16s 387ms, eta: 01h 24m 23s 064ms
2023-04-13T23:18:11 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T23:18:11 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T23:18:14 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T23:18:14 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T23:18:14 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, val/hateful_memes/cross_entropy: 3.4734, val/total_loss: 3.4734, val/hateful_memes/accuracy: 0.5780, val/hateful_memes/binary_f1: 0.4123, val/hateful_memes/roc_auc: 0.6292, num_updates: 14000, epoch: 106, iterations: 14000, max_updates: 22000, val_time: 03s 126ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T23:19:08 | INFO | mmf.trainers.callbacks.logistics : progress: 14100/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0532, train/total_loss: 0.0005, train/total_loss/avg: 0.0532, max mem: 19034.0, experiment: run, epoch: 107, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0.00002, ups: 1.89, time: 53s 353ms, time_since_start: 02h 08m 12s 868ms, eta: 01h 10m 48s 615ms
2023-04-13T23:19:59 | INFO | mmf.trainers.callbacks.logistics : progress: 14200/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0528, train/total_loss: 0.0005, train/total_loss/avg: 0.0528, max mem: 19034.0, experiment: run, epoch: 107, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 504ms, time_since_start: 02h 09m 04s 373ms, eta: 01h 07m 29s 514ms
2023-04-13T23:20:52 | INFO | mmf.trainers.callbacks.logistics : progress: 14300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0525, train/total_loss: 0.0004, train/total_loss/avg: 0.0525, max mem: 19034.0, experiment: run, epoch: 108, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 470ms, time_since_start: 02h 09m 56s 843ms, eta: 01h 07m 52s 528ms
2023-04-13T23:21:44 | INFO | mmf.trainers.callbacks.logistics : progress: 14400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0521, train/total_loss: 0.0002, train/total_loss/avg: 0.0521, max mem: 19034.0, experiment: run, epoch: 109, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 383ms, time_since_start: 02h 10m 49s 227ms, eta: 01h 06m 53s 025ms
2023-04-13T23:22:37 | INFO | mmf.trainers.callbacks.logistics : progress: 14500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0517, train/total_loss: 0.0002, train/total_loss/avg: 0.0517, max mem: 19034.0, experiment: run, epoch: 110, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 647ms, time_since_start: 02h 11m 41s 875ms, eta: 01h 06m 20s 171ms
2023-04-13T23:23:28 | INFO | mmf.trainers.callbacks.logistics : progress: 14600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0515, train/total_loss: 0.0003, train/total_loss/avg: 0.0515, max mem: 19034.0, experiment: run, epoch: 110, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 563ms, time_since_start: 02h 12m 33s 438ms, eta: 01h 04m 06s 232ms
2023-04-13T23:24:21 | INFO | mmf.trainers.callbacks.logistics : progress: 14700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0512, train/total_loss: 0.0002, train/total_loss/avg: 0.0512, max mem: 19034.0, experiment: run, epoch: 111, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 543ms, time_since_start: 02h 13m 25s 982ms, eta: 01h 04m 26s 387ms
2023-04-13T23:25:13 | INFO | mmf.trainers.callbacks.logistics : progress: 14800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0508, train/total_loss: 0.0002, train/total_loss/avg: 0.0508, max mem: 19034.0, experiment: run, epoch: 112, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 429ms, time_since_start: 02h 14m 18s 411ms, eta: 01h 03m 25s 100ms
2023-04-13T23:26:06 | INFO | mmf.trainers.callbacks.logistics : progress: 14900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0505, train/total_loss: 0.0002, train/total_loss/avg: 0.0505, max mem: 19034.0, experiment: run, epoch: 113, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 540ms, time_since_start: 02h 15m 10s 952ms, eta: 01h 02m 40s 217ms
2023-04-13T23:26:57 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T23:26:57 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T23:27:02 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T23:27:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T23:27:08 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0502, train/total_loss: 0.0002, train/total_loss/avg: 0.0502, max mem: 19034.0, experiment: run, epoch: 113, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0.00002, ups: 1.61, time: 01m 02s 188ms, time_since_start: 02h 16m 13s 140ms, eta: 01h 13m 08s 002ms
2023-04-13T23:27:08 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T23:27:08 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T23:27:11 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T23:27:11 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T23:27:11 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, val/hateful_memes/cross_entropy: 3.6556, val/total_loss: 3.6556, val/hateful_memes/accuracy: 0.5620, val/hateful_memes/binary_f1: 0.3900, val/hateful_memes/roc_auc: 0.6235, num_updates: 15000, epoch: 113, iterations: 15000, max_updates: 22000, val_time: 03s 055ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T23:28:04 | INFO | mmf.trainers.callbacks.logistics : progress: 15100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0499, train/total_loss: 0.0002, train/total_loss/avg: 0.0499, max mem: 19034.0, experiment: run, epoch: 114, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0.00002, ups: 1.89, time: 53s 207ms, time_since_start: 02h 17m 09s 405ms, eta: 01h 01m 40s 694ms
2023-04-13T23:28:57 | INFO | mmf.trainers.callbacks.logistics : progress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0496, train/total_loss: 0.0001, train/total_loss/avg: 0.0496, max mem: 19034.0, experiment: run, epoch: 115, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 478ms, time_since_start: 02h 18m 01s 883ms, eta: 59m 57s 083ms
2023-04-13T23:29:49 | INFO | mmf.trainers.callbacks.logistics : progress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0493, train/total_loss: 0.0001, train/total_loss/avg: 0.0493, max mem: 19034.0, experiment: run, epoch: 116, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 449ms, time_since_start: 02h 18m 54s 333ms, eta: 59m 02s 205ms
2023-04-13T23:30:41 | INFO | mmf.trainers.callbacks.logistics : progress: 15400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0489, train/total_loss: 0.0001, train/total_loss/avg: 0.0489, max mem: 19034.0, experiment: run, epoch: 116, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 689ms, time_since_start: 02h 19m 46s 022ms, eta: 57m 18s 820ms
2023-04-13T23:31:33 | INFO | mmf.trainers.callbacks.logistics : progress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0497, train/total_loss: 0.0001, train/total_loss/avg: 0.0497, max mem: 19034.0, experiment: run, epoch: 117, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 660ms, time_since_start: 02h 20m 38s 683ms, eta: 57m 30s 304ms
2023-04-13T23:32:26 | INFO | mmf.trainers.callbacks.logistics : progress: 15600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0494, train/total_loss: 0.0001, train/total_loss/avg: 0.0494, max mem: 19034.0, experiment: run, epoch: 118, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 509ms, time_since_start: 02h 21m 31s 192ms, eta: 56m 27s 501ms
2023-04-13T23:33:18 | INFO | mmf.trainers.callbacks.logistics : progress: 15700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0491, train/total_loss: 0.0001, train/total_loss/avg: 0.0491, max mem: 19034.0, experiment: run, epoch: 119, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 494ms, time_since_start: 02h 22m 23s 687ms, eta: 55m 33s 611ms
2023-04-13T23:34:10 | INFO | mmf.trainers.callbacks.logistics : progress: 15800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0488, train/total_loss: 0.0001, train/total_loss/avg: 0.0488, max mem: 19034.0, experiment: run, epoch: 119, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 624ms, time_since_start: 02h 23m 15s 312ms, eta: 53m 46s 343ms
2023-04-13T23:35:03 | INFO | mmf.trainers.callbacks.logistics : progress: 15900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0485, train/total_loss: 0.0001, train/total_loss/avg: 0.0485, max mem: 19034.0, experiment: run, epoch: 120, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 645ms, time_since_start: 02h 24m 07s 958ms, eta: 53m 57s 097ms
2023-04-13T23:35:55 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T23:35:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T23:36:01 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T23:36:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T23:36:08 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0482, train/total_loss: 0.0001, train/total_loss/avg: 0.0482, max mem: 19034.0, experiment: run, epoch: 121, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0.00002, ups: 1.54, time: 01m 05s 151ms, time_since_start: 02h 25m 13s 110ms, eta: 01h 05m 40s 380ms
2023-04-13T23:36:08 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T23:36:08 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T23:36:11 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T23:36:11 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T23:36:11 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, val/hateful_memes/cross_entropy: 3.4772, val/total_loss: 3.4772, val/hateful_memes/accuracy: 0.5800, val/hateful_memes/binary_f1: 0.4293, val/hateful_memes/roc_auc: 0.6456, num_updates: 16000, epoch: 121, iterations: 16000, max_updates: 22000, val_time: 03s 152ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T23:37:04 | INFO | mmf.trainers.callbacks.logistics : progress: 16100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0479, train/total_loss: 0.0001, train/total_loss/avg: 0.0479, max mem: 19034.0, experiment: run, epoch: 122, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 098ms, time_since_start: 02h 26m 09s 362ms, eta: 52m 37s 850ms
2023-04-13T23:37:56 | INFO | mmf.trainers.callbacks.logistics : progress: 16200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0476, train/total_loss: 0.0001, train/total_loss/avg: 0.0476, max mem: 19034.0, experiment: run, epoch: 122, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 559ms, time_since_start: 02h 27m 921ms, eta: 50m 14s 364ms
2023-04-13T23:38:48 | INFO | mmf.trainers.callbacks.logistics : progress: 16300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0473, train/total_loss: 0.0001, train/total_loss/avg: 0.0473, max mem: 19034.0, experiment: run, epoch: 123, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 542ms, time_since_start: 02h 27m 53s 464ms, eta: 50m 18s 909ms
2023-04-13T23:39:41 | INFO | mmf.trainers.callbacks.logistics : progress: 16400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0470, train/total_loss: 0.0001, train/total_loss/avg: 0.0470, max mem: 19034.0, experiment: run, epoch: 124, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 372ms, time_since_start: 02h 28m 45s 836ms, eta: 49m 16s 311ms
2023-04-13T23:40:33 | INFO | mmf.trainers.callbacks.logistics : progress: 16500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0467, train/total_loss: 0.0001, train/total_loss/avg: 0.0467, max mem: 19034.0, experiment: run, epoch: 125, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 578ms, time_since_start: 02h 29m 38s 415ms, eta: 48m 34s 977ms
2023-04-13T23:41:25 | INFO | mmf.trainers.callbacks.logistics : progress: 16600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0465, train/total_loss: 0.0001, train/total_loss/avg: 0.0465, max mem: 19034.0, experiment: run, epoch: 125, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 552ms, time_since_start: 02h 30m 29s 968ms, eta: 46m 46s 133ms
2023-04-13T23:42:17 | INFO | mmf.trainers.callbacks.logistics : progress: 16700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0462, train/total_loss: 0.0001, train/total_loss/avg: 0.0462, max mem: 19034.0, experiment: run, epoch: 126, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 599ms, time_since_start: 02h 31m 22s 567ms, eta: 46m 50s 055ms
2023-04-13T23:43:10 | INFO | mmf.trainers.callbacks.logistics : progress: 16800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0459, train/total_loss: 0.0001, train/total_loss/avg: 0.0459, max mem: 19034.0, experiment: run, epoch: 127, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 448ms, time_since_start: 02h 32m 15s 016ms, eta: 45m 49s 133ms
2023-04-13T23:44:02 | INFO | mmf.trainers.callbacks.logistics : progress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0456, train/total_loss: 0.0001, train/total_loss/avg: 0.0456, max mem: 19034.0, experiment: run, epoch: 128, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 520ms, time_since_start: 02h 33m 07s 536ms, eta: 44m 59s 988ms
2023-04-13T23:44:54 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T23:44:54 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T23:45:01 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T23:45:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T23:45:08 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0454, train/total_loss: 0.0001, train/total_loss/avg: 0.0454, max mem: 19034.0, experiment: run, epoch: 128, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0.00001, ups: 1.54, time: 01m 05s 945ms, time_since_start: 02h 34m 13s 482ms, eta: 55m 23s 633ms
2023-04-13T23:45:08 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T23:45:08 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T23:45:11 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T23:45:11 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T23:45:11 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, val/hateful_memes/cross_entropy: 3.8017, val/total_loss: 3.8017, val/hateful_memes/accuracy: 0.5780, val/hateful_memes/binary_f1: 0.4023, val/hateful_memes/roc_auc: 0.6272, num_updates: 17000, epoch: 128, iterations: 17000, max_updates: 22000, val_time: 03s 068ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T23:46:05 | INFO | mmf.trainers.callbacks.logistics : progress: 17100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0451, train/total_loss: 0.0001, train/total_loss/avg: 0.0451, max mem: 19034.0, experiment: run, epoch: 129, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 340ms, time_since_start: 02h 35m 09s 892ms, eta: 43m 54s 586ms
2023-04-13T23:46:57 | INFO | mmf.trainers.callbacks.logistics : progress: 17200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0448, train/total_loss: 0.0001, train/total_loss/avg: 0.0448, max mem: 19034.0, experiment: run, epoch: 130, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 600ms, time_since_start: 02h 36m 02s 493ms, eta: 42m 25s 037ms
2023-04-13T23:47:50 | INFO | mmf.trainers.callbacks.logistics : progress: 17300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0446, train/total_loss: 0.0001, train/total_loss/avg: 0.0446, max mem: 19034.0, experiment: run, epoch: 131, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 591ms, time_since_start: 02h 36m 55s 084ms, eta: 41m 31s 583ms
2023-04-13T23:48:41 | INFO | mmf.trainers.callbacks.logistics : progress: 17400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0443, train/total_loss: 0.0001, train/total_loss/avg: 0.0443, max mem: 19034.0, experiment: run, epoch: 131, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 588ms, time_since_start: 02h 37m 46s 673ms, eta: 39m 52s 068ms
2023-04-13T23:49:34 | INFO | mmf.trainers.callbacks.logistics : progress: 17500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0441, train/total_loss: 0.0001, train/total_loss/avg: 0.0441, max mem: 19034.0, experiment: run, epoch: 132, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 458ms, time_since_start: 02h 38m 39s 131ms, eta: 39m 39s 498ms
2023-04-13T23:50:26 | INFO | mmf.trainers.callbacks.logistics : progress: 17600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0438, train/total_loss: 0.0001, train/total_loss/avg: 0.0438, max mem: 19034.0, experiment: run, epoch: 133, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 400ms, time_since_start: 02h 39m 31s 532ms, eta: 38m 44s 078ms
2023-04-13T23:51:19 | INFO | mmf.trainers.callbacks.logistics : progress: 17700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0436, train/total_loss: 0.0001, train/total_loss/avg: 0.0436, max mem: 19034.0, experiment: run, epoch: 134, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 614ms, time_since_start: 02h 40m 24s 146ms, eta: 38m 521ms
2023-04-13T23:52:11 | INFO | mmf.trainers.callbacks.logistics : progress: 17800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0433, train/total_loss: 0.0001, train/total_loss/avg: 0.0433, max mem: 19034.0, experiment: run, epoch: 134, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 642ms, time_since_start: 02h 41m 15s 789ms, eta: 36m 26s 344ms
2023-04-13T23:53:03 | INFO | mmf.trainers.callbacks.logistics : progress: 17900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0431, train/total_loss: 0.0001, train/total_loss/avg: 0.0431, max mem: 19034.0, experiment: run, epoch: 135, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 482ms, time_since_start: 02h 42m 08s 272ms, eta: 36m 09s 017ms
2023-04-13T23:53:56 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-13T23:53:56 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-13T23:54:01 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-13T23:54:06 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-13T23:54:06 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0428, train/total_loss: 0.0001, train/total_loss/avg: 0.0428, max mem: 19034.0, experiment: run, epoch: 136, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0.00001, ups: 1.61, time: 01m 02s 957ms, time_since_start: 02h 43m 11s 229ms, eta: 42m 18s 432ms
2023-04-13T23:54:06 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-13T23:54:06 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-13T23:54:09 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-13T23:54:09 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-13T23:54:10 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, val/hateful_memes/cross_entropy: 3.6643, val/total_loss: 3.6643, val/hateful_memes/accuracy: 0.5900, val/hateful_memes/binary_f1: 0.4474, val/hateful_memes/roc_auc: 0.6372, num_updates: 18000, epoch: 136, iterations: 18000, max_updates: 22000, val_time: 03s 593ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-13T23:55:03 | INFO | mmf.trainers.callbacks.logistics : progress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0426, train/total_loss: 0.0000, train/total_loss/avg: 0.0426, max mem: 19034.0, experiment: run, epoch: 137, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 276ms, time_since_start: 02h 44m 08s 101ms, eta: 34m 54s 392ms
2023-04-13T23:55:55 | INFO | mmf.trainers.callbacks.logistics : progress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0424, train/total_loss: 0.0000, train/total_loss/avg: 0.0424, max mem: 19034.0, experiment: run, epoch: 137, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 768ms, time_since_start: 02h 44m 59s 869ms, eta: 33m 02s 936ms
2023-04-13T23:56:47 | INFO | mmf.trainers.callbacks.logistics : progress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0421, train/total_loss: 0.0000, train/total_loss/avg: 0.0421, max mem: 19034.0, experiment: run, epoch: 138, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 457ms, time_since_start: 02h 45m 52s 326ms, eta: 32m 36s 448ms
2023-04-13T23:57:40 | INFO | mmf.trainers.callbacks.logistics : progress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0419, train/total_loss: 0.0000, train/total_loss/avg: 0.0419, max mem: 19034.0, experiment: run, epoch: 139, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 492ms, time_since_start: 02h 46m 44s 819ms, eta: 31m 44s 859ms
2023-04-13T23:58:32 | INFO | mmf.trainers.callbacks.logistics : progress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0417, train/total_loss: 0.0000, train/total_loss/avg: 0.0417, max mem: 19034.0, experiment: run, epoch: 140, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 614ms, time_since_start: 02h 47m 37s 433ms, eta: 30m 56s 232ms
2023-04-13T23:59:24 | INFO | mmf.trainers.callbacks.logistics : progress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0415, train/total_loss: 0.0000, train/total_loss/avg: 0.0415, max mem: 19034.0, experiment: run, epoch: 140, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 596ms, time_since_start: 02h 48m 29s 030ms, eta: 29m 28s 320ms
2023-04-14T00:00:16 | INFO | mmf.trainers.callbacks.logistics : progress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0412, train/total_loss: 0.0000, train/total_loss/avg: 0.0412, max mem: 19034.0, experiment: run, epoch: 141, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 633ms, time_since_start: 02h 49m 21s 663ms, eta: 29m 10s 792ms
2023-04-14T00:01:09 | INFO | mmf.trainers.callbacks.logistics : progress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0410, train/total_loss: 0.0000, train/total_loss/avg: 0.0410, max mem: 19034.0, experiment: run, epoch: 142, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 488ms, time_since_start: 02h 50m 14s 152ms, eta: 28m 13s 083ms
2023-04-14T00:02:01 | INFO | mmf.trainers.callbacks.logistics : progress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0408, train/total_loss: 0.0000, train/total_loss/avg: 0.0408, max mem: 19034.0, experiment: run, epoch: 143, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 363ms, time_since_start: 02h 51m 06s 516ms, eta: 27m 16s 261ms
2023-04-14T00:02:53 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-14T00:02:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-14T00:02:58 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-14T00:03:06 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-14T00:03:06 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0406, train/total_loss: 0.0000, train/total_loss/avg: 0.0406, max mem: 19034.0, experiment: run, epoch: 143, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0.00001, ups: 1.56, time: 01m 04s 229ms, time_since_start: 02h 52m 10s 746ms, eta: 32m 22s 301ms
2023-04-14T00:03:06 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-14T00:03:06 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-14T00:03:08 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-14T00:03:08 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-14T00:03:09 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, val/hateful_memes/cross_entropy: 3.9152, val/total_loss: 3.9152, val/hateful_memes/accuracy: 0.5840, val/hateful_memes/binary_f1: 0.4348, val/hateful_memes/roc_auc: 0.6285, num_updates: 19000, epoch: 143, iterations: 19000, max_updates: 22000, val_time: 03s 018ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-14T00:04:02 | INFO | mmf.trainers.callbacks.logistics : progress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0404, train/total_loss: 0.0000, train/total_loss/avg: 0.0404, max mem: 19034.0, experiment: run, epoch: 144, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 487ms, time_since_start: 02h 53m 07s 254ms, eta: 26m 03s 561ms
2023-04-14T00:04:54 | INFO | mmf.trainers.callbacks.logistics : progress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0402, train/total_loss: 0.0000, train/total_loss/avg: 0.0402, max mem: 19034.0, experiment: run, epoch: 145, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 470ms, time_since_start: 02h 53m 59s 725ms, eta: 24m 40s 932ms
2023-04-14T00:05:47 | INFO | mmf.trainers.callbacks.logistics : progress: 19300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0400, train/total_loss: 0.0001, train/total_loss/avg: 0.0400, max mem: 19034.0, experiment: run, epoch: 146, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 676ms, time_since_start: 02h 54m 52s 401ms, eta: 23m 53s 642ms
2023-04-14T00:06:39 | INFO | mmf.trainers.callbacks.logistics : progress: 19400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0398, train/total_loss: 0.0001, train/total_loss/avg: 0.0398, max mem: 19034.0, experiment: run, epoch: 146, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 717ms, time_since_start: 02h 55m 44s 119ms, eta: 22m 35s 414ms
2023-04-14T00:07:31 | INFO | mmf.trainers.callbacks.logistics : progress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0396, train/total_loss: 0.0000, train/total_loss/avg: 0.0396, max mem: 19034.0, experiment: run, epoch: 147, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 522ms, time_since_start: 02h 56m 36s 642ms, eta: 22m 03s 577ms
2023-04-14T00:08:24 | INFO | mmf.trainers.callbacks.logistics : progress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0394, train/total_loss: 0.0000, train/total_loss/avg: 0.0394, max mem: 19034.0, experiment: run, epoch: 148, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 712ms, time_since_start: 02h 57m 29s 354ms, eta: 21m 15s 214ms
2023-04-14T00:09:17 | INFO | mmf.trainers.callbacks.logistics : progress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0392, train/total_loss: 0.0000, train/total_loss/avg: 0.0392, max mem: 19034.0, experiment: run, epoch: 149, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 571ms, time_since_start: 02h 58m 21s 926ms, eta: 20m 18s 822ms
2023-04-14T00:10:08 | INFO | mmf.trainers.callbacks.logistics : progress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0390, train/total_loss: 0.0000, train/total_loss/avg: 0.0390, max mem: 19034.0, experiment: run, epoch: 149, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 652ms, time_since_start: 02h 59m 13s 579ms, eta: 19m 05s 452ms
2023-04-14T00:11:01 | INFO | mmf.trainers.callbacks.logistics : progress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0388, train/total_loss: 0.0000, train/total_loss/avg: 0.0388, max mem: 19034.0, experiment: run, epoch: 150, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 611ms, time_since_start: 03h 06s 191ms, eta: 18m 33s 686ms
2023-04-14T00:11:53 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-14T00:11:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-14T00:11:59 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-14T00:12:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-14T00:12:04 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0386, train/total_loss: 0.0000, train/total_loss/avg: 0.0386, max mem: 19034.0, experiment: run, epoch: 151, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0.00001, ups: 1.59, time: 01m 03s 081ms, time_since_start: 03h 01m 09s 272ms, eta: 21m 11s 722ms
2023-04-14T00:12:04 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-14T00:12:04 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-14T00:12:07 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-14T00:12:07 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-14T00:12:07 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, val/hateful_memes/cross_entropy: 3.9471, val/total_loss: 3.9471, val/hateful_memes/accuracy: 0.5980, val/hateful_memes/binary_f1: 0.4432, val/hateful_memes/roc_auc: 0.6266, num_updates: 20000, epoch: 151, iterations: 20000, max_updates: 22000, val_time: 03s 018ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-14T00:13:00 | INFO | mmf.trainers.callbacks.logistics : progress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0384, train/total_loss: 0.0000, train/total_loss/avg: 0.0384, max mem: 19034.0, experiment: run, epoch: 152, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 1.89, time: 53s 255ms, time_since_start: 03h 02m 05s 548ms, eta: 16m 59s 953ms
2023-04-14T00:13:52 | INFO | mmf.trainers.callbacks.logistics : progress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0382, train/total_loss: 0.0000, train/total_loss/avg: 0.0382, max mem: 19034.0, experiment: run, epoch: 152, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 674ms, time_since_start: 03h 02m 57s 223ms, eta: 15m 37s 590ms
2023-04-14T00:14:45 | INFO | mmf.trainers.callbacks.logistics : progress: 20300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0380, train/total_loss: 0.0001, train/total_loss/avg: 0.0380, max mem: 19034.0, experiment: run, epoch: 153, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 632ms, time_since_start: 03h 03m 49s 856ms, eta: 15m 01s 912ms
2023-04-14T00:15:37 | INFO | mmf.trainers.callbacks.logistics : progress: 20400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0378, train/total_loss: 0.0001, train/total_loss/avg: 0.0378, max mem: 19034.0, experiment: run, epoch: 154, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 571ms, time_since_start: 03h 04m 42s 427ms, eta: 14m 07s 868ms
2023-04-14T00:16:30 | INFO | mmf.trainers.callbacks.logistics : progress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0376, train/total_loss: 0.0000, train/total_loss/avg: 0.0376, max mem: 19034.0, experiment: run, epoch: 155, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 727ms, time_since_start: 03h 05m 35s 155ms, eta: 13m 17s 241ms
2023-04-14T00:17:22 | INFO | mmf.trainers.callbacks.logistics : progress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0374, train/total_loss: 0.0000, train/total_loss/avg: 0.0374, max mem: 19034.0, experiment: run, epoch: 155, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 705ms, time_since_start: 03h 06m 26s 860ms, eta: 12m 09s 667ms
2023-04-14T00:18:14 | INFO | mmf.trainers.callbacks.logistics : progress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0373, train/total_loss: 0.0000, train/total_loss/avg: 0.0373, max mem: 19034.0, experiment: run, epoch: 156, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 633ms, time_since_start: 03h 07m 19s 494ms, eta: 11m 29s 711ms
2023-04-14T00:19:07 | INFO | mmf.trainers.callbacks.logistics : progress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0371, train/total_loss: 0.0000, train/total_loss/avg: 0.0371, max mem: 19034.0, experiment: run, epoch: 157, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 615ms, time_since_start: 03h 08m 12s 109ms, eta: 10m 36s 439ms
2023-04-14T00:19:59 | INFO | mmf.trainers.callbacks.logistics : progress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0369, train/total_loss: 0.0000, train/total_loss/avg: 0.0369, max mem: 19034.0, experiment: run, epoch: 158, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 461ms, time_since_start: 03h 09m 04s 571ms, eta: 09m 41s 691ms
2023-04-14T00:20:51 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-14T00:20:51 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-14T00:20:56 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-14T00:21:01 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-14T00:21:01 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0367, train/total_loss: 0.0000, train/total_loss/avg: 0.0367, max mem: 19034.0, experiment: run, epoch: 158, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 924ms, time_since_start: 03h 10m 06s 495ms, eta: 10m 24s 196ms
2023-04-14T00:21:01 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-14T00:21:01 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-14T00:21:04 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-14T00:21:04 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-14T00:21:04 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, val/hateful_memes/cross_entropy: 3.9136, val/total_loss: 3.9136, val/hateful_memes/accuracy: 0.5800, val/hateful_memes/binary_f1: 0.4293, val/hateful_memes/roc_auc: 0.6286, num_updates: 21000, epoch: 158, iterations: 21000, max_updates: 22000, val_time: 03s 104ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-14T00:21:58 | INFO | mmf.trainers.callbacks.logistics : progress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0366, train/total_loss: 0.0000, train/total_loss/avg: 0.0366, max mem: 19034.0, experiment: run, epoch: 159, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.89, time: 53s 262ms, time_since_start: 03h 11m 02s 864ms, eta: 08m 03s 200ms
2023-04-14T00:22:50 | INFO | mmf.trainers.callbacks.logistics : progress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0364, train/total_loss: 0.0000, train/total_loss/avg: 0.0364, max mem: 19034.0, experiment: run, epoch: 160, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 748ms, time_since_start: 03h 11m 55s 613ms, eta: 07m 05s 365ms
2023-04-14T00:23:43 | INFO | mmf.trainers.callbacks.logistics : progress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0362, train/total_loss: 0.0000, train/total_loss/avg: 0.0362, max mem: 19034.0, experiment: run, epoch: 161, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 595ms, time_since_start: 03h 12m 48s 208ms, eta: 06m 11s 112ms
2023-04-14T00:24:35 | INFO | mmf.trainers.callbacks.logistics : progress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0360, train/total_loss: 0.0000, train/total_loss/avg: 0.0360, max mem: 19034.0, experiment: run, epoch: 161, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 721ms, time_since_start: 03h 13m 39s 930ms, eta: 05m 12s 810ms
2023-04-14T00:25:27 | INFO | mmf.trainers.callbacks.logistics : progress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0359, train/total_loss: 0.0000, train/total_loss/avg: 0.0359, max mem: 19034.0, experiment: run, epoch: 162, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 488ms, time_since_start: 03h 14m 32s 418ms, eta: 04m 24s 543ms
2023-04-14T00:26:20 | INFO | mmf.trainers.callbacks.logistics : progress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0357, train/total_loss: 0.0000, train/total_loss/avg: 0.0357, max mem: 19034.0, experiment: run, epoch: 163, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 574ms, time_since_start: 03h 15m 24s 993ms, eta: 03m 31s 979ms
2023-04-14T00:27:12 | INFO | mmf.trainers.callbacks.logistics : progress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0355, train/total_loss: 0.0000, train/total_loss/avg: 0.0355, max mem: 19034.0, experiment: run, epoch: 164, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 463ms, time_since_start: 03h 16m 17s 456ms, eta: 02m 38s 648ms
2023-04-14T00:28:04 | INFO | mmf.trainers.callbacks.logistics : progress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0354, train/total_loss: 0.0000, train/total_loss/avg: 0.0354, max mem: 19034.0, experiment: run, epoch: 164, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 650ms, time_since_start: 03h 17m 09s 107ms, eta: 01m 44s 128ms
2023-04-14T00:28:56 | INFO | mmf.trainers.callbacks.logistics : progress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0352, train/total_loss: 0.0000, train/total_loss/avg: 0.0352, max mem: 19034.0, experiment: run, epoch: 165, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 546ms, time_since_start: 03h 18m 01s 653ms, eta: 52s 966ms
2023-04-14T00:29:49 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-14T00:29:49 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-14T00:29:54 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-14T00:29:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-14T00:29:59 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0351, train/total_loss: 0.0000, train/total_loss/avg: 0.0351, max mem: 19034.0, experiment: run, epoch: 166, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 1.61, time: 01m 02s 477ms, time_since_start: 03h 19m 04s 131ms, eta: 0ms
2023-04-14T00:29:59 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-14T00:29:59 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-14T00:30:02 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-14T00:30:02 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-14T00:30:02 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, val/hateful_memes/cross_entropy: 4.0397, val/total_loss: 4.0397, val/hateful_memes/accuracy: 0.5880, val/hateful_memes/binary_f1: 0.4278, val/hateful_memes/roc_auc: 0.6279, num_updates: 22000, epoch: 166, iterations: 22000, max_updates: 22000, val_time: 02s 992ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.667888
2023-04-14T00:30:02 | INFO | mmf.trainers.core.training_loop : Stepping into final validation check
2023-04-14T00:30:02 | INFO | mmf.utils.checkpoint : Restoring checkpoint
2023-04-14T00:30:02 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-14T00:30:19 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-14T00:30:19 | INFO | mmf.utils.checkpoint : Current num updates: 4000
2023-04-14T00:30:19 | INFO | mmf.utils.checkpoint : Current iteration: 4000
2023-04-14T00:30:19 | INFO | mmf.utils.checkpoint : Current epoch: 31
2023-04-14T00:30:31 | INFO | mmf.trainers.mmf_trainer : Starting inference on val set
2023-04-14T00:30:31 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-14T00:30:34 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-14T00:30:34 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-14T00:30:34 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, val/hateful_memes/cross_entropy: 2.0326, val/total_loss: 2.0326, val/hateful_memes/accuracy: 0.6040, val/hateful_memes/binary_f1: 0.4975, val/hateful_memes/roc_auc: 0.6679
2023-04-14T00:30:34 | INFO | mmf.trainers.callbacks.logistics : Finished run in 03h 19m 39s 560ms
2023-04-14T00:30:49 | INFO | mmf : Logging to: ./save/train.log
2023-04-14T00:30:49 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-14T00:30:49 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-14T00:30:49 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-14T00:30:49 | INFO | mmf_cli.run : Using seed 49820179
2023-04-14T00:30:49 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-14T00:30:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-14T00:30:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-14T00:30:51 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-14T00:30:51 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-14T00:30:51 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp_ti69j9a
2023-04-14T00:30:51 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp_ti69j9a/_remote_module_non_scriptable.py
2023-04-14T00:30:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-14T00:30:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-14T00:30:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-14T00:30:51 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-14T00:30:58 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-14T00:30:58 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-14T00:30:59 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-14T00:31:00 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-14T00:31:00 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-14T00:31:00 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-14T00:31:00 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-14T00:31:00 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-14T00:31:00 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-14T00:31:00 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-14T00:31:00 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-14T00:31:00 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-14T00:31:00 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-14T00:31:00 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-14T00:31:00 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-14T00:31:07 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_49820179/reports/hateful_memes_run_test_2023-04-14T00:31:07.csv
2023-04-14T00:31:07 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 16
2023-04-14T00:31:07 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-14T02:13:07 | INFO | mmf : Logging to: ./save/train.log
2023-04-14T02:13:08 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-14T02:13:08 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-14T02:13:08 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-14T02:13:08 | INFO | mmf_cli.run : Using seed 6851252
2023-04-14T02:13:08 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-14T02:13:14 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-14T02:13:14 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-14T02:13:14 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-14T02:13:14 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-14T02:13:14 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpekuyrxp_
2023-04-14T02:13:14 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpekuyrxp_/_remote_module_non_scriptable.py
2023-04-14T02:13:14 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-14T02:13:14 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-14T02:13:14 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-14T02:13:14 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-14T02:13:31 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-14T02:13:32 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-14T02:13:32 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-14T02:13:47 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-14T02:13:47 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-14T02:13:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-14T02:13:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-14T02:13:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-14T02:13:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-14T02:13:47 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-14T02:13:47 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-14T02:13:47 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-14T02:13:47 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-14T02:13:47 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-14T02:13:47 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-14T02:13:58 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_6851252/reports/hateful_memes_run_test_2023-04-14T02:13:58.csv
2023-04-14T02:13:58 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 16
2023-04-14T02:13:58 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-24T22:56:21 | INFO | mmf : Logging to: ./save/train.log
2023-04-24T22:56:21 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl'])
2023-04-24T22:56:21 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-24T22:56:21 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-24T22:56:21 | INFO | mmf_cli.run : Using seed 20740069
2023-04-24T22:56:21 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-24T22:57:49 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-24T22:57:49 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-24T22:57:49 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-24T22:57:49 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-24T22:57:49 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmp5_7k40a3
2023-04-24T22:57:49 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmp5_7k40a3/_remote_module_non_scriptable.py
2023-04-24T22:57:49 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-24T22:57:49 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-24T22:57:49 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-24T22:57:49 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-24T22:58:22 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-24T22:58:22 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-24T22:58:23 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-24T22:58:23 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-24T22:58:23 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-24T22:58:23 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-24T22:59:25 | INFO | mmf.trainers.callbacks.logistics : progress: 100/22000, train/hateful_memes/cross_entropy: 0.7904, train/hateful_memes/cross_entropy/avg: 0.7904, train/total_loss: 0.7904, train/total_loss/avg: 0.7904, max mem: 19030.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 1.64, time: 01m 01s 787ms, time_since_start: 01m 01s 811ms, eta: 03h 47m 19s 759ms
2023-04-24T23:00:17 | INFO | mmf.trainers.callbacks.logistics : progress: 200/22000, train/hateful_memes/cross_entropy: 0.7904, train/hateful_memes/cross_entropy/avg: 0.8415, train/total_loss: 0.7904, train/total_loss/avg: 0.8415, max mem: 19030.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 166ms, time_since_start: 01m 53s 978ms, eta: 03h 11m 03s 371ms
2023-04-24T23:01:09 | INFO | mmf.trainers.callbacks.logistics : progress: 300/22000, train/hateful_memes/cross_entropy: 0.7904, train/hateful_memes/cross_entropy/avg: 0.8039, train/total_loss: 0.7904, train/total_loss/avg: 0.8039, max mem: 19030.0, experiment: run, epoch: 3, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 089ms, time_since_start: 02m 46s 068ms, eta: 03h 09m 53s 857ms
2023-04-24T23:02:01 | INFO | mmf.trainers.callbacks.logistics : progress: 400/22000, train/hateful_memes/cross_entropy: 0.7496, train/hateful_memes/cross_entropy/avg: 0.7903, train/total_loss: 0.7496, train/total_loss/avg: 0.7903, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 996ms, time_since_start: 03m 38s 064ms, eta: 03h 08m 41s 001ms
2023-04-24T23:02:52 | INFO | mmf.trainers.callbacks.logistics : progress: 500/22000, train/hateful_memes/cross_entropy: 0.7496, train/hateful_memes/cross_entropy/avg: 0.7407, train/total_loss: 0.7496, train/total_loss/avg: 0.7407, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 248ms, time_since_start: 04m 29s 312ms, eta: 03h 05m 06s 495ms
2023-04-24T23:03:44 | INFO | mmf.trainers.callbacks.logistics : progress: 600/22000, train/hateful_memes/cross_entropy: 0.7287, train/hateful_memes/cross_entropy/avg: 0.6998, train/total_loss: 0.7287, train/total_loss/avg: 0.6998, max mem: 19030.0, experiment: run, epoch: 5, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 106ms, time_since_start: 05m 21s 418ms, eta: 03h 07m 19s 921ms
2023-04-24T23:04:37 | INFO | mmf.trainers.callbacks.logistics : progress: 700/22000, train/hateful_memes/cross_entropy: 0.7287, train/hateful_memes/cross_entropy/avg: 0.6510, train/total_loss: 0.7287, train/total_loss/avg: 0.6510, max mem: 19030.0, experiment: run, epoch: 6, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 048ms, time_since_start: 06m 13s 467ms, eta: 03h 06m 15s 074ms
2023-04-24T23:05:29 | INFO | mmf.trainers.callbacks.logistics : progress: 800/22000, train/hateful_memes/cross_entropy: 0.5422, train/hateful_memes/cross_entropy/avg: 0.5901, train/total_loss: 0.5422, train/total_loss/avg: 0.5901, max mem: 19030.0, experiment: run, epoch: 7, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 160ms, time_since_start: 07m 05s 628ms, eta: 03h 05m 46s 594ms
2023-04-24T23:06:20 | INFO | mmf.trainers.callbacks.logistics : progress: 900/22000, train/hateful_memes/cross_entropy: 0.5422, train/hateful_memes/cross_entropy/avg: 0.5457, train/total_loss: 0.5422, train/total_loss/avg: 0.5457, max mem: 19030.0, experiment: run, epoch: 7, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 207ms, time_since_start: 07m 56s 835ms, eta: 03h 01m 31s 189ms
2023-04-24T23:07:12 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-24T23:07:12 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:07:48 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:08:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:08:08 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, train/hateful_memes/cross_entropy: 0.4951, train/hateful_memes/cross_entropy/avg: 0.4964, train/total_loss: 0.4951, train/total_loss/avg: 0.4964, max mem: 19030.0, experiment: run, epoch: 8, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00003, ups: 0.93, time: 01m 48s 512ms, time_since_start: 09m 45s 348ms, eta: 06h 22m 49s 945ms
2023-04-24T23:08:08 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-24T23:08:10 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-24T23:08:13 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-24T23:08:13 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-24T23:08:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:08:19 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-24T23:08:54 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:08:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:08:59 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, val/hateful_memes/cross_entropy: 1.2238, val/total_loss: 1.2238, val/hateful_memes/accuracy: 0.5800, val/hateful_memes/binary_f1: 0.4293, val/hateful_memes/roc_auc: 0.6322, num_updates: 1000, epoch: 8, iterations: 1000, max_updates: 22000, val_time: 50s 758ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.632155
2023-04-24T23:09:52 | INFO | mmf.trainers.callbacks.logistics : progress: 1100/22000, train/hateful_memes/cross_entropy: 0.4951, train/hateful_memes/cross_entropy/avg: 0.4541, train/total_loss: 0.4951, train/total_loss/avg: 0.4541, max mem: 19033.0, experiment: run, epoch: 9, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 727ms, time_since_start: 11m 28s 835ms, eta: 03h 05m 08s 226ms
2023-04-24T23:10:44 | INFO | mmf.trainers.callbacks.logistics : progress: 1200/22000, train/hateful_memes/cross_entropy: 0.3585, train/hateful_memes/cross_entropy/avg: 0.4183, train/total_loss: 0.3585, train/total_loss/avg: 0.4183, max mem: 19033.0, experiment: run, epoch: 10, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 448ms, time_since_start: 12m 21s 283ms, eta: 03h 03m 16s 514ms
2023-04-24T23:11:36 | INFO | mmf.trainers.callbacks.logistics : progress: 1300/22000, train/hateful_memes/cross_entropy: 0.3585, train/hateful_memes/cross_entropy/avg: 0.3883, train/total_loss: 0.3585, train/total_loss/avg: 0.3883, max mem: 19033.0, experiment: run, epoch: 10, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 326ms, time_since_start: 13m 12s 610ms, eta: 02h 58m 29s 595ms
2023-04-24T23:12:28 | INFO | mmf.trainers.callbacks.logistics : progress: 1400/22000, train/hateful_memes/cross_entropy: 0.1908, train/hateful_memes/cross_entropy/avg: 0.3628, train/total_loss: 0.1908, train/total_loss/avg: 0.3628, max mem: 19033.0, experiment: run, epoch: 11, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 252ms, time_since_start: 14m 04s 863ms, eta: 03h 50s 184ms
2023-04-24T23:13:20 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/22000, train/hateful_memes/cross_entropy: 0.1908, train/hateful_memes/cross_entropy/avg: 0.3416, train/total_loss: 0.1908, train/total_loss/avg: 0.3416, max mem: 19033.0, experiment: run, epoch: 12, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 171ms, time_since_start: 14m 57s 034ms, eta: 02h 59m 40s 752ms
2023-04-24T23:14:12 | INFO | mmf.trainers.callbacks.logistics : progress: 1600/22000, train/hateful_memes/cross_entropy: 0.1634, train/hateful_memes/cross_entropy/avg: 0.3253, train/total_loss: 0.1634, train/total_loss/avg: 0.3253, max mem: 19033.0, experiment: run, epoch: 13, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 267ms, time_since_start: 15m 49s 302ms, eta: 02h 59m 07s 829ms
2023-04-24T23:15:04 | INFO | mmf.trainers.callbacks.logistics : progress: 1700/22000, train/hateful_memes/cross_entropy: 0.1634, train/hateful_memes/cross_entropy/avg: 0.3090, train/total_loss: 0.1634, train/total_loss/avg: 0.3090, max mem: 19033.0, experiment: run, epoch: 13, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 256ms, time_since_start: 16m 40s 559ms, eta: 02h 54m 48s 393ms
2023-04-24T23:15:56 | INFO | mmf.trainers.callbacks.logistics : progress: 1800/22000, train/hateful_memes/cross_entropy: 0.1579, train/hateful_memes/cross_entropy/avg: 0.3006, train/total_loss: 0.1579, train/total_loss/avg: 0.3006, max mem: 19033.0, experiment: run, epoch: 14, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 260ms, time_since_start: 17m 32s 819ms, eta: 02h 57m 21s 014ms
2023-04-24T23:16:48 | INFO | mmf.trainers.callbacks.logistics : progress: 1900/22000, train/hateful_memes/cross_entropy: 0.1579, train/hateful_memes/cross_entropy/avg: 0.2883, train/total_loss: 0.1579, train/total_loss/avg: 0.2883, max mem: 19033.0, experiment: run, epoch: 15, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 143ms, time_since_start: 18m 24s 962ms, eta: 02h 56m 04s 647ms
2023-04-24T23:17:40 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-24T23:17:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:18:12 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:18:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:18:18 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, train/hateful_memes/cross_entropy: 0.0800, train/hateful_memes/cross_entropy/avg: 0.2756, train/total_loss: 0.0800, train/total_loss/avg: 0.2756, max mem: 19033.0, experiment: run, epoch: 16, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 1.12, time: 01m 29s 558ms, time_since_start: 19m 54s 521ms, eta: 05h 55s 011ms
2023-04-24T23:18:18 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-24T23:18:18 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-24T23:18:21 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-24T23:18:21 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-24T23:18:21 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:18:27 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:18:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:18:32 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, val/hateful_memes/cross_entropy: 1.9500, val/total_loss: 1.9500, val/hateful_memes/accuracy: 0.5620, val/hateful_memes/binary_f1: 0.3384, val/hateful_memes/roc_auc: 0.6321, num_updates: 2000, epoch: 16, iterations: 2000, max_updates: 22000, val_time: 14s 336ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.632155
2023-04-24T23:19:24 | INFO | mmf.trainers.callbacks.logistics : progress: 2100/22000, train/hateful_memes/cross_entropy: 0.0672, train/hateful_memes/cross_entropy/avg: 0.2631, train/total_loss: 0.0672, train/total_loss/avg: 0.2631, max mem: 19033.0, experiment: run, epoch: 16, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 878ms, time_since_start: 21m 738ms, eta: 02h 53m 26s 409ms
2023-04-24T23:20:16 | INFO | mmf.trainers.callbacks.logistics : progress: 2200/22000, train/hateful_memes/cross_entropy: 0.0522, train/hateful_memes/cross_entropy/avg: 0.2517, train/total_loss: 0.0522, train/total_loss/avg: 0.2517, max mem: 19033.0, experiment: run, epoch: 17, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 300ms, time_since_start: 21m 53s 039ms, eta: 02h 53m 58s 447ms
2023-04-24T23:21:08 | INFO | mmf.trainers.callbacks.logistics : progress: 2300/22000, train/hateful_memes/cross_entropy: 0.0487, train/hateful_memes/cross_entropy/avg: 0.2414, train/total_loss: 0.0487, train/total_loss/avg: 0.2414, max mem: 19033.0, experiment: run, epoch: 18, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 305ms, time_since_start: 22m 45s 344ms, eta: 02h 53m 06s 669ms
2023-04-24T23:22:01 | INFO | mmf.trainers.callbacks.logistics : progress: 2400/22000, train/hateful_memes/cross_entropy: 0.0444, train/hateful_memes/cross_entropy/avg: 0.2328, train/total_loss: 0.0444, train/total_loss/avg: 0.2328, max mem: 19033.0, experiment: run, epoch: 19, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 189ms, time_since_start: 23m 37s 534ms, eta: 02h 51m 51s 058ms
2023-04-24T23:22:52 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/22000, train/hateful_memes/cross_entropy: 0.0353, train/hateful_memes/cross_entropy/avg: 0.2242, train/total_loss: 0.0353, train/total_loss/avg: 0.2242, max mem: 19033.0, experiment: run, epoch: 19, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 410ms, time_since_start: 24m 28s 945ms, eta: 02h 48m 25s 289ms
2023-04-24T23:23:44 | INFO | mmf.trainers.callbacks.logistics : progress: 2600/22000, train/hateful_memes/cross_entropy: 0.0353, train/hateful_memes/cross_entropy/avg: 0.2177, train/total_loss: 0.0353, train/total_loss/avg: 0.2177, max mem: 19033.0, experiment: run, epoch: 20, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 200ms, time_since_start: 25m 21s 146ms, eta: 02h 50m 07s 976ms
2023-04-24T23:24:36 | INFO | mmf.trainers.callbacks.logistics : progress: 2700/22000, train/hateful_memes/cross_entropy: 0.0348, train/hateful_memes/cross_entropy/avg: 0.2097, train/total_loss: 0.0348, train/total_loss/avg: 0.2097, max mem: 19033.0, experiment: run, epoch: 21, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 121ms, time_since_start: 26m 13s 268ms, eta: 02h 48m 59s 953ms
2023-04-24T23:25:29 | INFO | mmf.trainers.callbacks.logistics : progress: 2800/22000, train/hateful_memes/cross_entropy: 0.0318, train/hateful_memes/cross_entropy/avg: 0.2025, train/total_loss: 0.0318, train/total_loss/avg: 0.2025, max mem: 19033.0, experiment: run, epoch: 22, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 278ms, time_since_start: 27m 05s 547ms, eta: 02h 48m 37s 857ms
2023-04-24T23:26:20 | INFO | mmf.trainers.callbacks.logistics : progress: 2900/22000, train/hateful_memes/cross_entropy: 0.0318, train/hateful_memes/cross_entropy/avg: 0.1996, train/total_loss: 0.0318, train/total_loss/avg: 0.1996, max mem: 19033.0, experiment: run, epoch: 22, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 452ms, time_since_start: 27m 56s 999ms, eta: 02h 45m 05s 977ms
2023-04-24T23:27:12 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-24T23:27:12 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:27:39 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:27:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:27:47 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, train/hateful_memes/cross_entropy: 0.0317, train/hateful_memes/cross_entropy/avg: 0.1940, train/total_loss: 0.0317, train/total_loss/avg: 0.1940, max mem: 19033.0, experiment: run, epoch: 23, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 1.15, time: 01m 27s 185ms, time_since_start: 29m 24s 185ms, eta: 04h 38m 17s 823ms
2023-04-24T23:27:47 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-24T23:27:47 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-24T23:27:50 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-24T23:27:50 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-24T23:27:50 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:27:57 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:28:03 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:28:03 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, val/hateful_memes/cross_entropy: 2.0723, val/total_loss: 2.0723, val/hateful_memes/accuracy: 0.5980, val/hateful_memes/binary_f1: 0.4962, val/hateful_memes/roc_auc: 0.6267, num_updates: 3000, epoch: 23, iterations: 3000, max_updates: 22000, val_time: 15s 567ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.632155
2023-04-24T23:28:56 | INFO | mmf.trainers.callbacks.logistics : progress: 3100/22000, train/hateful_memes/cross_entropy: 0.0295, train/hateful_memes/cross_entropy/avg: 0.1880, train/total_loss: 0.0295, train/total_loss/avg: 0.1880, max mem: 19033.0, experiment: run, epoch: 24, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 977ms, time_since_start: 30m 32s 732ms, eta: 02h 48m 12s 822ms
2023-04-24T23:29:48 | INFO | mmf.trainers.callbacks.logistics : progress: 3200/22000, train/hateful_memes/cross_entropy: 0.0295, train/hateful_memes/cross_entropy/avg: 0.1824, train/total_loss: 0.0295, train/total_loss/avg: 0.1824, max mem: 19033.0, experiment: run, epoch: 25, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 257ms, time_since_start: 31m 24s 989ms, eta: 02h 45m 03s 004ms
2023-04-24T23:30:39 | INFO | mmf.trainers.callbacks.logistics : progress: 3300/22000, train/hateful_memes/cross_entropy: 0.0295, train/hateful_memes/cross_entropy/avg: 0.1771, train/total_loss: 0.0295, train/total_loss/avg: 0.1771, max mem: 19033.0, experiment: run, epoch: 25, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 247ms, time_since_start: 32m 16s 237ms, eta: 02h 40m 59s 889ms
2023-04-24T23:31:32 | INFO | mmf.trainers.callbacks.logistics : progress: 3400/22000, train/hateful_memes/cross_entropy: 0.0295, train/hateful_memes/cross_entropy/avg: 0.1731, train/total_loss: 0.0295, train/total_loss/avg: 0.1731, max mem: 19033.0, experiment: run, epoch: 26, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 229ms, time_since_start: 33m 08s 466ms, eta: 02h 43m 12s 352ms
2023-04-24T23:32:24 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/22000, train/hateful_memes/cross_entropy: 0.0177, train/hateful_memes/cross_entropy/avg: 0.1684, train/total_loss: 0.0177, train/total_loss/avg: 0.1684, max mem: 19033.0, experiment: run, epoch: 27, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 165ms, time_since_start: 34m 632ms, eta: 02h 42m 07s 905ms
2023-04-24T23:33:16 | INFO | mmf.trainers.callbacks.logistics : progress: 3600/22000, train/hateful_memes/cross_entropy: 0.0177, train/hateful_memes/cross_entropy/avg: 0.1646, train/total_loss: 0.0177, train/total_loss/avg: 0.1646, max mem: 19033.0, experiment: run, epoch: 28, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 268ms, time_since_start: 34m 52s 901ms, eta: 02h 41m 34s 413ms
2023-04-24T23:34:07 | INFO | mmf.trainers.callbacks.logistics : progress: 3700/22000, train/hateful_memes/cross_entropy: 0.0177, train/hateful_memes/cross_entropy/avg: 0.1608, train/total_loss: 0.0177, train/total_loss/avg: 0.1608, max mem: 19033.0, experiment: run, epoch: 28, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 1.96, time: 51s 286ms, time_since_start: 35m 44s 187ms, eta: 02h 37m 40s 432ms
2023-04-24T23:34:59 | INFO | mmf.trainers.callbacks.logistics : progress: 3800/22000, train/hateful_memes/cross_entropy: 0.0177, train/hateful_memes/cross_entropy/avg: 0.1587, train/total_loss: 0.0177, train/total_loss/avg: 0.1587, max mem: 19033.0, experiment: run, epoch: 29, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 129ms, time_since_start: 36m 36s 316ms, eta: 02h 39m 23s 404ms
2023-04-24T23:35:52 | INFO | mmf.trainers.callbacks.logistics : progress: 3900/22000, train/hateful_memes/cross_entropy: 0.0147, train/hateful_memes/cross_entropy/avg: 0.1549, train/total_loss: 0.0147, train/total_loss/avg: 0.1549, max mem: 19033.0, experiment: run, epoch: 30, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 1.92, time: 52s 277ms, time_since_start: 37m 28s 593ms, eta: 02h 38m 57s 925ms
2023-04-24T23:36:44 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-24T23:36:44 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:37:01 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:37:06 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:37:06 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, train/hateful_memes/cross_entropy: 0.0129, train/hateful_memes/cross_entropy/avg: 0.1513, train/total_loss: 0.0129, train/total_loss/avg: 0.1513, max mem: 19033.0, experiment: run, epoch: 31, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 1.35, time: 01m 14s 115ms, time_since_start: 38m 42s 709ms, eta: 03h 44m 07s 554ms
2023-04-24T23:37:06 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-24T23:37:06 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-24T23:37:09 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-24T23:37:09 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-24T23:37:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:37:15 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-24T23:37:20 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:37:29 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:37:29 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, val/hateful_memes/cross_entropy: 2.3355, val/total_loss: 2.3355, val/hateful_memes/accuracy: 0.5900, val/hateful_memes/binary_f1: 0.4193, val/hateful_memes/roc_auc: 0.6434, num_updates: 4000, epoch: 31, iterations: 4000, max_updates: 22000, val_time: 23s 114ms, best_update: 4000, best_iteration: 4000, best_val/hateful_memes/roc_auc: 0.643441
2023-04-24T23:38:21 | INFO | mmf.trainers.callbacks.logistics : progress: 4100/22000, train/hateful_memes/cross_entropy: 0.0117, train/hateful_memes/cross_entropy/avg: 0.1476, train/total_loss: 0.0117, train/total_loss/avg: 0.1476, max mem: 19033.0, experiment: run, epoch: 31, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 052ms, time_since_start: 39m 57s 879ms, eta: 02h 36m 32s 006ms
2023-04-24T23:39:14 | INFO | mmf.trainers.callbacks.logistics : progress: 4200/22000, train/hateful_memes/cross_entropy: 0.0104, train/hateful_memes/cross_entropy/avg: 0.1443, train/total_loss: 0.0104, train/total_loss/avg: 0.1443, max mem: 19033.0, experiment: run, epoch: 32, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 638ms, time_since_start: 40m 50s 517ms, eta: 02h 37m 24s 629ms
2023-04-24T23:40:06 | INFO | mmf.trainers.callbacks.logistics : progress: 4300/22000, train/hateful_memes/cross_entropy: 0.0093, train/hateful_memes/cross_entropy/avg: 0.1410, train/total_loss: 0.0093, train/total_loss/avg: 0.1410, max mem: 19033.0, experiment: run, epoch: 33, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 177ms, time_since_start: 41m 42s 695ms, eta: 02h 35m 09s 264ms
2023-04-24T23:40:58 | INFO | mmf.trainers.callbacks.logistics : progress: 4400/22000, train/hateful_memes/cross_entropy: 0.0091, train/hateful_memes/cross_entropy/avg: 0.1380, train/total_loss: 0.0091, train/total_loss/avg: 0.1380, max mem: 19033.0, experiment: run, epoch: 34, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 322ms, time_since_start: 42m 35s 017ms, eta: 02h 34m 42s 456ms
2023-04-24T23:41:49 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/22000, train/hateful_memes/cross_entropy: 0.0086, train/hateful_memes/cross_entropy/avg: 0.1350, train/total_loss: 0.0086, train/total_loss/avg: 0.1350, max mem: 19033.0, experiment: run, epoch: 34, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 352ms, time_since_start: 43m 26s 370ms, eta: 02h 30m 58s 587ms
2023-04-24T23:42:42 | INFO | mmf.trainers.callbacks.logistics : progress: 4600/22000, train/hateful_memes/cross_entropy: 0.0086, train/hateful_memes/cross_entropy/avg: 0.1323, train/total_loss: 0.0086, train/total_loss/avg: 0.1323, max mem: 19033.0, experiment: run, epoch: 35, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 316ms, time_since_start: 44m 18s 687ms, eta: 02h 32m 55s 958ms
2023-04-24T23:43:34 | INFO | mmf.trainers.callbacks.logistics : progress: 4700/22000, train/hateful_memes/cross_entropy: 0.0086, train/hateful_memes/cross_entropy/avg: 0.1295, train/total_loss: 0.0086, train/total_loss/avg: 0.1295, max mem: 19033.0, experiment: run, epoch: 36, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 350ms, time_since_start: 45m 11s 038ms, eta: 02h 32m 09s 134ms
2023-04-24T23:44:26 | INFO | mmf.trainers.callbacks.logistics : progress: 4800/22000, train/hateful_memes/cross_entropy: 0.0091, train/hateful_memes/cross_entropy/avg: 0.1273, train/total_loss: 0.0091, train/total_loss/avg: 0.1273, max mem: 19033.0, experiment: run, epoch: 37, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 249ms, time_since_start: 46m 03s 287ms, eta: 02h 30m 58s 872ms
2023-04-24T23:45:18 | INFO | mmf.trainers.callbacks.logistics : progress: 4900/22000, train/hateful_memes/cross_entropy: 0.0086, train/hateful_memes/cross_entropy/avg: 0.1248, train/total_loss: 0.0086, train/total_loss/avg: 0.1248, max mem: 19033.0, experiment: run, epoch: 37, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 364ms, time_since_start: 46m 54s 652ms, eta: 02h 27m 33s 627ms
2023-04-24T23:46:10 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-24T23:46:10 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:46:30 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:46:35 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:46:35 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, train/hateful_memes/cross_entropy: 0.0083, train/hateful_memes/cross_entropy/avg: 0.1223, train/total_loss: 0.0083, train/total_loss/avg: 0.1223, max mem: 19033.0, experiment: run, epoch: 38, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 1.30, time: 01m 17s 151ms, time_since_start: 48m 11s 804ms, eta: 03h 40m 20s 771ms
2023-04-24T23:46:35 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-24T23:46:35 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-24T23:46:38 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-24T23:46:38 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-24T23:46:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:46:43 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-24T23:46:50 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:46:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:46:59 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, val/hateful_memes/cross_entropy: 2.2787, val/total_loss: 2.2787, val/hateful_memes/accuracy: 0.6020, val/hateful_memes/binary_f1: 0.4858, val/hateful_memes/roc_auc: 0.6611, num_updates: 5000, epoch: 38, iterations: 5000, max_updates: 22000, val_time: 23s 801ms, best_update: 5000, best_iteration: 5000, best_val/hateful_memes/roc_auc: 0.661071
2023-04-24T23:47:52 | INFO | mmf.trainers.callbacks.logistics : progress: 5100/22000, train/hateful_memes/cross_entropy: 0.0077, train/hateful_memes/cross_entropy/avg: 0.1199, train/total_loss: 0.0077, train/total_loss/avg: 0.1199, max mem: 19033.0, experiment: run, epoch: 39, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 1.89, time: 53s 185ms, time_since_start: 49m 28s 792ms, eta: 02h 31m 194ms
2023-04-24T23:48:44 | INFO | mmf.trainers.callbacks.logistics : progress: 5200/22000, train/hateful_memes/cross_entropy: 0.0063, train/hateful_memes/cross_entropy/avg: 0.1177, train/total_loss: 0.0063, train/total_loss/avg: 0.1177, max mem: 19033.0, experiment: run, epoch: 40, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 532ms, time_since_start: 50m 21s 324ms, eta: 02h 28m 15s 988ms
2023-04-24T23:49:36 | INFO | mmf.trainers.callbacks.logistics : progress: 5300/22000, train/hateful_memes/cross_entropy: 0.0056, train/hateful_memes/cross_entropy/avg: 0.1155, train/total_loss: 0.0056, train/total_loss/avg: 0.1155, max mem: 19033.0, experiment: run, epoch: 40, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 430ms, time_since_start: 51m 12s 755ms, eta: 02h 24m 17s 620ms
2023-04-24T23:50:28 | INFO | mmf.trainers.callbacks.logistics : progress: 5400/22000, train/hateful_memes/cross_entropy: 0.0053, train/hateful_memes/cross_entropy/avg: 0.1134, train/total_loss: 0.0053, train/total_loss/avg: 0.1134, max mem: 19033.0, experiment: run, epoch: 41, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 373ms, time_since_start: 52m 05s 128ms, eta: 02h 26m 03s 534ms
2023-04-24T23:51:21 | INFO | mmf.trainers.callbacks.logistics : progress: 5500/22000, train/hateful_memes/cross_entropy: 0.0052, train/hateful_memes/cross_entropy/avg: 0.1114, train/total_loss: 0.0052, train/total_loss/avg: 0.1114, max mem: 19033.0, experiment: run, epoch: 42, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 428ms, time_since_start: 52m 57s 557ms, eta: 02h 25m 19s 917ms
2023-04-24T23:52:13 | INFO | mmf.trainers.callbacks.logistics : progress: 5600/22000, train/hateful_memes/cross_entropy: 0.0052, train/hateful_memes/cross_entropy/avg: 0.1118, train/total_loss: 0.0052, train/total_loss/avg: 0.1118, max mem: 19033.0, experiment: run, epoch: 43, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 379ms, time_since_start: 53m 49s 937ms, eta: 02h 24m 19s 020ms
2023-04-24T23:53:04 | INFO | mmf.trainers.callbacks.logistics : progress: 5700/22000, train/hateful_memes/cross_entropy: 0.0052, train/hateful_memes/cross_entropy/avg: 0.1105, train/total_loss: 0.0052, train/total_loss/avg: 0.1105, max mem: 19033.0, experiment: run, epoch: 43, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 386ms, time_since_start: 54m 41s 324ms, eta: 02h 20m 43s 095ms
2023-04-24T23:53:57 | INFO | mmf.trainers.callbacks.logistics : progress: 5800/22000, train/hateful_memes/cross_entropy: 0.0052, train/hateful_memes/cross_entropy/avg: 0.1097, train/total_loss: 0.0052, train/total_loss/avg: 0.1097, max mem: 19033.0, experiment: run, epoch: 44, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 297ms, time_since_start: 55m 33s 621ms, eta: 02h 22m 19s 922ms
2023-04-24T23:54:49 | INFO | mmf.trainers.callbacks.logistics : progress: 5900/22000, train/hateful_memes/cross_entropy: 0.0051, train/hateful_memes/cross_entropy/avg: 0.1079, train/total_loss: 0.0051, train/total_loss/avg: 0.1079, max mem: 19033.0, experiment: run, epoch: 45, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 236ms, time_since_start: 56m 25s 857ms, eta: 02h 21m 17s 322ms
2023-04-24T23:55:41 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-24T23:55:41 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:56:22 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:56:29 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:56:29 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1062, train/total_loss: 0.0041, train/total_loss/avg: 0.1062, max mem: 19033.0, experiment: run, epoch: 46, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 1.01, time: 01m 39s 757ms, time_since_start: 58m 05s 615ms, eta: 04h 28m 08s 845ms
2023-04-24T23:56:29 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-24T23:56:29 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-24T23:56:32 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-24T23:56:32 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-24T23:56:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-24T23:56:37 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-24T23:56:43 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-24T23:56:50 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-24T23:56:50 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, val/hateful_memes/cross_entropy: 2.5581, val/total_loss: 2.5581, val/hateful_memes/accuracy: 0.5900, val/hateful_memes/binary_f1: 0.4321, val/hateful_memes/roc_auc: 0.6631, num_updates: 6000, epoch: 46, iterations: 6000, max_updates: 22000, val_time: 21s 482ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.663140
2023-04-24T23:57:42 | INFO | mmf.trainers.callbacks.logistics : progress: 6100/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.1044, train/total_loss: 0.0041, train/total_loss/avg: 0.1044, max mem: 19033.0, experiment: run, epoch: 46, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 134ms, time_since_start: 59m 19s 233ms, eta: 02h 19m 15s 641ms
2023-04-24T23:58:35 | INFO | mmf.trainers.callbacks.logistics : progress: 6200/22000, train/hateful_memes/cross_entropy: 0.0035, train/hateful_memes/cross_entropy/avg: 0.1028, train/total_loss: 0.0035, train/total_loss/avg: 0.1028, max mem: 19033.0, experiment: run, epoch: 47, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 730ms, time_since_start: 01h 11s 964ms, eta: 02h 19m 58s 121ms
2023-04-24T23:59:27 | INFO | mmf.trainers.callbacks.logistics : progress: 6300/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1012, train/total_loss: 0.0031, train/total_loss/avg: 0.1012, max mem: 19033.0, experiment: run, epoch: 48, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 289ms, time_since_start: 01h 01m 04s 254ms, eta: 02h 17m 55s 205ms
2023-04-25T00:00:20 | INFO | mmf.trainers.callbacks.logistics : progress: 6400/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.1003, train/total_loss: 0.0031, train/total_loss/avg: 0.1003, max mem: 19033.0, experiment: run, epoch: 49, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 255ms, time_since_start: 01h 01m 56s 509ms, eta: 02h 16m 57s 070ms
2023-04-25T00:01:11 | INFO | mmf.trainers.callbacks.logistics : progress: 6500/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.0989, train/total_loss: 0.0031, train/total_loss/avg: 0.0989, max mem: 19033.0, experiment: run, epoch: 49, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 371ms, time_since_start: 01h 02m 47s 881ms, eta: 02h 13m 46s 312ms
2023-04-25T00:02:03 | INFO | mmf.trainers.callbacks.logistics : progress: 6600/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.0976, train/total_loss: 0.0031, train/total_loss/avg: 0.0976, max mem: 19033.0, experiment: run, epoch: 50, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 263ms, time_since_start: 01h 03m 40s 144ms, eta: 02h 15m 12s 901ms
2023-04-25T00:02:55 | INFO | mmf.trainers.callbacks.logistics : progress: 6700/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0962, train/total_loss: 0.0025, train/total_loss/avg: 0.0962, max mem: 19033.0, experiment: run, epoch: 51, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 225ms, time_since_start: 01h 04m 32s 370ms, eta: 02h 14m 14s 482ms
2023-04-25T00:03:48 | INFO | mmf.trainers.callbacks.logistics : progress: 6800/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0948, train/total_loss: 0.0021, train/total_loss/avg: 0.0948, max mem: 19033.0, experiment: run, epoch: 52, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 221ms, time_since_start: 01h 05m 24s 591ms, eta: 02h 13m 21s 126ms
2023-04-25T00:04:39 | INFO | mmf.trainers.callbacks.logistics : progress: 6900/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0934, train/total_loss: 0.0025, train/total_loss/avg: 0.0934, max mem: 19033.0, experiment: run, epoch: 52, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 443ms, time_since_start: 01h 06m 16s 035ms, eta: 02h 10m 30s 182ms
2023-04-25T00:05:32 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T00:05:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:06:14 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:06:19 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:06:19 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.0923, train/total_loss: 0.0031, train/total_loss/avg: 0.0923, max mem: 19033.0, experiment: run, epoch: 53, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 1.01, time: 01m 39s 912ms, time_since_start: 01h 07m 55s 947ms, eta: 04h 11m 46s 704ms
2023-04-25T00:06:19 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T00:06:19 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T00:06:22 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T00:06:22 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T00:06:22 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:06:27 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:06:33 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:06:33 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, val/hateful_memes/cross_entropy: 2.6884, val/total_loss: 2.6884, val/hateful_memes/accuracy: 0.5880, val/hateful_memes/binary_f1: 0.3563, val/hateful_memes/roc_auc: 0.6469, num_updates: 7000, epoch: 53, iterations: 7000, max_updates: 22000, val_time: 13s 551ms, best_update: 6000, best_iteration: 6000, best_val/hateful_memes/roc_auc: 0.663140
2023-04-25T00:07:26 | INFO | mmf.trainers.callbacks.logistics : progress: 7100/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.0910, train/total_loss: 0.0031, train/total_loss/avg: 0.0910, max mem: 19033.0, experiment: run, epoch: 54, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 1.89, time: 53s 269ms, time_since_start: 01h 09m 02s 771ms, eta: 02h 13m 20s 694ms
2023-04-25T00:08:18 | INFO | mmf.trainers.callbacks.logistics : progress: 7200/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0897, train/total_loss: 0.0025, train/total_loss/avg: 0.0897, max mem: 19033.0, experiment: run, epoch: 55, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 393ms, time_since_start: 01h 09m 55s 165ms, eta: 02h 10m 16s 295ms
2023-04-25T00:09:10 | INFO | mmf.trainers.callbacks.logistics : progress: 7300/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0885, train/total_loss: 0.0025, train/total_loss/avg: 0.0885, max mem: 19033.0, experiment: run, epoch: 55, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 482ms, time_since_start: 01h 10m 46s 647ms, eta: 02h 07m 08s 514ms
2023-04-25T00:10:02 | INFO | mmf.trainers.callbacks.logistics : progress: 7400/22000, train/hateful_memes/cross_entropy: 0.0031, train/hateful_memes/cross_entropy/avg: 0.0874, train/total_loss: 0.0031, train/total_loss/avg: 0.0874, max mem: 19033.0, experiment: run, epoch: 56, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 379ms, time_since_start: 01h 11m 39s 027ms, eta: 02h 08m 28s 607ms
2023-04-25T00:10:55 | INFO | mmf.trainers.callbacks.logistics : progress: 7500/22000, train/hateful_memes/cross_entropy: 0.0025, train/hateful_memes/cross_entropy/avg: 0.0863, train/total_loss: 0.0025, train/total_loss/avg: 0.0863, max mem: 19033.0, experiment: run, epoch: 57, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 411ms, time_since_start: 01h 12m 31s 438ms, eta: 02h 07m 40s 447ms
2023-04-25T00:11:47 | INFO | mmf.trainers.callbacks.logistics : progress: 7600/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0851, train/total_loss: 0.0020, train/total_loss/avg: 0.0851, max mem: 19033.0, experiment: run, epoch: 58, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 363ms, time_since_start: 01h 13m 23s 803ms, eta: 02h 06m 40s 744ms
2023-04-25T00:12:38 | INFO | mmf.trainers.callbacks.logistics : progress: 7700/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0840, train/total_loss: 0.0020, train/total_loss/avg: 0.0840, max mem: 19033.0, experiment: run, epoch: 58, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 1.96, time: 51s 332ms, time_since_start: 01h 14m 15s 135ms, eta: 02h 03m 19s 285ms
2023-04-25T00:13:31 | INFO | mmf.trainers.callbacks.logistics : progress: 7800/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.0830, train/total_loss: 0.0019, train/total_loss/avg: 0.0830, max mem: 19033.0, experiment: run, epoch: 59, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 380ms, time_since_start: 01h 15m 07s 516ms, eta: 02h 04m 57s 531ms
2023-04-25T00:14:23 | INFO | mmf.trainers.callbacks.logistics : progress: 7900/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.0820, train/total_loss: 0.0019, train/total_loss/avg: 0.0820, max mem: 19033.0, experiment: run, epoch: 60, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 1.92, time: 52s 308ms, time_since_start: 01h 15m 59s 824ms, eta: 02h 03m 54s 547ms
2023-04-25T00:15:15 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T00:15:15 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:15:47 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:15:54 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:15:54 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.0810, train/total_loss: 0.0019, train/total_loss/avg: 0.0810, max mem: 19033.0, experiment: run, epoch: 61, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00003, ups: 1.11, time: 01m 30s 933ms, time_since_start: 01h 17m 30s 758ms, eta: 03h 33m 52s 522ms
2023-04-25T00:15:54 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T00:15:54 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T00:15:57 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T00:15:57 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T00:15:57 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:16:02 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-25T00:16:08 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:16:14 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:16:14 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, val/hateful_memes/cross_entropy: 2.6853, val/total_loss: 2.6853, val/hateful_memes/accuracy: 0.6160, val/hateful_memes/binary_f1: 0.5102, val/hateful_memes/roc_auc: 0.6658, num_updates: 8000, epoch: 61, iterations: 8000, max_updates: 22000, val_time: 20s 003ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T00:17:06 | INFO | mmf.trainers.callbacks.logistics : progress: 8100/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0801, train/total_loss: 0.0021, train/total_loss/avg: 0.0801, max mem: 19033.0, experiment: run, epoch: 61, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 192ms, time_since_start: 01h 18m 42s 956ms, eta: 02h 01m 52s 746ms
2023-04-25T00:17:59 | INFO | mmf.trainers.callbacks.logistics : progress: 8200/22000, train/hateful_memes/cross_entropy: 0.0021, train/hateful_memes/cross_entropy/avg: 0.0796, train/total_loss: 0.0021, train/total_loss/avg: 0.0796, max mem: 19033.0, experiment: run, epoch: 62, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 656ms, time_since_start: 01h 19m 35s 613ms, eta: 02h 02m 04s 787ms
2023-04-25T00:18:51 | INFO | mmf.trainers.callbacks.logistics : progress: 8300/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.0786, train/total_loss: 0.0019, train/total_loss/avg: 0.0786, max mem: 19033.0, experiment: run, epoch: 63, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 421ms, time_since_start: 01h 20m 28s 034ms, eta: 02h 39s 156ms
2023-04-25T00:19:44 | INFO | mmf.trainers.callbacks.logistics : progress: 8400/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.0778, train/total_loss: 0.0019, train/total_loss/avg: 0.0778, max mem: 19033.0, experiment: run, epoch: 64, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 486ms, time_since_start: 01h 21m 20s 521ms, eta: 01h 59m 55s 326ms
2023-04-25T00:20:35 | INFO | mmf.trainers.callbacks.logistics : progress: 8500/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0769, train/total_loss: 0.0016, train/total_loss/avg: 0.0769, max mem: 19033.0, experiment: run, epoch: 64, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 491ms, time_since_start: 01h 22m 12s 013ms, eta: 01h 56m 47s 026ms
2023-04-25T00:21:27 | INFO | mmf.trainers.callbacks.logistics : progress: 8600/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0760, train/total_loss: 0.0016, train/total_loss/avg: 0.0760, max mem: 19033.0, experiment: run, epoch: 65, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 417ms, time_since_start: 01h 23m 04s 431ms, eta: 01h 58m 207ms
2023-04-25T00:22:20 | INFO | mmf.trainers.callbacks.logistics : progress: 8700/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0751, train/total_loss: 0.0016, train/total_loss/avg: 0.0751, max mem: 19033.0, experiment: run, epoch: 66, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 250ms, time_since_start: 01h 23m 56s 682ms, eta: 01h 56m 44s 914ms
2023-04-25T00:23:12 | INFO | mmf.trainers.callbacks.logistics : progress: 8800/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0743, train/total_loss: 0.0017, train/total_loss/avg: 0.0743, max mem: 19033.0, experiment: run, epoch: 67, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 251ms, time_since_start: 01h 24m 48s 933ms, eta: 01h 55m 52s 322ms
2023-04-25T00:24:03 | INFO | mmf.trainers.callbacks.logistics : progress: 8900/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0735, train/total_loss: 0.0017, train/total_loss/avg: 0.0735, max mem: 19033.0, experiment: run, epoch: 67, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 366ms, time_since_start: 01h 25m 40s 299ms, eta: 01h 53m 02s 826ms
2023-04-25T00:24:56 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T00:24:56 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:25:27 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:25:34 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:25:34 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0727, train/total_loss: 0.0016, train/total_loss/avg: 0.0727, max mem: 19033.0, experiment: run, epoch: 68, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 1.11, time: 01m 30s 834ms, time_since_start: 01h 27m 11s 134ms, eta: 03h 18m 22s 955ms
2023-04-25T00:25:34 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T00:25:34 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T00:25:37 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T00:25:37 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T00:25:37 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:25:43 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:25:48 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:25:48 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, val/hateful_memes/cross_entropy: 2.9155, val/total_loss: 2.9155, val/hateful_memes/accuracy: 0.5840, val/hateful_memes/binary_f1: 0.4222, val/hateful_memes/roc_auc: 0.6518, num_updates: 9000, epoch: 68, iterations: 9000, max_updates: 22000, val_time: 13s 860ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T00:26:41 | INFO | mmf.trainers.callbacks.logistics : progress: 9100/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0719, train/total_loss: 0.0016, train/total_loss/avg: 0.0719, max mem: 19033.0, experiment: run, epoch: 69, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 1.89, time: 53s 106ms, time_since_start: 01h 28m 18s 103ms, eta: 01h 55m 05s 612ms
2023-04-25T00:27:34 | INFO | mmf.trainers.callbacks.logistics : progress: 9200/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0715, train/total_loss: 0.0017, train/total_loss/avg: 0.0715, max mem: 19033.0, experiment: run, epoch: 70, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 522ms, time_since_start: 01h 29m 10s 625ms, eta: 01h 52m 56s 635ms
2023-04-25T00:28:25 | INFO | mmf.trainers.callbacks.logistics : progress: 9300/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.0708, train/total_loss: 0.0019, train/total_loss/avg: 0.0708, max mem: 19033.0, experiment: run, epoch: 70, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 388ms, time_since_start: 01h 30m 02s 014ms, eta: 01h 49m 38s 606ms
2023-04-25T00:29:17 | INFO | mmf.trainers.callbacks.logistics : progress: 9400/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0700, train/total_loss: 0.0017, train/total_loss/avg: 0.0700, max mem: 19033.0, experiment: run, epoch: 71, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 419ms, time_since_start: 01h 30m 54s 434ms, eta: 01h 50m 57s 676ms
2023-04-25T00:30:10 | INFO | mmf.trainers.callbacks.logistics : progress: 9500/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0693, train/total_loss: 0.0017, train/total_loss/avg: 0.0693, max mem: 19033.0, experiment: run, epoch: 72, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 281ms, time_since_start: 01h 31m 46s 716ms, eta: 01h 49m 47s 534ms
2023-04-25T00:31:02 | INFO | mmf.trainers.callbacks.logistics : progress: 9600/22000, train/hateful_memes/cross_entropy: 0.0019, train/hateful_memes/cross_entropy/avg: 0.0686, train/total_loss: 0.0019, train/total_loss/avg: 0.0686, max mem: 19033.0, experiment: run, epoch: 73, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 317ms, time_since_start: 01h 32m 39s 034ms, eta: 01h 48m 59s 330ms
2023-04-25T00:31:54 | INFO | mmf.trainers.callbacks.logistics : progress: 9700/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0679, train/total_loss: 0.0017, train/total_loss/avg: 0.0679, max mem: 19033.0, experiment: run, epoch: 73, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 417ms, time_since_start: 01h 33m 30s 451ms, eta: 01h 46m 14s 977ms
2023-04-25T00:32:46 | INFO | mmf.trainers.callbacks.logistics : progress: 9800/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0672, train/total_loss: 0.0017, train/total_loss/avg: 0.0672, max mem: 19033.0, experiment: run, epoch: 74, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 295ms, time_since_start: 01h 34m 22s 747ms, eta: 01h 47m 11s 099ms
2023-04-25T00:33:38 | INFO | mmf.trainers.callbacks.logistics : progress: 9900/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0666, train/total_loss: 0.0016, train/total_loss/avg: 0.0666, max mem: 19033.0, experiment: run, epoch: 75, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 374ms, time_since_start: 01h 35m 15s 121ms, eta: 01h 46m 27s 968ms
2023-04-25T00:34:31 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T00:34:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:35:03 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:35:10 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:35:10 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0659, train/total_loss: 0.0016, train/total_loss/avg: 0.0659, max mem: 19033.0, experiment: run, epoch: 76, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 1.09, time: 01m 32s 173ms, time_since_start: 01h 36m 47s 295ms, eta: 03h 05m 49s 288ms
2023-04-25T00:35:10 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T00:35:10 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T00:35:13 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T00:35:13 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T00:35:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:35:19 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:35:25 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:35:25 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, val/hateful_memes/cross_entropy: 3.0431, val/total_loss: 3.0431, val/hateful_memes/accuracy: 0.5860, val/hateful_memes/binary_f1: 0.4480, val/hateful_memes/roc_auc: 0.6357, num_updates: 10000, epoch: 76, iterations: 10000, max_updates: 22000, val_time: 15s 064ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T00:36:17 | INFO | mmf.trainers.callbacks.logistics : progress: 10100/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0653, train/total_loss: 0.0016, train/total_loss/avg: 0.0653, max mem: 19033.0, experiment: run, epoch: 76, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 042ms, time_since_start: 01h 37m 54s 404ms, eta: 01h 44m 02s 657ms
2023-04-25T00:37:10 | INFO | mmf.trainers.callbacks.logistics : progress: 10200/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0647, train/total_loss: 0.0013, train/total_loss/avg: 0.0647, max mem: 19033.0, experiment: run, epoch: 77, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 456ms, time_since_start: 01h 38m 46s 861ms, eta: 01h 43m 59s 435ms
2023-04-25T00:38:02 | INFO | mmf.trainers.callbacks.logistics : progress: 10300/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0640, train/total_loss: 0.0013, train/total_loss/avg: 0.0640, max mem: 19033.0, experiment: run, epoch: 78, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 408ms, time_since_start: 01h 39m 39s 269ms, eta: 01h 43m 825ms
2023-04-25T00:38:55 | INFO | mmf.trainers.callbacks.logistics : progress: 10400/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0639, train/total_loss: 0.0013, train/total_loss/avg: 0.0639, max mem: 19033.0, experiment: run, epoch: 79, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 281ms, time_since_start: 01h 40m 31s 550ms, eta: 01h 41m 53s 127ms
2023-04-25T00:39:46 | INFO | mmf.trainers.callbacks.logistics : progress: 10500/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0633, train/total_loss: 0.0013, train/total_loss/avg: 0.0633, max mem: 19033.0, experiment: run, epoch: 79, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 406ms, time_since_start: 01h 41m 22s 957ms, eta: 01h 39m 19s 040ms
2023-04-25T00:40:38 | INFO | mmf.trainers.callbacks.logistics : progress: 10600/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0627, train/total_loss: 0.0011, train/total_loss/avg: 0.0627, max mem: 19033.0, experiment: run, epoch: 80, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 289ms, time_since_start: 01h 42m 15s 246ms, eta: 01h 40m 08s 734ms
2023-04-25T00:41:31 | INFO | mmf.trainers.callbacks.logistics : progress: 10700/22000, train/hateful_memes/cross_entropy: 0.0013, train/hateful_memes/cross_entropy/avg: 0.0623, train/total_loss: 0.0013, train/total_loss/avg: 0.0623, max mem: 19033.0, experiment: run, epoch: 81, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 319ms, time_since_start: 01h 43m 07s 566ms, eta: 01h 39m 19s 366ms
2023-04-25T00:42:23 | INFO | mmf.trainers.callbacks.logistics : progress: 10800/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0618, train/total_loss: 0.0011, train/total_loss/avg: 0.0618, max mem: 19033.0, experiment: run, epoch: 82, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 287ms, time_since_start: 01h 43m 59s 853ms, eta: 01h 38m 23s 043ms
2023-04-25T00:43:14 | INFO | mmf.trainers.callbacks.logistics : progress: 10900/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0612, train/total_loss: 0.0011, train/total_loss/avg: 0.0612, max mem: 19033.0, experiment: run, epoch: 82, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 326ms, time_since_start: 01h 44m 51s 180ms, eta: 01h 35m 42s 870ms
2023-04-25T00:44:07 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T00:44:07 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:44:37 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:44:42 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:44:42 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0613, train/total_loss: 0.0011, train/total_loss/avg: 0.0613, max mem: 19033.0, experiment: run, epoch: 83, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 1.14, time: 01m 28s 250ms, time_since_start: 01h 46m 19s 430ms, eta: 02h 43m 05s 166ms
2023-04-25T00:44:42 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T00:44:42 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T00:44:45 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T00:44:45 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T00:44:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:44:51 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:44:57 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:44:57 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, val/hateful_memes/cross_entropy: 3.0744, val/total_loss: 3.0744, val/hateful_memes/accuracy: 0.5820, val/hateful_memes/binary_f1: 0.4305, val/hateful_memes/roc_auc: 0.6200, num_updates: 11000, epoch: 83, iterations: 11000, max_updates: 22000, val_time: 14s 507ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T00:45:50 | INFO | mmf.trainers.callbacks.logistics : progress: 11100/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0607, train/total_loss: 0.0011, train/total_loss/avg: 0.0607, max mem: 19034.0, experiment: run, epoch: 84, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 1.89, time: 53s 274ms, time_since_start: 01h 47m 27s 214ms, eta: 01h 37m 33s 361ms
2023-04-25T00:46:43 | INFO | mmf.trainers.callbacks.logistics : progress: 11200/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0602, train/total_loss: 0.0007, train/total_loss/avg: 0.0602, max mem: 19034.0, experiment: run, epoch: 85, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 452ms, time_since_start: 01h 48m 19s 667ms, eta: 01h 35m 10s 198ms
2023-04-25T00:47:34 | INFO | mmf.trainers.callbacks.logistics : progress: 11300/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0597, train/total_loss: 0.0006, train/total_loss/avg: 0.0597, max mem: 19034.0, experiment: run, epoch: 85, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 521ms, time_since_start: 01h 49m 11s 188ms, eta: 01h 32m 36s 856ms
2023-04-25T00:48:27 | INFO | mmf.trainers.callbacks.logistics : progress: 11400/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0592, train/total_loss: 0.0007, train/total_loss/avg: 0.0592, max mem: 19034.0, experiment: run, epoch: 86, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 380ms, time_since_start: 01h 50m 03s 568ms, eta: 01h 33m 16s 755ms
2023-04-25T00:49:19 | INFO | mmf.trainers.callbacks.logistics : progress: 11500/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0587, train/total_loss: 0.0011, train/total_loss/avg: 0.0587, max mem: 19034.0, experiment: run, epoch: 87, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 366ms, time_since_start: 01h 50m 55s 935ms, eta: 01h 32m 22s 489ms
2023-04-25T00:50:11 | INFO | mmf.trainers.callbacks.logistics : progress: 11600/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0583, train/total_loss: 0.0011, train/total_loss/avg: 0.0583, max mem: 19034.0, experiment: run, epoch: 88, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 350ms, time_since_start: 01h 51m 48s 286ms, eta: 01h 31m 28s 031ms
2023-04-25T00:51:03 | INFO | mmf.trainers.callbacks.logistics : progress: 11700/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0578, train/total_loss: 0.0011, train/total_loss/avg: 0.0578, max mem: 19034.0, experiment: run, epoch: 88, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 1.96, time: 51s 537ms, time_since_start: 01h 52m 39s 823ms, eta: 01h 29m 10s 842ms
2023-04-25T00:51:55 | INFO | mmf.trainers.callbacks.logistics : progress: 11800/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0573, train/total_loss: 0.0011, train/total_loss/avg: 0.0573, max mem: 19034.0, experiment: run, epoch: 89, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 289ms, time_since_start: 01h 53m 32s 112ms, eta: 01h 29m 36s 165ms
2023-04-25T00:52:48 | INFO | mmf.trainers.callbacks.logistics : progress: 11900/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0568, train/total_loss: 0.0008, train/total_loss/avg: 0.0568, max mem: 19034.0, experiment: run, epoch: 90, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 1.92, time: 52s 376ms, time_since_start: 01h 54m 24s 489ms, eta: 01h 28m 52s 309ms
2023-04-25T00:53:40 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T00:53:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:53:56 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:54:02 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:54:02 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0564, train/total_loss: 0.0008, train/total_loss/avg: 0.0564, max mem: 19034.0, experiment: run, epoch: 91, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 1.35, time: 01m 14s 135ms, time_since_start: 01h 55m 38s 624ms, eta: 02h 04m 32s 865ms
2023-04-25T00:54:02 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T00:54:02 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T00:54:05 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T00:54:05 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T00:54:05 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T00:54:10 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T00:54:17 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T00:54:17 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, val/hateful_memes/cross_entropy: 3.3864, val/total_loss: 3.3864, val/hateful_memes/accuracy: 0.5860, val/hateful_memes/binary_f1: 0.4169, val/hateful_memes/roc_auc: 0.6218, num_updates: 12000, epoch: 91, iterations: 12000, max_updates: 22000, val_time: 14s 981ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T00:55:09 | INFO | mmf.trainers.callbacks.logistics : progress: 12100/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0559, train/total_loss: 0.0006, train/total_loss/avg: 0.0559, max mem: 19034.0, experiment: run, epoch: 91, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 343ms, time_since_start: 01h 56m 45s 950ms, eta: 01h 27m 03s 431ms
2023-04-25T00:56:02 | INFO | mmf.trainers.callbacks.logistics : progress: 12200/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0554, train/total_loss: 0.0006, train/total_loss/avg: 0.0554, max mem: 19034.0, experiment: run, epoch: 92, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 556ms, time_since_start: 01h 57m 38s 507ms, eta: 01h 26m 31s 794ms
2023-04-25T00:56:54 | INFO | mmf.trainers.callbacks.logistics : progress: 12300/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0550, train/total_loss: 0.0006, train/total_loss/avg: 0.0550, max mem: 19034.0, experiment: run, epoch: 93, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 254ms, time_since_start: 01h 58m 30s 762ms, eta: 01h 25m 09s 284ms
2023-04-25T00:57:46 | INFO | mmf.trainers.callbacks.logistics : progress: 12400/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0546, train/total_loss: 0.0006, train/total_loss/avg: 0.0546, max mem: 19034.0, experiment: run, epoch: 94, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 455ms, time_since_start: 01h 59m 23s 218ms, eta: 01h 24m 36s 036ms
2023-04-25T00:58:38 | INFO | mmf.trainers.callbacks.logistics : progress: 12500/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0542, train/total_loss: 0.0006, train/total_loss/avg: 0.0542, max mem: 19034.0, experiment: run, epoch: 94, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 395ms, time_since_start: 02h 14s 614ms, eta: 01h 22m 01s 618ms
2023-04-25T00:59:30 | INFO | mmf.trainers.callbacks.logistics : progress: 12600/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0538, train/total_loss: 0.0006, train/total_loss/avg: 0.0538, max mem: 19034.0, experiment: run, epoch: 95, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 276ms, time_since_start: 02h 01m 06s 890ms, eta: 01h 22m 33s 264ms
2023-04-25T01:00:22 | INFO | mmf.trainers.callbacks.logistics : progress: 12700/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0533, train/total_loss: 0.0006, train/total_loss/avg: 0.0533, max mem: 19034.0, experiment: run, epoch: 96, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 310ms, time_since_start: 02h 01m 59s 200ms, eta: 01h 21m 43s 778ms
2023-04-25T01:01:15 | INFO | mmf.trainers.callbacks.logistics : progress: 12800/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0529, train/total_loss: 0.0006, train/total_loss/avg: 0.0529, max mem: 19034.0, experiment: run, epoch: 97, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 333ms, time_since_start: 02h 02m 51s 534ms, eta: 01h 20m 53s 240ms
2023-04-25T01:02:06 | INFO | mmf.trainers.callbacks.logistics : progress: 12900/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0525, train/total_loss: 0.0006, train/total_loss/avg: 0.0525, max mem: 19034.0, experiment: run, epoch: 97, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 426ms, time_since_start: 02h 03m 42s 960ms, eta: 01h 18m 37s 240ms
2023-04-25T01:02:58 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T01:02:58 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T01:03:40 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T01:03:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T01:03:47 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0521, train/total_loss: 0.0005, train/total_loss/avg: 0.0521, max mem: 19034.0, experiment: run, epoch: 98, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 1.00, time: 01m 40s 936ms, time_since_start: 02h 05m 23s 897ms, eta: 02h 32m 36s 970ms
2023-04-25T01:03:47 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T01:03:47 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T01:03:50 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T01:03:50 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T01:03:51 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, val/hateful_memes/cross_entropy: 3.7593, val/total_loss: 3.7593, val/hateful_memes/accuracy: 0.5560, val/hateful_memes/binary_f1: 0.3833, val/hateful_memes/roc_auc: 0.6280, num_updates: 13000, epoch: 98, iterations: 13000, max_updates: 22000, val_time: 04s 151ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T01:04:44 | INFO | mmf.trainers.callbacks.logistics : progress: 13100/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0517, train/total_loss: 0.0005, train/total_loss/avg: 0.0517, max mem: 19034.0, experiment: run, epoch: 99, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 1.89, time: 53s 159ms, time_since_start: 02h 06m 21s 209ms, eta: 01h 19m 29s 026ms
2023-04-25T01:05:37 | INFO | mmf.trainers.callbacks.logistics : progress: 13200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0513, train/total_loss: 0.0004, train/total_loss/avg: 0.0513, max mem: 19034.0, experiment: run, epoch: 100, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 506ms, time_since_start: 02h 07m 13s 716ms, eta: 01h 17m 37s 579ms
2023-04-25T01:06:28 | INFO | mmf.trainers.callbacks.logistics : progress: 13300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0510, train/total_loss: 0.0004, train/total_loss/avg: 0.0510, max mem: 19034.0, experiment: run, epoch: 100, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 319ms, time_since_start: 02h 08m 05s 035ms, eta: 01h 15m 481ms
2023-04-25T01:07:21 | INFO | mmf.trainers.callbacks.logistics : progress: 13400/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0506, train/total_loss: 0.0004, train/total_loss/avg: 0.0506, max mem: 19034.0, experiment: run, epoch: 101, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 494ms, time_since_start: 02h 08m 57s 530ms, eta: 01h 15m 50s 658ms
2023-04-25T01:08:13 | INFO | mmf.trainers.callbacks.logistics : progress: 13500/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0503, train/total_loss: 0.0004, train/total_loss/avg: 0.0503, max mem: 19034.0, experiment: run, epoch: 102, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 235ms, time_since_start: 02h 09m 49s 765ms, eta: 01h 14m 35s 525ms
2023-04-25T01:09:05 | INFO | mmf.trainers.callbacks.logistics : progress: 13600/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0499, train/total_loss: 0.0004, train/total_loss/avg: 0.0499, max mem: 19034.0, experiment: run, epoch: 103, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 441ms, time_since_start: 02h 10m 42s 207ms, eta: 01h 14m 334ms
2023-04-25T01:09:58 | INFO | mmf.trainers.callbacks.logistics : progress: 13700/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0495, train/total_loss: 0.0004, train/total_loss/avg: 0.0495, max mem: 19034.0, experiment: run, epoch: 104, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 276ms, time_since_start: 02h 11m 34s 483ms, eta: 01h 12m 53s 626ms
2023-04-25T01:10:49 | INFO | mmf.trainers.callbacks.logistics : progress: 13800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0492, train/total_loss: 0.0002, train/total_loss/avg: 0.0492, max mem: 19034.0, experiment: run, epoch: 104, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 479ms, time_since_start: 02h 12m 25s 962ms, eta: 01h 10m 55s 061ms
2023-04-25T01:11:41 | INFO | mmf.trainers.callbacks.logistics : progress: 13900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0488, train/total_loss: 0.0002, train/total_loss/avg: 0.0488, max mem: 19034.0, experiment: run, epoch: 105, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 437ms, time_since_start: 02h 13m 18s 400ms, eta: 01h 11m 21s 417ms
2023-04-25T01:12:34 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T01:12:34 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T01:13:07 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T01:13:16 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T01:13:16 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0485, train/total_loss: 0.0002, train/total_loss/avg: 0.0485, max mem: 19034.0, experiment: run, epoch: 106, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0.00002, ups: 1.06, time: 01m 34s 417ms, time_since_start: 02h 14m 52s 817ms, eta: 02h 06m 53s 815ms
2023-04-25T01:13:16 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T01:13:16 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T01:13:19 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T01:13:19 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T01:13:19 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, val/hateful_memes/cross_entropy: 3.6103, val/total_loss: 3.6103, val/hateful_memes/accuracy: 0.5700, val/hateful_memes/binary_f1: 0.4011, val/hateful_memes/roc_auc: 0.6329, num_updates: 14000, epoch: 106, iterations: 14000, max_updates: 22000, val_time: 03s 268ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T01:14:13 | INFO | mmf.trainers.callbacks.logistics : progress: 14100/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0481, train/total_loss: 0.0004, train/total_loss/avg: 0.0481, max mem: 19034.0, experiment: run, epoch: 107, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0.00002, ups: 1.89, time: 53s 429ms, time_since_start: 02h 15m 49s 517ms, eta: 01h 10m 54s 669ms
2023-04-25T01:15:04 | INFO | mmf.trainers.callbacks.logistics : progress: 14200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0478, train/total_loss: 0.0004, train/total_loss/avg: 0.0478, max mem: 19034.0, experiment: run, epoch: 107, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 784ms, time_since_start: 02h 16m 41s 301ms, eta: 01h 07m 51s 515ms
2023-04-25T01:15:57 | INFO | mmf.trainers.callbacks.logistics : progress: 14300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0475, train/total_loss: 0.0004, train/total_loss/avg: 0.0475, max mem: 19034.0, experiment: run, epoch: 108, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 775ms, time_since_start: 02h 17m 34s 077ms, eta: 01h 08m 16s 228ms
2023-04-25T01:16:50 | INFO | mmf.trainers.callbacks.logistics : progress: 14400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0471, train/total_loss: 0.0002, train/total_loss/avg: 0.0471, max mem: 19034.0, experiment: run, epoch: 109, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 523ms, time_since_start: 02h 18m 26s 601ms, eta: 01h 07m 03s 749ms
2023-04-25T01:17:42 | INFO | mmf.trainers.callbacks.logistics : progress: 14500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0468, train/total_loss: 0.0002, train/total_loss/avg: 0.0468, max mem: 19034.0, experiment: run, epoch: 110, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 657ms, time_since_start: 02h 19m 19s 258ms, eta: 01h 06m 20s 880ms
2023-04-25T01:18:34 | INFO | mmf.trainers.callbacks.logistics : progress: 14600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0465, train/total_loss: 0.0002, train/total_loss/avg: 0.0465, max mem: 19034.0, experiment: run, epoch: 110, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 840ms, time_since_start: 02h 20m 11s 099ms, eta: 01h 04m 26s 886ms
2023-04-25T01:19:27 | INFO | mmf.trainers.callbacks.logistics : progress: 14700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0462, train/total_loss: 0.0001, train/total_loss/avg: 0.0462, max mem: 19034.0, experiment: run, epoch: 111, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 741ms, time_since_start: 02h 21m 03s 840ms, eta: 01h 04m 40s 922ms
2023-04-25T01:20:20 | INFO | mmf.trainers.callbacks.logistics : progress: 14800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0459, train/total_loss: 0.0001, train/total_loss/avg: 0.0459, max mem: 19034.0, experiment: run, epoch: 112, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 671ms, time_since_start: 02h 21m 56s 511ms, eta: 01h 03m 42s 662ms
2023-04-25T01:21:12 | INFO | mmf.trainers.callbacks.logistics : progress: 14900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0456, train/total_loss: 0.0001, train/total_loss/avg: 0.0456, max mem: 19034.0, experiment: run, epoch: 113, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 728ms, time_since_start: 02h 22m 49s 240ms, eta: 01h 02m 53s 706ms
2023-04-25T01:22:04 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T01:22:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T01:22:47 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T01:22:57 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T01:22:57 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0453, train/total_loss: 0.0001, train/total_loss/avg: 0.0453, max mem: 19034.0, experiment: run, epoch: 113, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0.00002, ups: 0.96, time: 01m 44s 518ms, time_since_start: 02h 24m 33s 759ms, eta: 02h 02m 54s 819ms
2023-04-25T01:22:57 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T01:22:57 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T01:23:00 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T01:23:00 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T01:23:00 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, val/hateful_memes/cross_entropy: 3.9943, val/total_loss: 3.9943, val/hateful_memes/accuracy: 0.5780, val/hateful_memes/binary_f1: 0.4251, val/hateful_memes/roc_auc: 0.6244, num_updates: 15000, epoch: 113, iterations: 15000, max_updates: 22000, val_time: 03s 303ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T01:23:54 | INFO | mmf.trainers.callbacks.logistics : progress: 15100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0450, train/total_loss: 0.0001, train/total_loss/avg: 0.0450, max mem: 19034.0, experiment: run, epoch: 114, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0.00002, ups: 1.89, time: 53s 565ms, time_since_start: 02h 25m 30s 629ms, eta: 01h 02m 05s 587ms
2023-04-25T01:24:46 | INFO | mmf.trainers.callbacks.logistics : progress: 15200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0447, train/total_loss: 0.0001, train/total_loss/avg: 0.0447, max mem: 19034.0, experiment: run, epoch: 115, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 758ms, time_since_start: 02h 26m 23s 388ms, eta: 01h 16s 300ms
2023-04-25T01:25:39 | INFO | mmf.trainers.callbacks.logistics : progress: 15300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0447, train/total_loss: 0.0001, train/total_loss/avg: 0.0447, max mem: 19034.0, experiment: run, epoch: 116, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 622ms, time_since_start: 02h 27m 16s 011ms, eta: 59m 13s 922ms
2023-04-25T01:26:31 | INFO | mmf.trainers.callbacks.logistics : progress: 15400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0444, train/total_loss: 0.0001, train/total_loss/avg: 0.0444, max mem: 19034.0, experiment: run, epoch: 116, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 494ms, time_since_start: 02h 28m 07s 505ms, eta: 57m 05s 832ms
2023-04-25T01:27:23 | INFO | mmf.trainers.callbacks.logistics : progress: 15500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0441, train/total_loss: 0.0001, train/total_loss/avg: 0.0441, max mem: 19034.0, experiment: run, epoch: 117, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 600ms, time_since_start: 02h 29m 105ms, eta: 57m 26s 359ms
2023-04-25T01:28:16 | INFO | mmf.trainers.callbacks.logistics : progress: 15600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0438, train/total_loss: 0.0001, train/total_loss/avg: 0.0438, max mem: 19034.0, experiment: run, epoch: 118, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 668ms, time_since_start: 02h 29m 52s 774ms, eta: 56m 37s 736ms
2023-04-25T01:29:08 | INFO | mmf.trainers.callbacks.logistics : progress: 15700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0435, train/total_loss: 0.0001, train/total_loss/avg: 0.0435, max mem: 19034.0, experiment: run, epoch: 119, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 622ms, time_since_start: 02h 30m 45s 397ms, eta: 55m 41s 768ms
2023-04-25T01:30:00 | INFO | mmf.trainers.callbacks.logistics : progress: 15800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0433, train/total_loss: 0.0001, train/total_loss/avg: 0.0433, max mem: 19034.0, experiment: run, epoch: 119, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0.00002, ups: 1.96, time: 51s 760ms, time_since_start: 02h 31m 37s 158ms, eta: 53m 54s 855ms
2023-04-25T01:30:53 | INFO | mmf.trainers.callbacks.logistics : progress: 15900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0430, train/total_loss: 0.0001, train/total_loss/avg: 0.0430, max mem: 19034.0, experiment: run, epoch: 120, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0.00002, ups: 1.92, time: 52s 734ms, time_since_start: 02h 32m 29s 893ms, eta: 54m 02s 564ms
2023-04-25T01:31:46 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T01:31:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T01:32:06 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T01:32:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T01:32:13 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0427, train/total_loss: 0.0001, train/total_loss/avg: 0.0427, max mem: 19034.0, experiment: run, epoch: 121, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0.00002, ups: 1.27, time: 01m 19s 978ms, time_since_start: 02h 33m 49s 871ms, eta: 01h 20m 37s 072ms
2023-04-25T01:32:13 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T01:32:13 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T01:32:16 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T01:32:16 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T01:32:16 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, val/hateful_memes/cross_entropy: 3.8348, val/total_loss: 3.8348, val/hateful_memes/accuracy: 0.5840, val/hateful_memes/binary_f1: 0.4254, val/hateful_memes/roc_auc: 0.6254, num_updates: 16000, epoch: 121, iterations: 16000, max_updates: 22000, val_time: 03s 097ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T01:33:10 | INFO | mmf.trainers.callbacks.logistics : progress: 16100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0425, train/total_loss: 0.0001, train/total_loss/avg: 0.0425, max mem: 19034.0, experiment: run, epoch: 122, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 570ms, time_since_start: 02h 34m 46s 540ms, eta: 53m 05s 926ms
2023-04-25T01:34:01 | INFO | mmf.trainers.callbacks.logistics : progress: 16200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0422, train/total_loss: 0.0001, train/total_loss/avg: 0.0422, max mem: 19034.0, experiment: run, epoch: 122, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 804ms, time_since_start: 02h 35m 38s 345ms, eta: 50m 28s 696ms
2023-04-25T01:34:54 | INFO | mmf.trainers.callbacks.logistics : progress: 16300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0419, train/total_loss: 0.0001, train/total_loss/avg: 0.0419, max mem: 19034.0, experiment: run, epoch: 123, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 736ms, time_since_start: 02h 36m 31s 081ms, eta: 50m 30s 009ms
2023-04-25T01:35:47 | INFO | mmf.trainers.callbacks.logistics : progress: 16400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0417, train/total_loss: 0.0001, train/total_loss/avg: 0.0417, max mem: 19034.0, experiment: run, epoch: 124, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 532ms, time_since_start: 02h 37m 23s 614ms, eta: 49m 25s 351ms
2023-04-25T01:36:39 | INFO | mmf.trainers.callbacks.logistics : progress: 16500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0414, train/total_loss: 0.0001, train/total_loss/avg: 0.0414, max mem: 19034.0, experiment: run, epoch: 125, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 691ms, time_since_start: 02h 38m 16s 305ms, eta: 48m 41s 212ms
2023-04-25T01:37:31 | INFO | mmf.trainers.callbacks.logistics : progress: 16600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0412, train/total_loss: 0.0001, train/total_loss/avg: 0.0412, max mem: 19034.0, experiment: run, epoch: 125, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 754ms, time_since_start: 02h 39m 08s 060ms, eta: 46m 57s 103ms
2023-04-25T01:38:24 | INFO | mmf.trainers.callbacks.logistics : progress: 16700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0409, train/total_loss: 0.0001, train/total_loss/avg: 0.0409, max mem: 19034.0, experiment: run, epoch: 126, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 733ms, time_since_start: 02h 40m 793ms, eta: 46m 57s 248ms
2023-04-25T01:39:17 | INFO | mmf.trainers.callbacks.logistics : progress: 16800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0407, train/total_loss: 0.0001, train/total_loss/avg: 0.0407, max mem: 19034.0, experiment: run, epoch: 127, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 744ms, time_since_start: 02h 40m 53s 537ms, eta: 46m 04s 634ms
2023-04-25T01:40:09 | INFO | mmf.trainers.callbacks.logistics : progress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0405, train/total_loss: 0.0001, train/total_loss/avg: 0.0405, max mem: 19034.0, experiment: run, epoch: 128, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 642ms, time_since_start: 02h 41m 46s 180ms, eta: 45m 06s 267ms
2023-04-25T01:41:01 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T01:41:01 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T01:41:30 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T01:41:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T01:41:38 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0402, train/total_loss: 0.0001, train/total_loss/avg: 0.0402, max mem: 19034.0, experiment: run, epoch: 128, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0.00001, ups: 1.14, time: 01m 28s 594ms, time_since_start: 02h 43m 14s 775ms, eta: 01h 14m 25s 151ms
2023-04-25T01:41:38 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T01:41:38 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T01:41:41 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T01:41:41 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T01:41:41 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, val/hateful_memes/cross_entropy: 3.9001, val/total_loss: 3.9001, val/hateful_memes/accuracy: 0.5760, val/hateful_memes/binary_f1: 0.4111, val/hateful_memes/roc_auc: 0.6313, num_updates: 17000, epoch: 128, iterations: 17000, max_updates: 22000, val_time: 03s 523ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T01:42:35 | INFO | mmf.trainers.callbacks.logistics : progress: 17100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0400, train/total_loss: 0.0001, train/total_loss/avg: 0.0400, max mem: 19034.0, experiment: run, epoch: 129, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 507ms, time_since_start: 02h 44m 11s 808ms, eta: 44m 02s 826ms
2023-04-25T01:43:28 | INFO | mmf.trainers.callbacks.logistics : progress: 17200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0397, train/total_loss: 0.0001, train/total_loss/avg: 0.0397, max mem: 19034.0, experiment: run, epoch: 130, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 664ms, time_since_start: 02h 45m 04s 472ms, eta: 42m 28s 136ms
2023-04-25T01:44:20 | INFO | mmf.trainers.callbacks.logistics : progress: 17300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0395, train/total_loss: 0.0001, train/total_loss/avg: 0.0395, max mem: 19034.0, experiment: run, epoch: 131, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 670ms, time_since_start: 02h 45m 57s 143ms, eta: 41m 35s 339ms
2023-04-25T01:45:12 | INFO | mmf.trainers.callbacks.logistics : progress: 17400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0393, train/total_loss: 0.0001, train/total_loss/avg: 0.0393, max mem: 19034.0, experiment: run, epoch: 131, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 630ms, time_since_start: 02h 46m 48s 774ms, eta: 39m 54s 016ms
2023-04-25T01:46:04 | INFO | mmf.trainers.callbacks.logistics : progress: 17500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0391, train/total_loss: 0.0001, train/total_loss/avg: 0.0391, max mem: 19034.0, experiment: run, epoch: 132, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 563ms, time_since_start: 02h 47m 41s 338ms, eta: 39m 44s 279ms
2023-04-25T01:46:57 | INFO | mmf.trainers.callbacks.logistics : progress: 17600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0388, train/total_loss: 0.0001, train/total_loss/avg: 0.0388, max mem: 19034.0, experiment: run, epoch: 133, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 623ms, time_since_start: 02h 48m 33s 961ms, eta: 38m 53s 949ms
2023-04-25T01:47:50 | INFO | mmf.trainers.callbacks.logistics : progress: 17700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0386, train/total_loss: 0.0001, train/total_loss/avg: 0.0386, max mem: 19034.0, experiment: run, epoch: 134, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 646ms, time_since_start: 02h 49m 26s 607ms, eta: 38m 01s 901ms
2023-04-25T01:48:41 | INFO | mmf.trainers.callbacks.logistics : progress: 17800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0384, train/total_loss: 0.0000, train/total_loss/avg: 0.0384, max mem: 19034.0, experiment: run, epoch: 134, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 757ms, time_since_start: 02h 50m 18s 365ms, eta: 36m 31s 204ms
2023-04-25T01:49:34 | INFO | mmf.trainers.callbacks.logistics : progress: 17900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0382, train/total_loss: 0.0000, train/total_loss/avg: 0.0382, max mem: 19034.0, experiment: run, epoch: 135, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 662ms, time_since_start: 02h 51m 11s 028ms, eta: 36m 16s 451ms
2023-04-25T01:50:27 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T01:50:27 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T01:50:53 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T01:50:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T01:50:59 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0380, train/total_loss: 0.0000, train/total_loss/avg: 0.0380, max mem: 19034.0, experiment: run, epoch: 136, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0.00001, ups: 1.19, time: 01m 24s 671ms, time_since_start: 02h 52m 35s 699ms, eta: 56m 53s 963ms
2023-04-25T01:50:59 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T01:50:59 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T01:51:02 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T01:51:02 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T01:51:02 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, val/hateful_memes/cross_entropy: 4.0870, val/total_loss: 4.0870, val/hateful_memes/accuracy: 0.5680, val/hateful_memes/binary_f1: 0.3609, val/hateful_memes/roc_auc: 0.6056, num_updates: 18000, epoch: 136, iterations: 18000, max_updates: 22000, val_time: 03s 206ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T01:51:55 | INFO | mmf.trainers.callbacks.logistics : progress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0378, train/total_loss: 0.0000, train/total_loss/avg: 0.0378, max mem: 19034.0, experiment: run, epoch: 137, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 393ms, time_since_start: 02h 53m 32s 301ms, eta: 34m 58s 991ms
2023-04-25T01:52:47 | INFO | mmf.trainers.callbacks.logistics : progress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0376, train/total_loss: 0.0000, train/total_loss/avg: 0.0376, max mem: 19034.0, experiment: run, epoch: 137, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 884ms, time_since_start: 02h 54m 24s 186ms, eta: 33m 07s 378ms
2023-04-25T01:53:40 | INFO | mmf.trainers.callbacks.logistics : progress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0374, train/total_loss: 0.0000, train/total_loss/avg: 0.0374, max mem: 19034.0, experiment: run, epoch: 138, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 634ms, time_since_start: 02h 55m 16s 821ms, eta: 32m 43s 073ms
2023-04-25T01:54:32 | INFO | mmf.trainers.callbacks.logistics : progress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0372, train/total_loss: 0.0000, train/total_loss/avg: 0.0372, max mem: 19034.0, experiment: run, epoch: 139, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 606ms, time_since_start: 02h 56m 09s 427ms, eta: 31m 48s 991ms
2023-04-25T01:55:25 | INFO | mmf.trainers.callbacks.logistics : progress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0370, train/total_loss: 0.0000, train/total_loss/avg: 0.0370, max mem: 19034.0, experiment: run, epoch: 140, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 467ms, time_since_start: 02h 57m 01s 895ms, eta: 30m 51s 054ms
2023-04-25T01:56:17 | INFO | mmf.trainers.callbacks.logistics : progress: 18600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0368, train/total_loss: 0.0001, train/total_loss/avg: 0.0368, max mem: 19034.0, experiment: run, epoch: 140, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 771ms, time_since_start: 02h 57m 53s 667ms, eta: 29m 34s 327ms
2023-04-25T01:57:09 | INFO | mmf.trainers.callbacks.logistics : progress: 18700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0366, train/total_loss: 0.0001, train/total_loss/avg: 0.0366, max mem: 19034.0, experiment: run, epoch: 141, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 684ms, time_since_start: 02h 58m 46s 351ms, eta: 29m 12s 482ms
2023-04-25T01:58:02 | INFO | mmf.trainers.callbacks.logistics : progress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0364, train/total_loss: 0.0000, train/total_loss/avg: 0.0364, max mem: 19034.0, experiment: run, epoch: 142, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 697ms, time_since_start: 02h 59m 39s 048ms, eta: 28m 19s 804ms
2023-04-25T01:58:55 | INFO | mmf.trainers.callbacks.logistics : progress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0362, train/total_loss: 0.0000, train/total_loss/avg: 0.0362, max mem: 19034.0, experiment: run, epoch: 143, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 791ms, time_since_start: 03h 31s 840ms, eta: 27m 29s 629ms
2023-04-25T01:59:47 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T01:59:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T02:00:15 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T02:00:23 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T02:00:23 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0360, train/total_loss: 0.0000, train/total_loss/avg: 0.0360, max mem: 19034.0, experiment: run, epoch: 143, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0.00001, ups: 1.14, time: 01m 28s 209ms, time_since_start: 03h 02m 049ms, eta: 44m 27s 444ms
2023-04-25T02:00:23 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T02:00:23 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T02:00:26 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T02:00:26 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T02:00:26 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, val/hateful_memes/cross_entropy: 4.1043, val/total_loss: 4.1043, val/hateful_memes/accuracy: 0.5800, val/hateful_memes/binary_f1: 0.3966, val/hateful_memes/roc_auc: 0.6240, num_updates: 19000, epoch: 143, iterations: 19000, max_updates: 22000, val_time: 03s 111ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T02:01:20 | INFO | mmf.trainers.callbacks.logistics : progress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0358, train/total_loss: 0.0000, train/total_loss/avg: 0.0358, max mem: 19034.0, experiment: run, epoch: 144, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0.00001, ups: 1.89, time: 53s 304ms, time_since_start: 03h 02m 56s 467ms, eta: 25m 58s 211ms
2023-04-25T02:02:12 | INFO | mmf.trainers.callbacks.logistics : progress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0356, train/total_loss: 0.0000, train/total_loss/avg: 0.0356, max mem: 19034.0, experiment: run, epoch: 145, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 794ms, time_since_start: 03h 03m 49s 261ms, eta: 24m 50s 063ms
2023-04-25T02:03:05 | INFO | mmf.trainers.callbacks.logistics : progress: 19300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0354, train/total_loss: 0.0001, train/total_loss/avg: 0.0354, max mem: 19034.0, experiment: run, epoch: 146, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 681ms, time_since_start: 03h 04m 41s 943ms, eta: 23m 53s 783ms
2023-04-25T02:03:57 | INFO | mmf.trainers.callbacks.logistics : progress: 19400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0353, train/total_loss: 0.0001, train/total_loss/avg: 0.0353, max mem: 19034.0, experiment: run, epoch: 146, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 674ms, time_since_start: 03h 05m 33s 617ms, eta: 22m 34s 275ms
2023-04-25T02:04:49 | INFO | mmf.trainers.callbacks.logistics : progress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0351, train/total_loss: 0.0000, train/total_loss/avg: 0.0351, max mem: 19034.0, experiment: run, epoch: 147, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 520ms, time_since_start: 03h 06m 26s 137ms, eta: 22m 03s 520ms
2023-04-25T02:05:42 | INFO | mmf.trainers.callbacks.logistics : progress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0349, train/total_loss: 0.0000, train/total_loss/avg: 0.0349, max mem: 19034.0, experiment: run, epoch: 148, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 652ms, time_since_start: 03h 07m 18s 790ms, eta: 21m 13s 770ms
2023-04-25T02:06:35 | INFO | mmf.trainers.callbacks.logistics : progress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0347, train/total_loss: 0.0000, train/total_loss/avg: 0.0347, max mem: 19034.0, experiment: run, epoch: 149, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 748ms, time_since_start: 03h 08m 11s 539ms, eta: 20m 22s 925ms
2023-04-25T02:07:26 | INFO | mmf.trainers.callbacks.logistics : progress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0345, train/total_loss: 0.0000, train/total_loss/avg: 0.0345, max mem: 19034.0, experiment: run, epoch: 149, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0.00001, ups: 1.96, time: 51s 731ms, time_since_start: 03h 09m 03s 270ms, eta: 19m 07s 203ms
2023-04-25T02:08:19 | INFO | mmf.trainers.callbacks.logistics : progress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0344, train/total_loss: 0.0000, train/total_loss/avg: 0.0344, max mem: 19034.0, experiment: run, epoch: 150, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0.00001, ups: 1.92, time: 52s 672ms, time_since_start: 03h 09m 55s 943ms, eta: 18m 34s 970ms
2023-04-25T02:09:11 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T02:09:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T02:09:43 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T02:09:48 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T02:09:48 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0342, train/total_loss: 0.0000, train/total_loss/avg: 0.0342, max mem: 19034.0, experiment: run, epoch: 151, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0.00001, ups: 1.12, time: 01m 29s 323ms, time_since_start: 03h 11m 25s 266ms, eta: 30m 761ms
2023-04-25T02:09:48 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T02:09:48 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T02:09:51 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T02:09:51 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T02:09:51 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, val/hateful_memes/cross_entropy: 4.3284, val/total_loss: 4.3284, val/hateful_memes/accuracy: 0.5860, val/hateful_memes/binary_f1: 0.3930, val/hateful_memes/roc_auc: 0.6245, num_updates: 20000, epoch: 151, iterations: 20000, max_updates: 22000, val_time: 03s 072ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T02:10:45 | INFO | mmf.trainers.callbacks.logistics : progress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0340, train/total_loss: 0.0000, train/total_loss/avg: 0.0340, max mem: 19034.0, experiment: run, epoch: 152, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 1.89, time: 53s 569ms, time_since_start: 03h 12m 21s 911ms, eta: 17m 05s 973ms
2023-04-25T02:11:37 | INFO | mmf.trainers.callbacks.logistics : progress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0339, train/total_loss: 0.0000, train/total_loss/avg: 0.0339, max mem: 19034.0, experiment: run, epoch: 152, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 576ms, time_since_start: 03h 13m 13s 487ms, eta: 15m 35s 797ms
2023-04-25T02:12:29 | INFO | mmf.trainers.callbacks.logistics : progress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0337, train/total_loss: 0.0000, train/total_loss/avg: 0.0337, max mem: 19034.0, experiment: run, epoch: 153, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 561ms, time_since_start: 03h 14m 06s 049ms, eta: 15m 700ms
2023-04-25T02:13:22 | INFO | mmf.trainers.callbacks.logistics : progress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0335, train/total_loss: 0.0000, train/total_loss/avg: 0.0335, max mem: 19034.0, experiment: run, epoch: 154, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 570ms, time_since_start: 03h 14m 58s 620ms, eta: 14m 07s 862ms
2023-04-25T02:14:14 | INFO | mmf.trainers.callbacks.logistics : progress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0334, train/total_loss: 0.0000, train/total_loss/avg: 0.0334, max mem: 19034.0, experiment: run, epoch: 155, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 641ms, time_since_start: 03h 15m 51s 261ms, eta: 13m 15s 935ms
2023-04-25T02:15:06 | INFO | mmf.trainers.callbacks.logistics : progress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0332, train/total_loss: 0.0000, train/total_loss/avg: 0.0332, max mem: 19034.0, experiment: run, epoch: 155, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 675ms, time_since_start: 03h 16m 42s 937ms, eta: 12m 09s 252ms
2023-04-25T02:15:59 | INFO | mmf.trainers.callbacks.logistics : progress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0331, train/total_loss: 0.0000, train/total_loss/avg: 0.0331, max mem: 19034.0, experiment: run, epoch: 156, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 672ms, time_since_start: 03h 17m 35s 610ms, eta: 11m 30s 223ms
2023-04-25T02:16:52 | INFO | mmf.trainers.callbacks.logistics : progress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0329, train/total_loss: 0.0000, train/total_loss/avg: 0.0329, max mem: 19034.0, experiment: run, epoch: 157, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 830ms, time_since_start: 03h 18m 28s 440ms, eta: 10m 39s 034ms
2023-04-25T02:17:44 | INFO | mmf.trainers.callbacks.logistics : progress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0327, train/total_loss: 0.0000, train/total_loss/avg: 0.0327, max mem: 19034.0, experiment: run, epoch: 158, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 505ms, time_since_start: 03h 19m 20s 945ms, eta: 09m 42s 181ms
2023-04-25T02:18:36 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T02:18:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T02:19:15 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T02:19:20 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T02:19:20 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0326, train/total_loss: 0.0000, train/total_loss/avg: 0.0326, max mem: 19034.0, experiment: run, epoch: 158, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 1.04, time: 01m 36s 472ms, time_since_start: 03h 20m 57s 418ms, eta: 16m 12s 441ms
2023-04-25T02:19:20 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T02:19:20 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T02:19:24 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T02:19:24 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T02:19:24 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, val/hateful_memes/cross_entropy: 4.2643, val/total_loss: 4.2643, val/hateful_memes/accuracy: 0.5840, val/hateful_memes/binary_f1: 0.3918, val/hateful_memes/roc_auc: 0.6230, num_updates: 21000, epoch: 158, iterations: 21000, max_updates: 22000, val_time: 03s 237ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T02:20:17 | INFO | mmf.trainers.callbacks.logistics : progress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0324, train/total_loss: 0.0000, train/total_loss/avg: 0.0324, max mem: 19034.0, experiment: run, epoch: 159, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 1.89, time: 53s 421ms, time_since_start: 03h 21m 54s 079ms, eta: 08m 04s 642ms
2023-04-25T02:21:10 | INFO | mmf.trainers.callbacks.logistics : progress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0323, train/total_loss: 0.0000, train/total_loss/avg: 0.0323, max mem: 19034.0, experiment: run, epoch: 160, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 849ms, time_since_start: 03h 22m 46s 929ms, eta: 07m 06s 180ms
2023-04-25T02:22:03 | INFO | mmf.trainers.callbacks.logistics : progress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0321, train/total_loss: 0.0000, train/total_loss/avg: 0.0321, max mem: 19034.0, experiment: run, epoch: 161, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 646ms, time_since_start: 03h 23m 39s 575ms, eta: 06m 11s 472ms
2023-04-25T02:22:54 | INFO | mmf.trainers.callbacks.logistics : progress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0320, train/total_loss: 0.0000, train/total_loss/avg: 0.0320, max mem: 19034.0, experiment: run, epoch: 161, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 503ms, time_since_start: 03h 24m 31s 079ms, eta: 05m 11s 491ms
2023-04-25T02:23:47 | INFO | mmf.trainers.callbacks.logistics : progress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0318, train/total_loss: 0.0000, train/total_loss/avg: 0.0318, max mem: 19034.0, experiment: run, epoch: 162, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 639ms, time_since_start: 03h 25m 23s 718ms, eta: 04m 25s 302ms
2023-04-25T02:24:39 | INFO | mmf.trainers.callbacks.logistics : progress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0317, train/total_loss: 0.0000, train/total_loss/avg: 0.0317, max mem: 19034.0, experiment: run, epoch: 163, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 645ms, time_since_start: 03h 26m 16s 364ms, eta: 03m 32s 267ms
2023-04-25T02:25:32 | INFO | mmf.trainers.callbacks.logistics : progress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0315, train/total_loss: 0.0000, train/total_loss/avg: 0.0315, max mem: 19034.0, experiment: run, epoch: 164, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 631ms, time_since_start: 03h 27m 08s 996ms, eta: 02m 39s 159ms
2023-04-25T02:26:24 | INFO | mmf.trainers.callbacks.logistics : progress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0314, train/total_loss: 0.0000, train/total_loss/avg: 0.0314, max mem: 19034.0, experiment: run, epoch: 164, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 1.96, time: 51s 727ms, time_since_start: 03h 28m 724ms, eta: 01m 44s 283ms
2023-04-25T02:27:16 | INFO | mmf.trainers.callbacks.logistics : progress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0312, train/total_loss: 0.0000, train/total_loss/avg: 0.0312, max mem: 19034.0, experiment: run, epoch: 165, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 1.92, time: 52s 574ms, time_since_start: 03h 28m 53s 299ms, eta: 52s 995ms
2023-04-25T02:28:09 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T02:28:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T02:28:25 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T02:28:32 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T02:28:32 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0311, train/total_loss: 0.0000, train/total_loss/avg: 0.0311, max mem: 19034.0, experiment: run, epoch: 166, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 1.33, time: 01m 15s 903ms, time_since_start: 03h 30m 09s 203ms, eta: 0ms
2023-04-25T02:28:32 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T02:28:32 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T02:28:35 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T02:28:35 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T02:28:35 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, val/hateful_memes/cross_entropy: 4.1010, val/total_loss: 4.1010, val/hateful_memes/accuracy: 0.5940, val/hateful_memes/binary_f1: 0.4282, val/hateful_memes/roc_auc: 0.6254, num_updates: 22000, epoch: 166, iterations: 22000, max_updates: 22000, val_time: 03s 095ms, best_update: 8000, best_iteration: 8000, best_val/hateful_memes/roc_auc: 0.665776
2023-04-25T02:28:36 | INFO | mmf.trainers.core.training_loop : Stepping into final validation check
2023-04-25T02:28:36 | INFO | mmf.utils.checkpoint : Restoring checkpoint
2023-04-25T02:28:36 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-25T02:28:56 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-25T02:28:56 | INFO | mmf.utils.checkpoint : Current num updates: 8000
2023-04-25T02:28:56 | INFO | mmf.utils.checkpoint : Current iteration: 8000
2023-04-25T02:28:56 | INFO | mmf.utils.checkpoint : Current epoch: 61
2023-04-25T02:29:14 | INFO | mmf.trainers.mmf_trainer : Starting inference on val set
2023-04-25T02:29:14 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T02:29:17 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T02:29:17 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T02:29:18 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, val/hateful_memes/cross_entropy: 2.6853, val/total_loss: 2.6853, val/hateful_memes/accuracy: 0.6160, val/hateful_memes/binary_f1: 0.5102, val/hateful_memes/roc_auc: 0.6658
2023-04-25T02:29:18 | INFO | mmf.trainers.callbacks.logistics : Finished run in 03h 30m 54s 619ms
2023-04-25T02:29:34 | INFO | mmf : Logging to: ./save/train.log
2023-04-25T02:29:34 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-25T02:29:34 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-25T02:29:34 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-25T02:29:34 | INFO | mmf_cli.run : Using seed 34209704
2023-04-25T02:29:34 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-25T02:30:32 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T02:30:32 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T02:30:32 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T02:30:32 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-25T02:30:32 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpwwu2bh6x
2023-04-25T02:30:32 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpwwu2bh6x/_remote_module_non_scriptable.py
2023-04-25T02:30:32 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T02:30:32 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T02:30:32 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T02:30:32 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T02:31:00 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-25T02:31:00 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-25T02:31:00 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-25T02:31:01 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-25T02:31:01 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-25T02:31:02 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T02:31:02 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T02:31:02 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T02:31:02 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T02:31:02 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-25T02:31:02 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-25T02:31:02 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-25T02:31:02 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-25T02:31:02 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-25T02:31:02 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T02:31:08 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_34209704/reports/hateful_memes_run_test_2023-04-25T02:31:08.csv
2023-04-25T02:31:08 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 16
2023-04-25T02:31:08 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T02:31:19 | INFO | mmf : Logging to: ./save/train.log
2023-04-25T02:31:19 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])
2023-04-25T02:31:19 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-25T02:31:19 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-25T02:31:19 | INFO | mmf_cli.run : Using seed 19462401
2023-04-25T02:31:19 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-25T02:32:21 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T02:32:21 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T02:32:21 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T02:32:21 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-25T02:32:21 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpg74bfrct
2023-04-25T02:32:21 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpg74bfrct/_remote_module_non_scriptable.py
2023-04-25T02:32:21 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T02:32:21 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T02:32:21 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T02:32:21 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T02:32:46 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-25T02:32:46 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-25T02:32:46 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-25T02:32:47 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-25T02:32:47 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-25T02:32:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T02:32:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T02:32:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T02:32:47 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T02:32:47 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-25T02:32:47 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-25T02:32:47 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-25T02:32:47 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-25T02:32:47 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-25T02:32:47 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T02:32:52 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_19462401/reports/hateful_memes_run_test_2023-04-25T02:32:52.csv
2023-04-25T02:32:52 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 8
2023-04-25T02:32:52 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T04:07:52 | INFO | mmf : Logging to: ./save/train.log
2023-04-25T04:07:52 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'run_type=train_val', 'dataset=hateful_memes', 'training.num_workers=0', 'checkpoint.max_to_keep=1', 'dataset_config.hateful_memes.annotations.train[0]=hateful_memes/defaults/annotations/train.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.features.train[0]=/content/gdrive/MyDrive/vmb_x_152_detectron_100/', 'dataset_config.hateful_memes.features.val[0]=/content/gdrive/MyDrive/vmb_x_152_detectron_100/', 'dataset_config.hateful_memes.features.test[0]=/content/gdrive/MyDrive/vmb_x_152_detectron_100/'])
2023-04-25T04:07:52 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-25T04:07:52 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-25T04:07:52 | INFO | mmf_cli.run : Using seed 51691988
2023-04-25T04:07:52 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-25T04:08:11 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T04:08:11 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T04:08:11 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T04:08:11 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T04:08:11 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T04:08:11 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T04:08:11 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-25T04:08:11 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpna8_iem9
2023-04-25T04:08:11 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpna8_iem9/_remote_module_non_scriptable.py
2023-04-25T04:08:11 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T04:08:11 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T04:08:11 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T04:08:11 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T04:08:32 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-25T04:08:32 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-25T04:08:32 | INFO | mmf.trainers.mmf_trainer : ===== Model =====
2023-04-25T04:08:32 | INFO | mmf.trainers.mmf_trainer : ConcatBERTEx(
  (vision_module): ResNet152ImageEncoder(
    (model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
    )
    (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (language_module): BertModelJit(
    (embeddings): BertEmbeddingsJit(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoderJit(
      (layer): ModuleList(
        (0-11): 12 x BertLayerJit(
          (attention): BertAttentionJit(
            (self): BertSelfAttentionJit(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (classifier): MLPClassifer(
    (layers): ModuleList(
      (0): Linear(in_features=2816, out_features=768, bias=True)
      (1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=768, out_features=768, bias=True)
      (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=768, out_features=2, bias=True)
    )
  )
  (losses): Losses(
    (losses): ModuleList(
      (0): MMFLoss(
        (loss_criterion): CrossEntropyLoss(
          (loss_fn): CrossEntropyLoss()
        )
      )
    )
  )
)
2023-04-25T04:08:32 | INFO | mmf.utils.general : Total Parameters: 170384706. Trained Parameters: 170384706
2023-04-25T04:08:32 | INFO | mmf.trainers.core.training_loop : Starting training...
2023-04-25T04:11:07 | INFO | mmf.trainers.callbacks.logistics : progress: 100/22000, train/hateful_memes/cross_entropy: 0.6984, train/hateful_memes/cross_entropy/avg: 0.6984, train/total_loss: 0.6984, train/total_loss/avg: 0.6984, max mem: 19030.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 22000, lr: 0., ups: 0.65, time: 02m 34s 320ms, time_since_start: 02m 34s 398ms, eta: 09h 27m 46s 537ms
2023-04-25T04:13:33 | INFO | mmf.trainers.callbacks.logistics : progress: 200/22000, train/hateful_memes/cross_entropy: 0.6551, train/hateful_memes/cross_entropy/avg: 0.6767, train/total_loss: 0.6551, train/total_loss/avg: 0.6767, max mem: 19030.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 878ms, time_since_start: 05m 276ms, eta: 08h 54m 15s 831ms
2023-04-25T04:15:57 | INFO | mmf.trainers.callbacks.logistics : progress: 300/22000, train/hateful_memes/cross_entropy: 0.6984, train/hateful_memes/cross_entropy/avg: 0.6846, train/total_loss: 0.6984, train/total_loss/avg: 0.6846, max mem: 19030.0, experiment: run, epoch: 3, num_updates: 300, iterations: 300, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 843ms, time_since_start: 07m 25s 120ms, eta: 08h 48m 02s 556ms
2023-04-25T04:18:23 | INFO | mmf.trainers.callbacks.logistics : progress: 400/22000, train/hateful_memes/cross_entropy: 0.6551, train/hateful_memes/cross_entropy/avg: 0.6419, train/total_loss: 0.6551, train/total_loss/avg: 0.6419, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 400, iterations: 400, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 392ms, time_since_start: 09m 50s 512ms, eta: 08h 47m 35s 979ms
2023-04-25T04:20:48 | INFO | mmf.trainers.callbacks.logistics : progress: 500/22000, train/hateful_memes/cross_entropy: 0.6984, train/hateful_memes/cross_entropy/avg: 0.6533, train/total_loss: 0.6984, train/total_loss/avg: 0.6533, max mem: 19030.0, experiment: run, epoch: 4, num_updates: 500, iterations: 500, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 450ms, time_since_start: 12m 15s 963ms, eta: 08h 45m 22s 007ms
2023-04-25T04:23:14 | INFO | mmf.trainers.callbacks.logistics : progress: 600/22000, train/hateful_memes/cross_entropy: 0.6551, train/hateful_memes/cross_entropy/avg: 0.6292, train/total_loss: 0.6551, train/total_loss/avg: 0.6292, max mem: 19030.0, experiment: run, epoch: 5, num_updates: 600, iterations: 600, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 202ms, time_since_start: 14m 41s 165ms, eta: 08h 42m 01s 983ms
2023-04-25T04:25:39 | INFO | mmf.trainers.callbacks.logistics : progress: 700/22000, train/hateful_memes/cross_entropy: 0.6551, train/hateful_memes/cross_entropy/avg: 0.5899, train/total_loss: 0.6551, train/total_loss/avg: 0.5899, max mem: 19030.0, experiment: run, epoch: 6, num_updates: 700, iterations: 700, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 062ms, time_since_start: 17m 06s 228ms, eta: 08h 39m 05s 444ms
2023-04-25T04:28:04 | INFO | mmf.trainers.callbacks.logistics : progress: 800/22000, train/hateful_memes/cross_entropy: 0.5139, train/hateful_memes/cross_entropy/avg: 0.5575, train/total_loss: 0.5139, train/total_loss/avg: 0.5575, max mem: 19030.0, experiment: run, epoch: 7, num_updates: 800, iterations: 800, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 217ms, time_since_start: 19m 31s 445ms, eta: 08h 37m 12s 380ms
2023-04-25T04:30:29 | INFO | mmf.trainers.callbacks.logistics : progress: 900/22000, train/hateful_memes/cross_entropy: 0.5139, train/hateful_memes/cross_entropy/avg: 0.5303, train/total_loss: 0.5139, train/total_loss/avg: 0.5303, max mem: 19030.0, experiment: run, epoch: 7, num_updates: 900, iterations: 900, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 436ms, time_since_start: 21m 56s 882ms, eta: 08h 35m 32s 685ms
2023-04-25T04:32:54 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T04:32:54 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T04:33:17 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T04:33:49 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T04:33:49 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, train/hateful_memes/cross_entropy: 0.5091, train/hateful_memes/cross_entropy/avg: 0.4884, train/total_loss: 0.5091, train/total_loss/avg: 0.4884, max mem: 19030.0, experiment: run, epoch: 8, num_updates: 1000, iterations: 1000, max_updates: 22000, lr: 0.00003, ups: 0.50, time: 03m 19s 649ms, time_since_start: 25m 16s 531ms, eta: 11h 44m 21s 757ms
2023-04-25T04:33:49 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T04:33:51 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T04:33:51 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T04:33:59 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T04:33:59 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T04:33:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T04:34:05 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-25T04:34:30 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T04:34:36 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T04:34:36 | INFO | mmf.trainers.callbacks.logistics : progress: 1000/22000, val/hateful_memes/cross_entropy: 1.1650, val/total_loss: 1.1650, val/hateful_memes/accuracy: 0.6020, val/hateful_memes/binary_f1: 0.5228, val/hateful_memes/roc_auc: 0.6313, num_updates: 1000, epoch: 8, iterations: 1000, max_updates: 22000, val_time: 47s 213ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.631307
2023-04-25T04:37:03 | INFO | mmf.trainers.callbacks.logistics : progress: 1100/22000, train/hateful_memes/cross_entropy: 0.5091, train/hateful_memes/cross_entropy/avg: 0.4504, train/total_loss: 0.5091, train/total_loss/avg: 0.4504, max mem: 19033.0, experiment: run, epoch: 9, num_updates: 1100, iterations: 1100, max_updates: 22000, lr: 0.00003, ups: 0.68, time: 02m 27s 249ms, time_since_start: 28m 30s 996ms, eta: 08h 37m 01s 324ms
2023-04-25T04:39:29 | INFO | mmf.trainers.callbacks.logistics : progress: 1200/22000, train/hateful_memes/cross_entropy: 0.3541, train/hateful_memes/cross_entropy/avg: 0.4147, train/total_loss: 0.3541, train/total_loss/avg: 0.4147, max mem: 19033.0, experiment: run, epoch: 10, num_updates: 1200, iterations: 1200, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 423ms, time_since_start: 30m 56s 420ms, eta: 08h 28m 10s 031ms
2023-04-25T04:41:55 | INFO | mmf.trainers.callbacks.logistics : progress: 1300/22000, train/hateful_memes/cross_entropy: 0.3541, train/hateful_memes/cross_entropy/avg: 0.3842, train/total_loss: 0.3541, train/total_loss/avg: 0.3842, max mem: 19033.0, experiment: run, epoch: 10, num_updates: 1300, iterations: 1300, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 774ms, time_since_start: 33m 22s 194ms, eta: 08h 26m 56s 677ms
2023-04-25T04:44:20 | INFO | mmf.trainers.callbacks.logistics : progress: 1400/22000, train/hateful_memes/cross_entropy: 0.3302, train/hateful_memes/cross_entropy/avg: 0.3635, train/total_loss: 0.3302, train/total_loss/avg: 0.3635, max mem: 19033.0, experiment: run, epoch: 11, num_updates: 1400, iterations: 1400, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 256ms, time_since_start: 35m 47s 451ms, eta: 08h 22m 42s 317ms
2023-04-25T04:46:45 | INFO | mmf.trainers.callbacks.logistics : progress: 1500/22000, train/hateful_memes/cross_entropy: 0.3302, train/hateful_memes/cross_entropy/avg: 0.3402, train/total_loss: 0.3302, train/total_loss/avg: 0.3402, max mem: 19033.0, experiment: run, epoch: 12, num_updates: 1500, iterations: 1500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 988ms, time_since_start: 38m 12s 440ms, eta: 08h 19m 20s 498ms
2023-04-25T04:49:11 | INFO | mmf.trainers.callbacks.logistics : progress: 1600/22000, train/hateful_memes/cross_entropy: 0.3133, train/hateful_memes/cross_entropy/avg: 0.3213, train/total_loss: 0.3133, train/total_loss/avg: 0.3213, max mem: 19033.0, experiment: run, epoch: 13, num_updates: 1600, iterations: 1600, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 26s 046ms, time_since_start: 40m 38s 487ms, eta: 08h 20m 31s 895ms
2023-04-25T04:51:36 | INFO | mmf.trainers.callbacks.logistics : progress: 1700/22000, train/hateful_memes/cross_entropy: 0.3133, train/hateful_memes/cross_entropy/avg: 0.3096, train/total_loss: 0.3133, train/total_loss/avg: 0.3096, max mem: 19033.0, experiment: run, epoch: 13, num_updates: 1700, iterations: 1700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 267ms, time_since_start: 43m 03s 754ms, eta: 08h 15m 25s 120ms
2023-04-25T04:54:02 | INFO | mmf.trainers.callbacks.logistics : progress: 1800/22000, train/hateful_memes/cross_entropy: 0.1220, train/hateful_memes/cross_entropy/avg: 0.2951, train/total_loss: 0.1220, train/total_loss/avg: 0.2951, max mem: 19033.0, experiment: run, epoch: 14, num_updates: 1800, iterations: 1800, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 573ms, time_since_start: 45m 29s 327ms, eta: 08h 14m 01s 070ms
2023-04-25T04:56:27 | INFO | mmf.trainers.callbacks.logistics : progress: 1900/22000, train/hateful_memes/cross_entropy: 0.1220, train/hateful_memes/cross_entropy/avg: 0.2803, train/total_loss: 0.1220, train/total_loss/avg: 0.2803, max mem: 19033.0, experiment: run, epoch: 15, num_updates: 1900, iterations: 1900, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 530ms, time_since_start: 47m 54s 857ms, eta: 08h 11m 25s 563ms
2023-04-25T04:58:52 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T04:58:52 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T04:59:44 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T04:59:50 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T04:59:50 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, train/hateful_memes/cross_entropy: 0.1108, train/hateful_memes/cross_entropy/avg: 0.2675, train/total_loss: 0.1108, train/total_loss/avg: 0.2675, max mem: 19033.0, experiment: run, epoch: 16, num_updates: 2000, iterations: 2000, max_updates: 22000, lr: 0.00005, ups: 0.50, time: 03m 22s 941ms, time_since_start: 51m 17s 798ms, eta: 11h 21m 52s 939ms
2023-04-25T04:59:50 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T04:59:50 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T04:59:50 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T04:59:59 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T04:59:59 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T04:59:59 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T05:00:04 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-25T05:00:12 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T05:00:20 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T05:00:20 | INFO | mmf.trainers.callbacks.logistics : progress: 2000/22000, val/hateful_memes/cross_entropy: 1.6289, val/total_loss: 1.6289, val/hateful_memes/accuracy: 0.6000, val/hateful_memes/binary_f1: 0.4924, val/hateful_memes/roc_auc: 0.6400, num_updates: 2000, epoch: 16, iterations: 2000, max_updates: 22000, val_time: 29s 552ms, best_update: 2000, best_iteration: 2000, best_val/hateful_memes/roc_auc: 0.640012
2023-04-25T05:02:48 | INFO | mmf.trainers.callbacks.logistics : progress: 2100/22000, train/hateful_memes/cross_entropy: 0.0941, train/hateful_memes/cross_entropy/avg: 0.2560, train/total_loss: 0.0941, train/total_loss/avg: 0.2560, max mem: 19033.0, experiment: run, epoch: 16, num_updates: 2100, iterations: 2100, max_updates: 22000, lr: 0.00005, ups: 0.68, time: 02m 28s 576ms, time_since_start: 54m 15s 930ms, eta: 08h 16m 43s 271ms
2023-04-25T05:05:13 | INFO | mmf.trainers.callbacks.logistics : progress: 2200/22000, train/hateful_memes/cross_entropy: 0.0710, train/hateful_memes/cross_entropy/avg: 0.2447, train/total_loss: 0.0710, train/total_loss/avg: 0.2447, max mem: 19033.0, experiment: run, epoch: 17, num_updates: 2200, iterations: 2200, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 24s 984ms, time_since_start: 56m 40s 915ms, eta: 08h 02m 16s 658ms
2023-04-25T05:07:39 | INFO | mmf.trainers.callbacks.logistics : progress: 2300/22000, train/hateful_memes/cross_entropy: 0.0492, train/hateful_memes/cross_entropy/avg: 0.2344, train/total_loss: 0.0492, train/total_loss/avg: 0.2344, max mem: 19033.0, experiment: run, epoch: 18, num_updates: 2300, iterations: 2300, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 712ms, time_since_start: 59m 06s 627ms, eta: 08h 02m 15s 008ms
2023-04-25T05:10:04 | INFO | mmf.trainers.callbacks.logistics : progress: 2400/22000, train/hateful_memes/cross_entropy: 0.0377, train/hateful_memes/cross_entropy/avg: 0.2252, train/total_loss: 0.0377, train/total_loss/avg: 0.2252, max mem: 19033.0, experiment: run, epoch: 19, num_updates: 2400, iterations: 2400, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 24s 815ms, time_since_start: 01h 01m 31s 443ms, eta: 07h 56m 50s 915ms
2023-04-25T05:12:30 | INFO | mmf.trainers.callbacks.logistics : progress: 2500/22000, train/hateful_memes/cross_entropy: 0.0377, train/hateful_memes/cross_entropy/avg: 0.2178, train/total_loss: 0.0377, train/total_loss/avg: 0.2178, max mem: 19033.0, experiment: run, epoch: 19, num_updates: 2500, iterations: 2500, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 945ms, time_since_start: 01h 03m 57s 388ms, eta: 07h 58m 06s 997ms
2023-04-25T05:14:55 | INFO | mmf.trainers.callbacks.logistics : progress: 2600/22000, train/hateful_memes/cross_entropy: 0.0267, train/hateful_memes/cross_entropy/avg: 0.2097, train/total_loss: 0.0267, train/total_loss/avg: 0.2097, max mem: 19033.0, experiment: run, epoch: 20, num_updates: 2600, iterations: 2600, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 24s 801ms, time_since_start: 01h 06m 22s 190ms, eta: 07h 51m 56s 273ms
2023-04-25T05:17:20 | INFO | mmf.trainers.callbacks.logistics : progress: 2700/22000, train/hateful_memes/cross_entropy: 0.0239, train/hateful_memes/cross_entropy/avg: 0.2025, train/total_loss: 0.0239, train/total_loss/avg: 0.2025, max mem: 19033.0, experiment: run, epoch: 21, num_updates: 2700, iterations: 2700, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 006ms, time_since_start: 01h 08m 47s 197ms, eta: 07h 50m 10s 199ms
2023-04-25T05:19:45 | INFO | mmf.trainers.callbacks.logistics : progress: 2800/22000, train/hateful_memes/cross_entropy: 0.0239, train/hateful_memes/cross_entropy/avg: 0.1970, train/total_loss: 0.0239, train/total_loss/avg: 0.1970, max mem: 19033.0, experiment: run, epoch: 22, num_updates: 2800, iterations: 2800, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 024ms, time_since_start: 01h 11m 12s 222ms, eta: 07h 47m 47s 506ms
2023-04-25T05:22:10 | INFO | mmf.trainers.callbacks.logistics : progress: 2900/22000, train/hateful_memes/cross_entropy: 0.0239, train/hateful_memes/cross_entropy/avg: 0.1912, train/total_loss: 0.0239, train/total_loss/avg: 0.1912, max mem: 19033.0, experiment: run, epoch: 22, num_updates: 2900, iterations: 2900, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 479ms, time_since_start: 01h 13m 37s 701ms, eta: 07h 46m 48s 874ms
2023-04-25T05:24:35 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T05:24:35 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T05:25:24 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T05:25:31 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T05:25:31 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, train/hateful_memes/cross_entropy: 0.0239, train/hateful_memes/cross_entropy/avg: 0.1865, train/total_loss: 0.0239, train/total_loss/avg: 0.1865, max mem: 19033.0, experiment: run, epoch: 23, num_updates: 3000, iterations: 3000, max_updates: 22000, lr: 0.00005, ups: 0.50, time: 03m 20s 772ms, time_since_start: 01h 16m 58s 473ms, eta: 10h 40m 51s 891ms
2023-04-25T05:25:31 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T05:25:31 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T05:25:31 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T05:25:39 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T05:25:39 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T05:25:39 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T05:25:45 | INFO | mmf.utils.checkpoint : Saving best checkpoint
2023-04-25T05:25:51 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T05:25:58 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T05:25:58 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, val/hateful_memes/cross_entropy: 2.2826, val/total_loss: 2.2826, val/hateful_memes/accuracy: 0.5860, val/hateful_memes/binary_f1: 0.4298, val/hateful_memes/roc_auc: 0.6510, num_updates: 3000, epoch: 23, iterations: 3000, max_updates: 22000, val_time: 27s 232ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T05:28:26 | INFO | mmf.trainers.callbacks.logistics : progress: 3100/22000, train/hateful_memes/cross_entropy: 0.0216, train/hateful_memes/cross_entropy/avg: 0.1808, train/total_loss: 0.0216, train/total_loss/avg: 0.1808, max mem: 19033.0, experiment: run, epoch: 24, num_updates: 3100, iterations: 3100, max_updates: 22000, lr: 0.00005, ups: 0.68, time: 02m 27s 540ms, time_since_start: 01h 19m 53s 249ms, eta: 07h 48m 28s 332ms
2023-04-25T05:30:51 | INFO | mmf.trainers.callbacks.logistics : progress: 3200/22000, train/hateful_memes/cross_entropy: 0.0239, train/hateful_memes/cross_entropy/avg: 0.1763, train/total_loss: 0.0239, train/total_loss/avg: 0.1763, max mem: 19033.0, experiment: run, epoch: 25, num_updates: 3200, iterations: 3200, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 227ms, time_since_start: 01h 22m 18s 476ms, eta: 07h 38m 41s 119ms
2023-04-25T05:33:16 | INFO | mmf.trainers.callbacks.logistics : progress: 3300/22000, train/hateful_memes/cross_entropy: 0.0239, train/hateful_memes/cross_entropy/avg: 0.1710, train/total_loss: 0.0239, train/total_loss/avg: 0.1710, max mem: 19033.0, experiment: run, epoch: 25, num_updates: 3300, iterations: 3300, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 208ms, time_since_start: 01h 24m 43s 684ms, eta: 07h 36m 11s 183ms
2023-04-25T05:35:41 | INFO | mmf.trainers.callbacks.logistics : progress: 3400/22000, train/hateful_memes/cross_entropy: 0.0149, train/hateful_memes/cross_entropy/avg: 0.1661, train/total_loss: 0.0149, train/total_loss/avg: 0.1661, max mem: 19033.0, experiment: run, epoch: 26, num_updates: 3400, iterations: 3400, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 031ms, time_since_start: 01h 27m 08s 715ms, eta: 07h 33m 11s 624ms
2023-04-25T05:38:07 | INFO | mmf.trainers.callbacks.logistics : progress: 3500/22000, train/hateful_memes/cross_entropy: 0.0239, train/hateful_memes/cross_entropy/avg: 0.1622, train/total_loss: 0.0239, train/total_loss/avg: 0.1622, max mem: 19033.0, experiment: run, epoch: 27, num_updates: 3500, iterations: 3500, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 475ms, time_since_start: 01h 29m 34s 191ms, eta: 07h 32m 08s 206ms
2023-04-25T05:40:32 | INFO | mmf.trainers.callbacks.logistics : progress: 3600/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1578, train/total_loss: 0.0146, train/total_loss/avg: 0.1578, max mem: 19033.0, experiment: run, epoch: 28, num_updates: 3600, iterations: 3600, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 409ms, time_since_start: 01h 31m 59s 600ms, eta: 07h 29m 29s 338ms
2023-04-25T05:42:57 | INFO | mmf.trainers.callbacks.logistics : progress: 3700/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1550, train/total_loss: 0.0146, train/total_loss/avg: 0.1550, max mem: 19033.0, experiment: run, epoch: 28, num_updates: 3700, iterations: 3700, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 509ms, time_since_start: 01h 34m 25s 110ms, eta: 07h 27m 21s 336ms
2023-04-25T05:45:22 | INFO | mmf.trainers.callbacks.logistics : progress: 3800/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1518, train/total_loss: 0.0146, train/total_loss/avg: 0.1518, max mem: 19033.0, experiment: run, epoch: 29, num_updates: 3800, iterations: 3800, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 24s 914ms, time_since_start: 01h 36m 50s 024ms, eta: 07h 23m 05s 394ms
2023-04-25T05:47:48 | INFO | mmf.trainers.callbacks.logistics : progress: 3900/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1480, train/total_loss: 0.0146, train/total_loss/avg: 0.1480, max mem: 19033.0, experiment: run, epoch: 30, num_updates: 3900, iterations: 3900, max_updates: 22000, lr: 0.00005, ups: 0.69, time: 02m 25s 173ms, time_since_start: 01h 39m 15s 197ms, eta: 07h 21m 26s 586ms
2023-04-25T05:50:13 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T05:50:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T05:50:39 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T05:50:45 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T05:50:45 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1448, train/total_loss: 0.0146, train/total_loss/avg: 0.1448, max mem: 19033.0, experiment: run, epoch: 31, num_updates: 4000, iterations: 4000, max_updates: 22000, lr: 0.00005, ups: 0.56, time: 02m 57s 629ms, time_since_start: 01h 42m 12s 827ms, eta: 08h 57m 09s 156ms
2023-04-25T05:50:45 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T05:50:45 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T05:50:45 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T05:50:53 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T05:50:53 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T05:50:53 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T05:50:59 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T05:51:06 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T05:51:06 | INFO | mmf.trainers.callbacks.logistics : progress: 4000/22000, val/hateful_memes/cross_entropy: 2.2254, val/total_loss: 2.2254, val/hateful_memes/accuracy: 0.5640, val/hateful_memes/binary_f1: 0.4076, val/hateful_memes/roc_auc: 0.6022, num_updates: 4000, epoch: 31, iterations: 4000, max_updates: 22000, val_time: 20s 463ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T05:53:34 | INFO | mmf.trainers.callbacks.logistics : progress: 4100/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1421, train/total_loss: 0.0146, train/total_loss/avg: 0.1421, max mem: 19033.0, experiment: run, epoch: 31, num_updates: 4100, iterations: 4100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 28s 448ms, time_since_start: 01h 45m 01s 741ms, eta: 07h 26m 24s 933ms
2023-04-25T05:55:59 | INFO | mmf.trainers.callbacks.logistics : progress: 4200/22000, train/hateful_memes/cross_entropy: 0.0146, train/hateful_memes/cross_entropy/avg: 0.1388, train/total_loss: 0.0146, train/total_loss/avg: 0.1388, max mem: 19033.0, experiment: run, epoch: 32, num_updates: 4200, iterations: 4200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 668ms, time_since_start: 01h 47m 26s 410ms, eta: 07h 12m 37s 066ms
2023-04-25T05:58:25 | INFO | mmf.trainers.callbacks.logistics : progress: 4300/22000, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1370, train/total_loss: 0.0209, train/total_loss/avg: 0.1370, max mem: 19033.0, experiment: run, epoch: 33, num_updates: 4300, iterations: 4300, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 922ms, time_since_start: 01h 49m 52s 332ms, eta: 07h 13m 54s 832ms
2023-04-25T06:00:50 | INFO | mmf.trainers.callbacks.logistics : progress: 4400/22000, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1339, train/total_loss: 0.0209, train/total_loss/avg: 0.1339, max mem: 19033.0, experiment: run, epoch: 34, num_updates: 4400, iterations: 4400, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 561ms, time_since_start: 01h 52m 17s 894ms, eta: 07h 10m 23s 787ms
2023-04-25T06:03:16 | INFO | mmf.trainers.callbacks.logistics : progress: 4500/22000, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1315, train/total_loss: 0.0209, train/total_loss/avg: 0.1315, max mem: 19033.0, experiment: run, epoch: 34, num_updates: 4500, iterations: 4500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 673ms, time_since_start: 01h 54m 43s 568ms, eta: 07h 08m 16s 893ms
2023-04-25T06:05:40 | INFO | mmf.trainers.callbacks.logistics : progress: 4600/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.1295, train/total_loss: 0.0244, train/total_loss/avg: 0.1295, max mem: 19033.0, experiment: run, epoch: 35, num_updates: 4600, iterations: 4600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 454ms, time_since_start: 01h 57m 08s 022ms, eta: 07h 02m 16s 115ms
2023-04-25T06:08:06 | INFO | mmf.trainers.callbacks.logistics : progress: 4700/22000, train/hateful_memes/cross_entropy: 0.0244, train/hateful_memes/cross_entropy/avg: 0.1270, train/total_loss: 0.0244, train/total_loss/avg: 0.1270, max mem: 19033.0, experiment: run, epoch: 36, num_updates: 4700, iterations: 4700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 841ms, time_since_start: 01h 59m 33s 864ms, eta: 07h 03m 52s 502ms
2023-04-25T06:10:31 | INFO | mmf.trainers.callbacks.logistics : progress: 4800/22000, train/hateful_memes/cross_entropy: 0.0209, train/hateful_memes/cross_entropy/avg: 0.1246, train/total_loss: 0.0209, train/total_loss/avg: 0.1246, max mem: 19033.0, experiment: run, epoch: 37, num_updates: 4800, iterations: 4800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 031ms, time_since_start: 02h 01m 58s 895ms, eta: 06h 59m 04s 904ms
2023-04-25T06:12:57 | INFO | mmf.trainers.callbacks.logistics : progress: 4900/22000, train/hateful_memes/cross_entropy: 0.0124, train/hateful_memes/cross_entropy/avg: 0.1222, train/total_loss: 0.0124, train/total_loss/avg: 0.1222, max mem: 19033.0, experiment: run, epoch: 37, num_updates: 4900, iterations: 4900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 374ms, time_since_start: 02h 04m 24s 270ms, eta: 06h 57m 37s 890ms
2023-04-25T06:15:22 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T06:15:22 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T06:15:41 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T06:15:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T06:15:47 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, train/hateful_memes/cross_entropy: 0.0124, train/hateful_memes/cross_entropy/avg: 0.1204, train/total_loss: 0.0124, train/total_loss/avg: 0.1204, max mem: 19033.0, experiment: run, epoch: 38, num_updates: 5000, iterations: 5000, max_updates: 22000, lr: 0.00004, ups: 0.59, time: 02m 50s 424ms, time_since_start: 02h 07m 14s 694ms, eta: 08h 06m 43s 992ms
2023-04-25T06:15:47 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T06:15:47 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T06:15:47 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T06:15:55 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T06:15:55 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T06:15:56 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T06:16:01 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T06:16:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T06:16:11 | INFO | mmf.trainers.callbacks.logistics : progress: 5000/22000, val/hateful_memes/cross_entropy: 2.4691, val/total_loss: 2.4691, val/hateful_memes/accuracy: 0.5940, val/hateful_memes/binary_f1: 0.4727, val/hateful_memes/roc_auc: 0.6373, num_updates: 5000, epoch: 38, iterations: 5000, max_updates: 22000, val_time: 23s 828ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T06:18:39 | INFO | mmf.trainers.callbacks.logistics : progress: 5100/22000, train/hateful_memes/cross_entropy: 0.0185, train/hateful_memes/cross_entropy/avg: 0.1184, train/total_loss: 0.0185, train/total_loss/avg: 0.1184, max mem: 19033.0, experiment: run, epoch: 39, num_updates: 5100, iterations: 5100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 28s 202ms, time_since_start: 02h 10m 06s 727ms, eta: 07h 46s 551ms
2023-04-25T06:21:04 | INFO | mmf.trainers.callbacks.logistics : progress: 5200/22000, train/hateful_memes/cross_entropy: 0.0128, train/hateful_memes/cross_entropy/avg: 0.1164, train/total_loss: 0.0128, train/total_loss/avg: 0.1164, max mem: 19033.0, experiment: run, epoch: 40, num_updates: 5200, iterations: 5200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 107ms, time_since_start: 02h 12m 31s 835ms, eta: 06h 49m 33s 162ms
2023-04-25T06:23:30 | INFO | mmf.trainers.callbacks.logistics : progress: 5300/22000, train/hateful_memes/cross_entropy: 0.0128, train/hateful_memes/cross_entropy/avg: 0.1142, train/total_loss: 0.0128, train/total_loss/avg: 0.1142, max mem: 19033.0, experiment: run, epoch: 40, num_updates: 5300, iterations: 5300, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 26s 178ms, time_since_start: 02h 14m 58s 013ms, eta: 06h 50m 07s 143ms
2023-04-25T06:25:56 | INFO | mmf.trainers.callbacks.logistics : progress: 5400/22000, train/hateful_memes/cross_entropy: 0.0185, train/hateful_memes/cross_entropy/avg: 0.1126, train/total_loss: 0.0185, train/total_loss/avg: 0.1126, max mem: 19033.0, experiment: run, epoch: 41, num_updates: 5400, iterations: 5400, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 152ms, time_since_start: 02h 17m 23s 166ms, eta: 06h 44m 48s 116ms
2023-04-25T06:28:21 | INFO | mmf.trainers.callbacks.logistics : progress: 5500/22000, train/hateful_memes/cross_entropy: 0.0128, train/hateful_memes/cross_entropy/avg: 0.1106, train/total_loss: 0.0128, train/total_loss/avg: 0.1106, max mem: 19033.0, experiment: run, epoch: 42, num_updates: 5500, iterations: 5500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 390ms, time_since_start: 02h 19m 48s 556ms, eta: 06h 43m 01s 272ms
2023-04-25T06:30:46 | INFO | mmf.trainers.callbacks.logistics : progress: 5600/22000, train/hateful_memes/cross_entropy: 0.0128, train/hateful_memes/cross_entropy/avg: 0.1086, train/total_loss: 0.0128, train/total_loss/avg: 0.1086, max mem: 19033.0, experiment: run, epoch: 43, num_updates: 5600, iterations: 5600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 233ms, time_since_start: 02h 22m 13s 790ms, eta: 06h 40m 08s 926ms
2023-04-25T06:33:12 | INFO | mmf.trainers.callbacks.logistics : progress: 5700/22000, train/hateful_memes/cross_entropy: 0.0124, train/hateful_memes/cross_entropy/avg: 0.1068, train/total_loss: 0.0124, train/total_loss/avg: 0.1068, max mem: 19033.0, experiment: run, epoch: 43, num_updates: 5700, iterations: 5700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 922ms, time_since_start: 02h 24m 39s 713ms, eta: 06h 39m 35s 690ms
2023-04-25T06:35:37 | INFO | mmf.trainers.callbacks.logistics : progress: 5800/22000, train/hateful_memes/cross_entropy: 0.0122, train/hateful_memes/cross_entropy/avg: 0.1049, train/total_loss: 0.0122, train/total_loss/avg: 0.1049, max mem: 19033.0, experiment: run, epoch: 44, num_updates: 5800, iterations: 5800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 959ms, time_since_start: 02h 27m 04s 672ms, eta: 06h 34m 31s 247ms
2023-04-25T06:38:02 | INFO | mmf.trainers.callbacks.logistics : progress: 5900/22000, train/hateful_memes/cross_entropy: 0.0122, train/hateful_memes/cross_entropy/avg: 0.1032, train/total_loss: 0.0122, train/total_loss/avg: 0.1032, max mem: 19033.0, experiment: run, epoch: 45, num_updates: 5900, iterations: 5900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 824ms, time_since_start: 02h 29m 29s 497ms, eta: 06h 31m 43s 350ms
2023-04-25T06:40:28 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T06:40:28 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T06:40:58 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T06:41:04 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T06:41:04 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, train/hateful_memes/cross_entropy: 0.0122, train/hateful_memes/cross_entropy/avg: 0.1017, train/total_loss: 0.0122, train/total_loss/avg: 0.1017, max mem: 19033.0, experiment: run, epoch: 46, num_updates: 6000, iterations: 6000, max_updates: 22000, lr: 0.00004, ups: 0.55, time: 03m 02s 343ms, time_since_start: 02h 32m 31s 840ms, eta: 08h 10m 08s 315ms
2023-04-25T06:41:04 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T06:41:04 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T06:41:04 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T06:41:13 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T06:41:13 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T06:41:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T06:41:18 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T06:41:25 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T06:41:25 | INFO | mmf.trainers.callbacks.logistics : progress: 6000/22000, val/hateful_memes/cross_entropy: 2.5308, val/total_loss: 2.5308, val/hateful_memes/accuracy: 0.5900, val/hateful_memes/binary_f1: 0.4353, val/hateful_memes/roc_auc: 0.6248, num_updates: 6000, epoch: 46, iterations: 6000, max_updates: 22000, val_time: 20s 473ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T06:43:52 | INFO | mmf.trainers.callbacks.logistics : progress: 6100/22000, train/hateful_memes/cross_entropy: 0.0064, train/hateful_memes/cross_entropy/avg: 0.1001, train/total_loss: 0.0064, train/total_loss/avg: 0.1001, max mem: 19033.0, experiment: run, epoch: 46, num_updates: 6100, iterations: 6100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 27s 086ms, time_since_start: 02h 35m 19s 404ms, eta: 06h 32m 53s 857ms
2023-04-25T06:46:17 | INFO | mmf.trainers.callbacks.logistics : progress: 6200/22000, train/hateful_memes/cross_entropy: 0.0064, train/hateful_memes/cross_entropy/avg: 0.0985, train/total_loss: 0.0064, train/total_loss/avg: 0.0985, max mem: 19033.0, experiment: run, epoch: 47, num_updates: 6200, iterations: 6200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 428ms, time_since_start: 02h 37m 44s 833ms, eta: 06h 26m 01s 600ms
2023-04-25T06:48:43 | INFO | mmf.trainers.callbacks.logistics : progress: 6300/22000, train/hateful_memes/cross_entropy: 0.0064, train/hateful_memes/cross_entropy/avg: 0.0972, train/total_loss: 0.0064, train/total_loss/avg: 0.0972, max mem: 19033.0, experiment: run, epoch: 48, num_updates: 6300, iterations: 6300, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 674ms, time_since_start: 02h 40m 10s 507ms, eta: 06h 24m 13s 856ms
2023-04-25T06:51:08 | INFO | mmf.trainers.callbacks.logistics : progress: 6400/22000, train/hateful_memes/cross_entropy: 0.0064, train/hateful_memes/cross_entropy/avg: 0.0957, train/total_loss: 0.0064, train/total_loss/avg: 0.0957, max mem: 19033.0, experiment: run, epoch: 49, num_updates: 6400, iterations: 6400, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 876ms, time_since_start: 02h 42m 35s 383ms, eta: 06h 19m 41s 509ms
2023-04-25T06:53:33 | INFO | mmf.trainers.callbacks.logistics : progress: 6500/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0943, train/total_loss: 0.0041, train/total_loss/avg: 0.0943, max mem: 19033.0, experiment: run, epoch: 49, num_updates: 6500, iterations: 6500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 680ms, time_since_start: 02h 45m 01s 064ms, eta: 06h 19m 21s 121ms
2023-04-25T06:55:58 | INFO | mmf.trainers.callbacks.logistics : progress: 6600/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0930, train/total_loss: 0.0041, train/total_loss/avg: 0.0930, max mem: 19033.0, experiment: run, epoch: 50, num_updates: 6600, iterations: 6600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 24s 952ms, time_since_start: 02h 47m 26s 017ms, eta: 06h 15m 01s 322ms
2023-04-25T06:58:24 | INFO | mmf.trainers.callbacks.logistics : progress: 6700/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0917, train/total_loss: 0.0041, train/total_loss/avg: 0.0917, max mem: 19033.0, experiment: run, epoch: 51, num_updates: 6700, iterations: 6700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 463ms, time_since_start: 02h 49m 51s 481ms, eta: 06h 13m 54s 009ms
2023-04-25T07:00:49 | INFO | mmf.trainers.callbacks.logistics : progress: 6800/22000, train/hateful_memes/cross_entropy: 0.0041, train/hateful_memes/cross_entropy/avg: 0.0906, train/total_loss: 0.0041, train/total_loss/avg: 0.0906, max mem: 19033.0, experiment: run, epoch: 52, num_updates: 6800, iterations: 6800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 247ms, time_since_start: 02h 52m 16s 728ms, eta: 06h 10m 54s 242ms
2023-04-25T07:03:14 | INFO | mmf.trainers.callbacks.logistics : progress: 6900/22000, train/hateful_memes/cross_entropy: 0.0040, train/hateful_memes/cross_entropy/avg: 0.0893, train/total_loss: 0.0040, train/total_loss/avg: 0.0893, max mem: 19033.0, experiment: run, epoch: 52, num_updates: 6900, iterations: 6900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 378ms, time_since_start: 02h 54m 42s 107ms, eta: 06h 08m 47s 838ms
2023-04-25T07:05:39 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T07:05:39 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T07:06:00 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T07:06:05 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T07:06:05 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, train/hateful_memes/cross_entropy: 0.0039, train/hateful_memes/cross_entropy/avg: 0.0881, train/total_loss: 0.0039, train/total_loss/avg: 0.0881, max mem: 19033.0, experiment: run, epoch: 53, num_updates: 7000, iterations: 7000, max_updates: 22000, lr: 0.00004, ups: 0.59, time: 02m 50s 311ms, time_since_start: 02h 57m 32s 418ms, eta: 07h 09m 11s 076ms
2023-04-25T07:06:05 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T07:06:05 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T07:06:05 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T07:06:13 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T07:06:13 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T07:06:13 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T07:06:19 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T07:06:24 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T07:06:24 | INFO | mmf.trainers.callbacks.logistics : progress: 7000/22000, val/hateful_memes/cross_entropy: 2.8653, val/total_loss: 2.8653, val/hateful_memes/accuracy: 0.6060, val/hateful_memes/binary_f1: 0.4883, val/hateful_memes/roc_auc: 0.6209, num_updates: 7000, epoch: 53, iterations: 7000, max_updates: 22000, val_time: 19s 322ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T07:08:51 | INFO | mmf.trainers.callbacks.logistics : progress: 7100/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.0868, train/total_loss: 0.0037, train/total_loss/avg: 0.0868, max mem: 19033.0, experiment: run, epoch: 54, num_updates: 7100, iterations: 7100, max_updates: 22000, lr: 0.00004, ups: 0.68, time: 02m 27s 347ms, time_since_start: 03h 19s 091ms, eta: 06h 08m 50s 481ms
2023-04-25T07:11:17 | INFO | mmf.trainers.callbacks.logistics : progress: 7200/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0856, train/total_loss: 0.0020, train/total_loss/avg: 0.0856, max mem: 19033.0, experiment: run, epoch: 55, num_updates: 7200, iterations: 7200, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 258ms, time_since_start: 03h 02m 44s 350ms, eta: 06h 01m 10s 315ms
2023-04-25T07:13:42 | INFO | mmf.trainers.callbacks.logistics : progress: 7300/22000, train/hateful_memes/cross_entropy: 0.0037, train/hateful_memes/cross_entropy/avg: 0.0847, train/total_loss: 0.0037, train/total_loss/avg: 0.0847, max mem: 19033.0, experiment: run, epoch: 55, num_updates: 7300, iterations: 7300, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 322ms, time_since_start: 03h 05m 09s 673ms, eta: 05h 58m 53s 374ms
2023-04-25T07:16:08 | INFO | mmf.trainers.callbacks.logistics : progress: 7400/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0836, train/total_loss: 0.0020, train/total_loss/avg: 0.0836, max mem: 19033.0, experiment: run, epoch: 56, num_updates: 7400, iterations: 7400, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 724ms, time_since_start: 03h 07m 35s 397ms, eta: 05h 57m 26s 003ms
2023-04-25T07:18:33 | INFO | mmf.trainers.callbacks.logistics : progress: 7500/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0824, train/total_loss: 0.0020, train/total_loss/avg: 0.0824, max mem: 19033.0, experiment: run, epoch: 57, num_updates: 7500, iterations: 7500, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 081ms, time_since_start: 03h 10m 479ms, eta: 05h 53m 25s 143ms
2023-04-25T07:20:58 | INFO | mmf.trainers.callbacks.logistics : progress: 7600/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0814, train/total_loss: 0.0020, train/total_loss/avg: 0.0814, max mem: 19033.0, experiment: run, epoch: 58, num_updates: 7600, iterations: 7600, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 009ms, time_since_start: 03h 12m 25s 489ms, eta: 05h 50m 48s 412ms
2023-04-25T07:23:23 | INFO | mmf.trainers.callbacks.logistics : progress: 7700/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0804, train/total_loss: 0.0020, train/total_loss/avg: 0.0804, max mem: 19033.0, experiment: run, epoch: 58, num_updates: 7700, iterations: 7700, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 115ms, time_since_start: 03h 14m 50s 604ms, eta: 05h 48m 37s 502ms
2023-04-25T07:25:48 | INFO | mmf.trainers.callbacks.logistics : progress: 7800/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0793, train/total_loss: 0.0020, train/total_loss/avg: 0.0793, max mem: 19033.0, experiment: run, epoch: 59, num_updates: 7800, iterations: 7800, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 521ms, time_since_start: 03h 17m 16s 125ms, eta: 05h 47m 09s 321ms
2023-04-25T07:28:14 | INFO | mmf.trainers.callbacks.logistics : progress: 7900/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0783, train/total_loss: 0.0020, train/total_loss/avg: 0.0783, max mem: 19033.0, experiment: run, epoch: 60, num_updates: 7900, iterations: 7900, max_updates: 22000, lr: 0.00004, ups: 0.69, time: 02m 25s 129ms, time_since_start: 03h 19m 41s 255ms, eta: 05h 43m 46s 950ms
2023-04-25T07:30:38 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T07:30:38 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T07:31:15 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T07:31:23 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T07:31:23 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0774, train/total_loss: 0.0020, train/total_loss/avg: 0.0774, max mem: 19033.0, experiment: run, epoch: 61, num_updates: 8000, iterations: 8000, max_updates: 22000, lr: 0.00003, ups: 0.53, time: 03m 09s 192ms, time_since_start: 03h 22m 50s 447ms, eta: 07h 24m 58s 801ms
2023-04-25T07:31:23 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T07:31:23 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T07:31:23 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T07:31:31 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T07:31:31 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T07:31:31 | INFO | mmf.trainers.callbacks.logistics : progress: 8000/22000, val/hateful_memes/cross_entropy: 2.8285, val/total_loss: 2.8285, val/hateful_memes/accuracy: 0.5720, val/hateful_memes/binary_f1: 0.4216, val/hateful_memes/roc_auc: 0.6231, num_updates: 8000, epoch: 61, iterations: 8000, max_updates: 22000, val_time: 08s 651ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T07:33:58 | INFO | mmf.trainers.callbacks.logistics : progress: 8100/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0765, train/total_loss: 0.0020, train/total_loss/avg: 0.0765, max mem: 19033.0, experiment: run, epoch: 61, num_updates: 8100, iterations: 8100, max_updates: 22000, lr: 0.00003, ups: 0.68, time: 02m 26s 221ms, time_since_start: 03h 25m 25s 322ms, eta: 05h 41m 27s 441ms
2023-04-25T07:36:23 | INFO | mmf.trainers.callbacks.logistics : progress: 8200/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0756, train/total_loss: 0.0020, train/total_loss/avg: 0.0756, max mem: 19033.0, experiment: run, epoch: 62, num_updates: 8200, iterations: 8200, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 627ms, time_since_start: 03h 27m 50s 949ms, eta: 05h 37m 37s 343ms
2023-04-25T07:38:48 | INFO | mmf.trainers.callbacks.logistics : progress: 8300/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0747, train/total_loss: 0.0020, train/total_loss/avg: 0.0747, max mem: 19033.0, experiment: run, epoch: 63, num_updates: 8300, iterations: 8300, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 015ms, time_since_start: 03h 30m 15s 965ms, eta: 05h 33m 46s 109ms
2023-04-25T07:41:13 | INFO | mmf.trainers.callbacks.logistics : progress: 8400/22000, train/hateful_memes/cross_entropy: 0.0020, train/hateful_memes/cross_entropy/avg: 0.0738, train/total_loss: 0.0020, train/total_loss/avg: 0.0738, max mem: 19033.0, experiment: run, epoch: 64, num_updates: 8400, iterations: 8400, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 828ms, time_since_start: 03h 32m 40s 794ms, eta: 05h 30m 54s 235ms
2023-04-25T07:43:38 | INFO | mmf.trainers.callbacks.logistics : progress: 8500/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0729, train/total_loss: 0.0017, train/total_loss/avg: 0.0729, max mem: 19033.0, experiment: run, epoch: 64, num_updates: 8500, iterations: 8500, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 638ms, time_since_start: 03h 35m 05s 432ms, eta: 05h 28m 02s 347ms
2023-04-25T07:46:03 | INFO | mmf.trainers.callbacks.logistics : progress: 8600/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0722, train/total_loss: 0.0017, train/total_loss/avg: 0.0722, max mem: 19033.0, experiment: run, epoch: 65, num_updates: 8600, iterations: 8600, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 638ms, time_since_start: 03h 37m 31s 070ms, eta: 05h 27m 51s 713ms
2023-04-25T07:48:28 | INFO | mmf.trainers.callbacks.logistics : progress: 8700/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0714, train/total_loss: 0.0017, train/total_loss/avg: 0.0714, max mem: 19033.0, experiment: run, epoch: 66, num_updates: 8700, iterations: 8700, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 771ms, time_since_start: 03h 39m 55s 842ms, eta: 05h 23m 28s 704ms
2023-04-25T07:50:53 | INFO | mmf.trainers.callbacks.logistics : progress: 8800/22000, train/hateful_memes/cross_entropy: 0.0017, train/hateful_memes/cross_entropy/avg: 0.0707, train/total_loss: 0.0017, train/total_loss/avg: 0.0707, max mem: 19033.0, experiment: run, epoch: 67, num_updates: 8800, iterations: 8800, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 283ms, time_since_start: 03h 42m 21s 125ms, eta: 05h 22m 10s 796ms
2023-04-25T07:53:19 | INFO | mmf.trainers.callbacks.logistics : progress: 8900/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0699, train/total_loss: 0.0016, train/total_loss/avg: 0.0699, max mem: 19033.0, experiment: run, epoch: 67, num_updates: 8900, iterations: 8900, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 647ms, time_since_start: 03h 44m 46s 773ms, eta: 05h 20m 32s 502ms
2023-04-25T07:55:44 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T07:55:44 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T07:56:11 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T07:56:19 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T07:56:19 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0692, train/total_loss: 0.0016, train/total_loss/avg: 0.0692, max mem: 19033.0, experiment: run, epoch: 68, num_updates: 9000, iterations: 9000, max_updates: 22000, lr: 0.00003, ups: 0.56, time: 03m 207ms, time_since_start: 03h 47m 46s 981ms, eta: 06h 33m 34s 359ms
2023-04-25T07:56:19 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T07:56:19 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T07:56:19 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T07:56:28 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T07:56:28 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T07:56:28 | INFO | mmf.trainers.callbacks.logistics : progress: 9000/22000, val/hateful_memes/cross_entropy: 3.2214, val/total_loss: 3.2214, val/hateful_memes/accuracy: 0.5880, val/hateful_memes/binary_f1: 0.4432, val/hateful_memes/roc_auc: 0.6426, num_updates: 9000, epoch: 68, iterations: 9000, max_updates: 22000, val_time: 08s 531ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T07:58:53 | INFO | mmf.trainers.callbacks.logistics : progress: 9100/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0685, train/total_loss: 0.0016, train/total_loss/avg: 0.0685, max mem: 19033.0, experiment: run, epoch: 69, num_updates: 9100, iterations: 9100, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 312ms, time_since_start: 03h 50m 20s 827ms, eta: 05h 14m 55s 303ms
2023-04-25T08:01:18 | INFO | mmf.trainers.callbacks.logistics : progress: 9200/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0678, train/total_loss: 0.0016, train/total_loss/avg: 0.0678, max mem: 19033.0, experiment: run, epoch: 70, num_updates: 9200, iterations: 9200, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 823ms, time_since_start: 03h 52m 45s 651ms, eta: 05h 11m 25s 738ms
2023-04-25T08:03:43 | INFO | mmf.trainers.callbacks.logistics : progress: 9300/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0672, train/total_loss: 0.0016, train/total_loss/avg: 0.0672, max mem: 19033.0, experiment: run, epoch: 70, num_updates: 9300, iterations: 9300, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 157ms, time_since_start: 03h 55m 10s 808ms, eta: 05h 09m 42s 483ms
2023-04-25T08:06:07 | INFO | mmf.trainers.callbacks.logistics : progress: 9400/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0667, train/total_loss: 0.0016, train/total_loss/avg: 0.0667, max mem: 19033.0, experiment: run, epoch: 71, num_updates: 9400, iterations: 9400, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 209ms, time_since_start: 03h 57m 35s 018ms, eta: 05h 05m 15s 723ms
2023-04-25T08:08:32 | INFO | mmf.trainers.callbacks.logistics : progress: 9500/22000, train/hateful_memes/cross_entropy: 0.0016, train/hateful_memes/cross_entropy/avg: 0.0660, train/total_loss: 0.0016, train/total_loss/avg: 0.0660, max mem: 19033.0, experiment: run, epoch: 72, num_updates: 9500, iterations: 9500, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 008ms, time_since_start: 04h 027ms, eta: 05h 04m 31s 133ms
2023-04-25T08:10:57 | INFO | mmf.trainers.callbacks.logistics : progress: 9600/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0653, train/total_loss: 0.0015, train/total_loss/avg: 0.0653, max mem: 19033.0, experiment: run, epoch: 73, num_updates: 9600, iterations: 9600, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 917ms, time_since_start: 04h 02m 24s 944ms, eta: 05h 01m 53s 494ms
2023-04-25T08:13:22 | INFO | mmf.trainers.callbacks.logistics : progress: 9700/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0647, train/total_loss: 0.0011, train/total_loss/avg: 0.0647, max mem: 19033.0, experiment: run, epoch: 73, num_updates: 9700, iterations: 9700, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 830ms, time_since_start: 04h 04m 49s 774ms, eta: 04h 59m 16s 663ms
2023-04-25T08:15:47 | INFO | mmf.trainers.callbacks.logistics : progress: 9800/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0640, train/total_loss: 0.0011, train/total_loss/avg: 0.0640, max mem: 19033.0, experiment: run, epoch: 74, num_updates: 9800, iterations: 9800, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 071ms, time_since_start: 04h 07m 14s 846ms, eta: 04h 57m 20s 368ms
2023-04-25T08:18:12 | INFO | mmf.trainers.callbacks.logistics : progress: 9900/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0635, train/total_loss: 0.0015, train/total_loss/avg: 0.0635, max mem: 19033.0, experiment: run, epoch: 75, num_updates: 9900, iterations: 9900, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 283ms, time_since_start: 04h 09m 40s 130ms, eta: 04h 55m 19s 965ms
2023-04-25T08:20:37 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T08:20:37 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T08:21:10 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T08:21:16 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T08:21:16 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0628, train/total_loss: 0.0011, train/total_loss/avg: 0.0628, max mem: 19033.0, experiment: run, epoch: 76, num_updates: 10000, iterations: 10000, max_updates: 22000, lr: 0.00003, ups: 0.55, time: 03m 03s 529ms, time_since_start: 04h 12m 43s 660ms, eta: 06h 09m 59s 722ms
2023-04-25T08:21:16 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T08:21:16 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T08:21:16 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T08:21:25 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T08:21:25 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T08:21:25 | INFO | mmf.trainers.callbacks.logistics : progress: 10000/22000, val/hateful_memes/cross_entropy: 3.0805, val/total_loss: 3.0805, val/hateful_memes/accuracy: 0.5880, val/hateful_memes/binary_f1: 0.4772, val/hateful_memes/roc_auc: 0.6282, num_updates: 10000, epoch: 76, iterations: 10000, max_updates: 22000, val_time: 09s 067ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T08:23:53 | INFO | mmf.trainers.callbacks.logistics : progress: 10100/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0625, train/total_loss: 0.0015, train/total_loss/avg: 0.0625, max mem: 19033.0, experiment: run, epoch: 76, num_updates: 10100, iterations: 10100, max_updates: 22000, lr: 0.00003, ups: 0.68, time: 02m 27s 558ms, time_since_start: 04h 15m 20s 288ms, eta: 04h 54m 59s 994ms
2023-04-25T08:26:18 | INFO | mmf.trainers.callbacks.logistics : progress: 10200/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0620, train/total_loss: 0.0015, train/total_loss/avg: 0.0620, max mem: 19033.0, experiment: run, epoch: 77, num_updates: 10200, iterations: 10200, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 590ms, time_since_start: 04h 17m 45s 879ms, eta: 04h 48m 37s 116ms
2023-04-25T08:28:43 | INFO | mmf.trainers.callbacks.logistics : progress: 10300/22000, train/hateful_memes/cross_entropy: 0.0015, train/hateful_memes/cross_entropy/avg: 0.0614, train/total_loss: 0.0015, train/total_loss/avg: 0.0614, max mem: 19033.0, experiment: run, epoch: 78, num_updates: 10300, iterations: 10300, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 931ms, time_since_start: 04h 20m 10s 810ms, eta: 04h 44m 52s 597ms
2023-04-25T08:31:08 | INFO | mmf.trainers.callbacks.logistics : progress: 10400/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0608, train/total_loss: 0.0011, train/total_loss/avg: 0.0608, max mem: 19033.0, experiment: run, epoch: 79, num_updates: 10400, iterations: 10400, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 335ms, time_since_start: 04h 22m 36s 145ms, eta: 04h 43m 13s 775ms
2023-04-25T08:33:34 | INFO | mmf.trainers.callbacks.logistics : progress: 10500/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0602, train/total_loss: 0.0011, train/total_loss/avg: 0.0602, max mem: 19033.0, experiment: run, epoch: 79, num_updates: 10500, iterations: 10500, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 059ms, time_since_start: 04h 25m 01s 205ms, eta: 04h 40m 15s 249ms
2023-04-25T08:35:58 | INFO | mmf.trainers.callbacks.logistics : progress: 10600/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0598, train/total_loss: 0.0011, train/total_loss/avg: 0.0598, max mem: 19033.0, experiment: run, epoch: 80, num_updates: 10600, iterations: 10600, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 729ms, time_since_start: 04h 27m 25s 934ms, eta: 04h 37m 11s 153ms
2023-04-25T08:38:24 | INFO | mmf.trainers.callbacks.logistics : progress: 10700/22000, train/hateful_memes/cross_entropy: 0.0011, train/hateful_memes/cross_entropy/avg: 0.0592, train/total_loss: 0.0011, train/total_loss/avg: 0.0592, max mem: 19033.0, experiment: run, epoch: 81, num_updates: 10700, iterations: 10700, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 485ms, time_since_start: 04h 29m 51s 419ms, eta: 04h 36m 11s 353ms
2023-04-25T08:40:48 | INFO | mmf.trainers.callbacks.logistics : progress: 10800/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0587, train/total_loss: 0.0009, train/total_loss/avg: 0.0587, max mem: 19033.0, experiment: run, epoch: 82, num_updates: 10800, iterations: 10800, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 572ms, time_since_start: 04h 32m 15s 992ms, eta: 04h 32m 01s 644ms
2023-04-25T08:43:14 | INFO | mmf.trainers.callbacks.logistics : progress: 10900/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0581, train/total_loss: 0.0009, train/total_loss/avg: 0.0581, max mem: 19033.0, experiment: run, epoch: 82, num_updates: 10900, iterations: 10900, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 237ms, time_since_start: 04h 34m 41s 229ms, eta: 04h 30m 50s 295ms
2023-04-25T08:45:39 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T08:45:39 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T08:46:02 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T08:46:09 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T08:46:09 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, train/hateful_memes/cross_entropy: 0.0009, train/hateful_memes/cross_entropy/avg: 0.0576, train/total_loss: 0.0009, train/total_loss/avg: 0.0576, max mem: 19033.0, experiment: run, epoch: 83, num_updates: 11000, iterations: 11000, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 55s 679ms, time_since_start: 04h 37m 36s 909ms, eta: 05h 24m 39s 367ms
2023-04-25T08:46:09 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T08:46:09 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T08:46:09 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T08:46:18 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T08:46:18 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T08:46:18 | INFO | mmf.trainers.callbacks.logistics : progress: 11000/22000, val/hateful_memes/cross_entropy: 3.1514, val/total_loss: 3.1514, val/hateful_memes/accuracy: 0.5700, val/hateful_memes/binary_f1: 0.3768, val/hateful_memes/roc_auc: 0.6470, num_updates: 11000, epoch: 83, iterations: 11000, max_updates: 22000, val_time: 08s 382ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T08:48:45 | INFO | mmf.trainers.callbacks.logistics : progress: 11100/22000, train/hateful_memes/cross_entropy: 0.0008, train/hateful_memes/cross_entropy/avg: 0.0571, train/total_loss: 0.0008, train/total_loss/avg: 0.0571, max mem: 19034.0, experiment: run, epoch: 84, num_updates: 11100, iterations: 11100, max_updates: 22000, lr: 0.00003, ups: 0.68, time: 02m 27s 453ms, time_since_start: 04h 40m 12s 747ms, eta: 04h 30m 01s 018ms
2023-04-25T08:51:10 | INFO | mmf.trainers.callbacks.logistics : progress: 11200/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0566, train/total_loss: 0.0007, train/total_loss/avg: 0.0566, max mem: 19034.0, experiment: run, epoch: 85, num_updates: 11200, iterations: 11200, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 702ms, time_since_start: 04h 42m 37s 449ms, eta: 04h 22m 32s 875ms
2023-04-25T08:53:35 | INFO | mmf.trainers.callbacks.logistics : progress: 11300/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0561, train/total_loss: 0.0007, train/total_loss/avg: 0.0561, max mem: 19034.0, experiment: run, epoch: 85, num_updates: 11300, iterations: 11300, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 983ms, time_since_start: 04h 45m 02s 433ms, eta: 04h 20m 37s 392ms
2023-04-25T08:56:00 | INFO | mmf.trainers.callbacks.logistics : progress: 11400/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0556, train/total_loss: 0.0007, train/total_loss/avg: 0.0556, max mem: 19034.0, experiment: run, epoch: 86, num_updates: 11400, iterations: 11400, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 797ms, time_since_start: 04h 47m 27s 230ms, eta: 04h 17m 51s 296ms
2023-04-25T08:58:24 | INFO | mmf.trainers.callbacks.logistics : progress: 11500/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0551, train/total_loss: 0.0007, train/total_loss/avg: 0.0551, max mem: 19034.0, experiment: run, epoch: 87, num_updates: 11500, iterations: 11500, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 786ms, time_since_start: 04h 49m 52s 017ms, eta: 04h 15m 24s 172ms
2023-04-25T09:00:50 | INFO | mmf.trainers.callbacks.logistics : progress: 11600/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0547, train/total_loss: 0.0007, train/total_loss/avg: 0.0547, max mem: 19034.0, experiment: run, epoch: 88, num_updates: 11600, iterations: 11600, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 581ms, time_since_start: 04h 52m 17s 598ms, eta: 04h 14m 21s 569ms
2023-04-25T09:03:15 | INFO | mmf.trainers.callbacks.logistics : progress: 11700/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0542, train/total_loss: 0.0007, train/total_loss/avg: 0.0542, max mem: 19034.0, experiment: run, epoch: 88, num_updates: 11700, iterations: 11700, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 588ms, time_since_start: 04h 54m 42s 186ms, eta: 04h 10m 11s 773ms
2023-04-25T09:05:39 | INFO | mmf.trainers.callbacks.logistics : progress: 11800/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0538, train/total_loss: 0.0007, train/total_loss/avg: 0.0538, max mem: 19034.0, experiment: run, epoch: 89, num_updates: 11800, iterations: 11800, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 24s 489ms, time_since_start: 04h 57m 06s 676ms, eta: 04h 07m 35s 790ms
2023-04-25T09:08:04 | INFO | mmf.trainers.callbacks.logistics : progress: 11900/22000, train/hateful_memes/cross_entropy: 0.0007, train/hateful_memes/cross_entropy/avg: 0.0534, train/total_loss: 0.0007, train/total_loss/avg: 0.0534, max mem: 19034.0, experiment: run, epoch: 90, num_updates: 11900, iterations: 11900, max_updates: 22000, lr: 0.00003, ups: 0.69, time: 02m 25s 030ms, time_since_start: 04h 59m 31s 707ms, eta: 04h 06m 05s 305ms
2023-04-25T09:10:28 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T09:10:28 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T09:10:53 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T09:11:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T09:11:00 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, train/hateful_memes/cross_entropy: 0.0006, train/hateful_memes/cross_entropy/avg: 0.0529, train/total_loss: 0.0006, train/total_loss/avg: 0.0529, max mem: 19034.0, experiment: run, epoch: 91, num_updates: 12000, iterations: 12000, max_updates: 22000, lr: 0.00003, ups: 0.57, time: 02m 56s 335ms, time_since_start: 05h 02m 28s 042ms, eta: 04h 56m 14s 630ms
2023-04-25T09:11:00 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T09:11:00 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T09:11:00 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T09:11:09 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T09:11:09 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T09:11:09 | INFO | mmf.trainers.callbacks.logistics : progress: 12000/22000, val/hateful_memes/cross_entropy: 3.2461, val/total_loss: 3.2461, val/hateful_memes/accuracy: 0.6060, val/hateful_memes/binary_f1: 0.4910, val/hateful_memes/roc_auc: 0.6401, num_updates: 12000, epoch: 91, iterations: 12000, max_updates: 22000, val_time: 08s 498ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T09:13:37 | INFO | mmf.trainers.callbacks.logistics : progress: 12100/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0525, train/total_loss: 0.0004, train/total_loss/avg: 0.0525, max mem: 19034.0, experiment: run, epoch: 91, num_updates: 12100, iterations: 12100, max_updates: 22000, lr: 0.00002, ups: 0.68, time: 02m 27s 766ms, time_since_start: 05h 05m 04s 310ms, eta: 04h 05m 45s 931ms
2023-04-25T09:16:02 | INFO | mmf.trainers.callbacks.logistics : progress: 12200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0521, train/total_loss: 0.0004, train/total_loss/avg: 0.0521, max mem: 19034.0, experiment: run, epoch: 92, num_updates: 12200, iterations: 12200, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 682ms, time_since_start: 05h 07m 29s 992ms, eta: 03h 59m 51s 071ms
2023-04-25T09:18:28 | INFO | mmf.trainers.callbacks.logistics : progress: 12300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0517, train/total_loss: 0.0004, train/total_loss/avg: 0.0517, max mem: 19034.0, experiment: run, epoch: 93, num_updates: 12300, iterations: 12300, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 346ms, time_since_start: 05h 09m 55s 339ms, eta: 03h 56m 51s 409ms
2023-04-25T09:20:53 | INFO | mmf.trainers.callbacks.logistics : progress: 12400/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0512, train/total_loss: 0.0004, train/total_loss/avg: 0.0512, max mem: 19034.0, experiment: run, epoch: 94, num_updates: 12400, iterations: 12400, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 24s 983ms, time_since_start: 05h 12m 20s 323ms, eta: 03h 53m 49s 796ms
2023-04-25T09:23:18 | INFO | mmf.trainers.callbacks.logistics : progress: 12500/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0508, train/total_loss: 0.0004, train/total_loss/avg: 0.0508, max mem: 19034.0, experiment: run, epoch: 94, num_updates: 12500, iterations: 12500, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 649ms, time_since_start: 05h 14m 45s 972ms, eta: 03h 52m 27s 380ms
2023-04-25T09:25:43 | INFO | mmf.trainers.callbacks.logistics : progress: 12600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0504, train/total_loss: 0.0003, train/total_loss/avg: 0.0504, max mem: 19034.0, experiment: run, epoch: 95, num_updates: 12600, iterations: 12600, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 074ms, time_since_start: 05h 17m 11s 046ms, eta: 03h 49m 06s 064ms
2023-04-25T09:28:09 | INFO | mmf.trainers.callbacks.logistics : progress: 12700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0500, train/total_loss: 0.0003, train/total_loss/avg: 0.0500, max mem: 19034.0, experiment: run, epoch: 96, num_updates: 12700, iterations: 12700, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 728ms, time_since_start: 05h 19m 36s 774ms, eta: 03h 47m 41s 146ms
2023-04-25T09:30:34 | INFO | mmf.trainers.callbacks.logistics : progress: 12800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0496, train/total_loss: 0.0003, train/total_loss/avg: 0.0496, max mem: 19034.0, experiment: run, epoch: 97, num_updates: 12800, iterations: 12800, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 298ms, time_since_start: 05h 22m 02s 072ms, eta: 03h 44m 34s 364ms
2023-04-25T09:33:00 | INFO | mmf.trainers.callbacks.logistics : progress: 12900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0493, train/total_loss: 0.0003, train/total_loss/avg: 0.0493, max mem: 19034.0, experiment: run, epoch: 97, num_updates: 12900, iterations: 12900, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 412ms, time_since_start: 05h 24m 27s 485ms, eta: 03h 42m 18s 423ms
2023-04-25T09:35:25 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T09:35:25 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T09:35:45 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T09:35:55 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T09:35:55 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0489, train/total_loss: 0.0003, train/total_loss/avg: 0.0489, max mem: 19034.0, experiment: run, epoch: 98, num_updates: 13000, iterations: 13000, max_updates: 22000, lr: 0.00002, ups: 0.57, time: 02m 55s 502ms, time_since_start: 05h 27m 22s 988ms, eta: 04h 25m 21s 571ms
2023-04-25T09:35:55 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T09:35:55 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T09:35:55 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T09:36:04 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T09:36:04 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T09:36:04 | INFO | mmf.trainers.callbacks.logistics : progress: 13000/22000, val/hateful_memes/cross_entropy: 3.6457, val/total_loss: 3.6457, val/hateful_memes/accuracy: 0.5860, val/hateful_memes/binary_f1: 0.4390, val/hateful_memes/roc_auc: 0.6269, num_updates: 13000, epoch: 98, iterations: 13000, max_updates: 22000, val_time: 08s 442ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T09:38:30 | INFO | mmf.trainers.callbacks.logistics : progress: 13100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0486, train/total_loss: 0.0003, train/total_loss/avg: 0.0486, max mem: 19034.0, experiment: run, epoch: 99, num_updates: 13100, iterations: 13100, max_updates: 22000, lr: 0.00002, ups: 0.68, time: 02m 26s 205ms, time_since_start: 05h 29m 57s 637ms, eta: 03h 38m 36s 361ms
2023-04-25T09:40:56 | INFO | mmf.trainers.callbacks.logistics : progress: 13200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0482, train/total_loss: 0.0003, train/total_loss/avg: 0.0482, max mem: 19034.0, experiment: run, epoch: 100, num_updates: 13200, iterations: 13200, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 808ms, time_since_start: 05h 32m 23s 445ms, eta: 03h 35m 33s 777ms
2023-04-25T09:43:21 | INFO | mmf.trainers.callbacks.logistics : progress: 13300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0479, train/total_loss: 0.0003, train/total_loss/avg: 0.0479, max mem: 19034.0, experiment: run, epoch: 100, num_updates: 13300, iterations: 13300, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 299ms, time_since_start: 05h 34m 48s 745ms, eta: 03h 32m 22s 182ms
2023-04-25T09:45:47 | INFO | mmf.trainers.callbacks.logistics : progress: 13400/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0476, train/total_loss: 0.0005, train/total_loss/avg: 0.0476, max mem: 19034.0, experiment: run, epoch: 101, num_updates: 13400, iterations: 13400, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 859ms, time_since_start: 05h 37m 14s 604ms, eta: 03h 30m 44s 231ms
2023-04-25T09:48:12 | INFO | mmf.trainers.callbacks.logistics : progress: 13500/22000, train/hateful_memes/cross_entropy: 0.0005, train/hateful_memes/cross_entropy/avg: 0.0472, train/total_loss: 0.0005, train/total_loss/avg: 0.0472, max mem: 19034.0, experiment: run, epoch: 102, num_updates: 13500, iterations: 13500, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 277ms, time_since_start: 05h 39m 39s 881ms, eta: 03h 27m 27s 390ms
2023-04-25T09:50:38 | INFO | mmf.trainers.callbacks.logistics : progress: 13600/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0469, train/total_loss: 0.0003, train/total_loss/avg: 0.0469, max mem: 19034.0, experiment: run, epoch: 103, num_updates: 13600, iterations: 13600, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 751ms, time_since_start: 05h 42m 05s 633ms, eta: 03h 25m 41s 055ms
2023-04-25T09:53:03 | INFO | mmf.trainers.callbacks.logistics : progress: 13700/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0465, train/total_loss: 0.0003, train/total_loss/avg: 0.0465, max mem: 19034.0, experiment: run, epoch: 104, num_updates: 13700, iterations: 13700, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 246ms, time_since_start: 05h 44m 30s 879ms, eta: 03h 22m 31s 913ms
2023-04-25T09:55:29 | INFO | mmf.trainers.callbacks.logistics : progress: 13800/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0462, train/total_loss: 0.0003, train/total_loss/avg: 0.0462, max mem: 19034.0, experiment: run, epoch: 104, num_updates: 13800, iterations: 13800, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 438ms, time_since_start: 05h 46m 56s 318ms, eta: 03h 20m 21s 344ms
2023-04-25T09:57:54 | INFO | mmf.trainers.callbacks.logistics : progress: 13900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0459, train/total_loss: 0.0003, train/total_loss/avg: 0.0459, max mem: 19034.0, experiment: run, epoch: 105, num_updates: 13900, iterations: 13900, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 682ms, time_since_start: 05h 49m 22s 000ms, eta: 03h 18m 14s 698ms
2023-04-25T10:00:19 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T10:00:19 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T10:00:53 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T10:01:01 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T10:01:01 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0455, train/total_loss: 0.0003, train/total_loss/avg: 0.0455, max mem: 19034.0, experiment: run, epoch: 106, num_updates: 14000, iterations: 14000, max_updates: 22000, lr: 0.00002, ups: 0.54, time: 03m 06s 551ms, time_since_start: 05h 52m 28s 551ms, eta: 04h 10m 43s 480ms
2023-04-25T10:01:01 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T10:01:01 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T10:01:01 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T10:01:09 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T10:01:09 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T10:01:09 | INFO | mmf.trainers.callbacks.logistics : progress: 14000/22000, val/hateful_memes/cross_entropy: 3.4374, val/total_loss: 3.4374, val/hateful_memes/accuracy: 0.5940, val/hateful_memes/binary_f1: 0.4615, val/hateful_memes/roc_auc: 0.6217, num_updates: 14000, epoch: 106, iterations: 14000, max_updates: 22000, val_time: 08s 397ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T10:03:36 | INFO | mmf.trainers.callbacks.logistics : progress: 14100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0453, train/total_loss: 0.0003, train/total_loss/avg: 0.0453, max mem: 19034.0, experiment: run, epoch: 107, num_updates: 14100, iterations: 14100, max_updates: 22000, lr: 0.00002, ups: 0.68, time: 02m 27s 177ms, time_since_start: 05h 55m 04s 128ms, eta: 03h 15m 20s 060ms
2023-04-25T10:06:02 | INFO | mmf.trainers.callbacks.logistics : progress: 14200/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0449, train/total_loss: 0.0004, train/total_loss/avg: 0.0449, max mem: 19034.0, experiment: run, epoch: 107, num_updates: 14200, iterations: 14200, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 579ms, time_since_start: 05h 57m 29s 708ms, eta: 03h 10m 46s 032ms
2023-04-25T10:08:27 | INFO | mmf.trainers.callbacks.logistics : progress: 14300/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0446, train/total_loss: 0.0004, train/total_loss/avg: 0.0446, max mem: 19034.0, experiment: run, epoch: 108, num_updates: 14300, iterations: 14300, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 252ms, time_since_start: 05h 59m 54s 960ms, eta: 03h 07m 53s 889ms
2023-04-25T10:10:52 | INFO | mmf.trainers.callbacks.logistics : progress: 14400/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0443, train/total_loss: 0.0004, train/total_loss/avg: 0.0443, max mem: 19034.0, experiment: run, epoch: 109, num_updates: 14400, iterations: 14400, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 194ms, time_since_start: 06h 02m 20s 155ms, eta: 03h 05m 23s 087ms
2023-04-25T10:13:18 | INFO | mmf.trainers.callbacks.logistics : progress: 14500/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0440, train/total_loss: 0.0004, train/total_loss/avg: 0.0440, max mem: 19034.0, experiment: run, epoch: 110, num_updates: 14500, iterations: 14500, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 594ms, time_since_start: 06h 04m 45s 749ms, eta: 03h 03m 26s 970ms
2023-04-25T10:15:44 | INFO | mmf.trainers.callbacks.logistics : progress: 14600/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0437, train/total_loss: 0.0004, train/total_loss/avg: 0.0437, max mem: 19034.0, experiment: run, epoch: 110, num_updates: 14600, iterations: 14600, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 435ms, time_since_start: 06h 07m 11s 185ms, eta: 03h 48s 345ms
2023-04-25T10:18:09 | INFO | mmf.trainers.callbacks.logistics : progress: 14700/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0434, train/total_loss: 0.0004, train/total_loss/avg: 0.0434, max mem: 19034.0, experiment: run, epoch: 111, num_updates: 14700, iterations: 14700, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 922ms, time_since_start: 06h 09m 37s 108ms, eta: 02h 58m 57s 587ms
2023-04-25T10:20:34 | INFO | mmf.trainers.callbacks.logistics : progress: 14800/22000, train/hateful_memes/cross_entropy: 0.0004, train/hateful_memes/cross_entropy/avg: 0.0431, train/total_loss: 0.0004, train/total_loss/avg: 0.0431, max mem: 19034.0, experiment: run, epoch: 112, num_updates: 14800, iterations: 14800, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 24s 779ms, time_since_start: 06h 12m 01s 888ms, eta: 02h 55m 07s 544ms
2023-04-25T10:23:00 | INFO | mmf.trainers.callbacks.logistics : progress: 14900/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0428, train/total_loss: 0.0003, train/total_loss/avg: 0.0428, max mem: 19034.0, experiment: run, epoch: 113, num_updates: 14900, iterations: 14900, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 772ms, time_since_start: 06h 14m 27s 661ms, eta: 02h 53m 52s 654ms
2023-04-25T10:25:26 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T10:25:26 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T10:25:52 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T10:25:58 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T10:25:58 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0426, train/total_loss: 0.0003, train/total_loss/avg: 0.0426, max mem: 19034.0, experiment: run, epoch: 113, num_updates: 15000, iterations: 15000, max_updates: 22000, lr: 0.00002, ups: 0.56, time: 02m 57s 932ms, time_since_start: 06h 17m 25s 593ms, eta: 03h 29m 14s 904ms
2023-04-25T10:25:58 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T10:25:58 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T10:25:58 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T10:26:06 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T10:26:06 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T10:26:07 | INFO | mmf.trainers.callbacks.logistics : progress: 15000/22000, val/hateful_memes/cross_entropy: 3.4831, val/total_loss: 3.4831, val/hateful_memes/accuracy: 0.5840, val/hateful_memes/binary_f1: 0.4555, val/hateful_memes/roc_auc: 0.6221, num_updates: 15000, epoch: 113, iterations: 15000, max_updates: 22000, val_time: 08s 644ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T10:28:33 | INFO | mmf.trainers.callbacks.logistics : progress: 15100/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0423, train/total_loss: 0.0003, train/total_loss/avg: 0.0423, max mem: 19034.0, experiment: run, epoch: 114, num_updates: 15100, iterations: 15100, max_updates: 22000, lr: 0.00002, ups: 0.68, time: 02m 26s 137ms, time_since_start: 06h 20m 378ms, eta: 02h 49m 24s 182ms
2023-04-25T10:30:58 | INFO | mmf.trainers.callbacks.logistics : progress: 15200/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0420, train/total_loss: 0.0003, train/total_loss/avg: 0.0420, max mem: 19034.0, experiment: run, epoch: 115, num_updates: 15200, iterations: 15200, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 266ms, time_since_start: 06h 22m 25s 645ms, eta: 02h 45m 57s 166ms
2023-04-25T10:33:23 | INFO | mmf.trainers.callbacks.logistics : progress: 15300/22000, train/hateful_memes/cross_entropy: 0.0003, train/hateful_memes/cross_entropy/avg: 0.0417, train/total_loss: 0.0003, train/total_loss/avg: 0.0417, max mem: 19034.0, experiment: run, epoch: 116, num_updates: 15300, iterations: 15300, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 488ms, time_since_start: 06h 24m 51s 133ms, eta: 02h 43m 45s 699ms
2023-04-25T10:35:49 | INFO | mmf.trainers.callbacks.logistics : progress: 15400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0415, train/total_loss: 0.0002, train/total_loss/avg: 0.0415, max mem: 19034.0, experiment: run, epoch: 116, num_updates: 15400, iterations: 15400, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 207ms, time_since_start: 06h 27m 16s 340ms, eta: 02h 41m 339ms
2023-04-25T10:38:15 | INFO | mmf.trainers.callbacks.logistics : progress: 15500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0412, train/total_loss: 0.0002, train/total_loss/avg: 0.0412, max mem: 19034.0, experiment: run, epoch: 117, num_updates: 15500, iterations: 15500, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 896ms, time_since_start: 06h 29m 42s 237ms, eta: 02h 39m 19s 159ms
2023-04-25T10:40:40 | INFO | mmf.trainers.callbacks.logistics : progress: 15600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0409, train/total_loss: 0.0002, train/total_loss/avg: 0.0409, max mem: 19034.0, experiment: run, epoch: 118, num_updates: 15600, iterations: 15600, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 704ms, time_since_start: 06h 32m 07s 941ms, eta: 02h 36m 39s 682ms
2023-04-25T10:43:05 | INFO | mmf.trainers.callbacks.logistics : progress: 15700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0407, train/total_loss: 0.0002, train/total_loss/avg: 0.0407, max mem: 19034.0, experiment: run, epoch: 119, num_updates: 15700, iterations: 15700, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 24s 674ms, time_since_start: 06h 34m 32s 615ms, eta: 02h 33m 07s 386ms
2023-04-25T10:45:31 | INFO | mmf.trainers.callbacks.logistics : progress: 15800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0404, train/total_loss: 0.0002, train/total_loss/avg: 0.0404, max mem: 19034.0, experiment: run, epoch: 119, num_updates: 15800, iterations: 15800, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 824ms, time_since_start: 06h 36m 58s 440ms, eta: 02h 31m 53s 452ms
2023-04-25T10:47:56 | INFO | mmf.trainers.callbacks.logistics : progress: 15900/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0402, train/total_loss: 0.0002, train/total_loss/avg: 0.0402, max mem: 19034.0, experiment: run, epoch: 120, num_updates: 15900, iterations: 15900, max_updates: 22000, lr: 0.00002, ups: 0.69, time: 02m 25s 433ms, time_since_start: 06h 39m 23s 873ms, eta: 02h 29m 02s 412ms
2023-04-25T10:50:21 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T10:50:21 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T10:50:48 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T10:50:54 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T10:50:54 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0399, train/total_loss: 0.0002, train/total_loss/avg: 0.0399, max mem: 19034.0, experiment: run, epoch: 121, num_updates: 16000, iterations: 16000, max_updates: 22000, lr: 0.00002, ups: 0.56, time: 02m 57s 430ms, time_since_start: 06h 42m 21s 304ms, eta: 02h 58m 50s 990ms
2023-04-25T10:50:54 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T10:50:54 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T10:50:54 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T10:51:02 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T10:51:02 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T10:51:02 | INFO | mmf.trainers.callbacks.logistics : progress: 16000/22000, val/hateful_memes/cross_entropy: 3.6962, val/total_loss: 3.6962, val/hateful_memes/accuracy: 0.5960, val/hateful_memes/binary_f1: 0.4451, val/hateful_memes/roc_auc: 0.6263, num_updates: 16000, epoch: 121, iterations: 16000, max_updates: 22000, val_time: 08s 443ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T10:53:29 | INFO | mmf.trainers.callbacks.logistics : progress: 16100/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0397, train/total_loss: 0.0002, train/total_loss/avg: 0.0397, max mem: 19034.0, experiment: run, epoch: 122, num_updates: 16100, iterations: 16100, max_updates: 22000, lr: 0.00001, ups: 0.68, time: 02m 26s 534ms, time_since_start: 06h 44m 56s 283ms, eta: 02h 25m 14s 696ms
2023-04-25T10:55:54 | INFO | mmf.trainers.callbacks.logistics : progress: 16200/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0394, train/total_loss: 0.0002, train/total_loss/avg: 0.0394, max mem: 19034.0, experiment: run, epoch: 122, num_updates: 16200, iterations: 16200, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 379ms, time_since_start: 06h 47m 21s 663ms, eta: 02h 21m 39s 441ms
2023-04-25T10:58:19 | INFO | mmf.trainers.callbacks.logistics : progress: 16300/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0392, train/total_loss: 0.0002, train/total_loss/avg: 0.0392, max mem: 19034.0, experiment: run, epoch: 123, num_updates: 16300, iterations: 16300, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 499ms, time_since_start: 06h 49m 47s 162ms, eta: 02h 19m 19s 828ms
2023-04-25T11:00:45 | INFO | mmf.trainers.callbacks.logistics : progress: 16400/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0390, train/total_loss: 0.0002, train/total_loss/avg: 0.0390, max mem: 19034.0, experiment: run, epoch: 124, num_updates: 16400, iterations: 16400, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 475ms, time_since_start: 06h 52m 12s 638ms, eta: 02h 16m 51s 793ms
2023-04-25T11:03:11 | INFO | mmf.trainers.callbacks.logistics : progress: 16500/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0387, train/total_loss: 0.0002, train/total_loss/avg: 0.0387, max mem: 19034.0, experiment: run, epoch: 125, num_updates: 16500, iterations: 16500, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 631ms, time_since_start: 06h 54m 38s 269ms, eta: 02h 14m 33s 796ms
2023-04-25T11:05:36 | INFO | mmf.trainers.callbacks.logistics : progress: 16600/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0385, train/total_loss: 0.0002, train/total_loss/avg: 0.0385, max mem: 19034.0, experiment: run, epoch: 125, num_updates: 16600, iterations: 16600, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 643ms, time_since_start: 06h 57m 03s 912ms, eta: 02h 12m 07s 675ms
2023-04-25T11:08:02 | INFO | mmf.trainers.callbacks.logistics : progress: 16700/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0383, train/total_loss: 0.0002, train/total_loss/avg: 0.0383, max mem: 19034.0, experiment: run, epoch: 126, num_updates: 16700, iterations: 16700, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 588ms, time_since_start: 06h 59m 29s 501ms, eta: 02h 09m 37s 899ms
2023-04-25T11:10:27 | INFO | mmf.trainers.callbacks.logistics : progress: 16800/22000, train/hateful_memes/cross_entropy: 0.0002, train/hateful_memes/cross_entropy/avg: 0.0380, train/total_loss: 0.0002, train/total_loss/avg: 0.0380, max mem: 19034.0, experiment: run, epoch: 127, num_updates: 16800, iterations: 16800, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 029ms, time_since_start: 07h 01m 54s 530ms, eta: 02h 06m 41s 868ms
2023-04-25T11:12:52 | INFO | mmf.trainers.callbacks.logistics : progress: 16900/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0378, train/total_loss: 0.0001, train/total_loss/avg: 0.0378, max mem: 19034.0, experiment: run, epoch: 128, num_updates: 16900, iterations: 16900, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 519ms, time_since_start: 07h 04m 20s 049ms, eta: 02h 04m 40s 847ms
2023-04-25T11:15:18 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T11:15:18 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T11:15:39 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T11:15:47 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T11:15:47 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0376, train/total_loss: 0.0001, train/total_loss/avg: 0.0376, max mem: 19034.0, experiment: run, epoch: 128, num_updates: 17000, iterations: 17000, max_updates: 22000, lr: 0.00001, ups: 0.57, time: 02m 54s 822ms, time_since_start: 07h 07m 14s 872ms, eta: 02h 26m 51s 066ms
2023-04-25T11:15:47 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T11:15:47 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T11:15:47 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T11:15:56 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T11:15:56 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T11:15:56 | INFO | mmf.trainers.callbacks.logistics : progress: 17000/22000, val/hateful_memes/cross_entropy: 3.7080, val/total_loss: 3.7080, val/hateful_memes/accuracy: 0.6020, val/hateful_memes/binary_f1: 0.4749, val/hateful_memes/roc_auc: 0.6257, num_updates: 17000, epoch: 128, iterations: 17000, max_updates: 22000, val_time: 08s 668ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T11:18:22 | INFO | mmf.trainers.callbacks.logistics : progress: 17100/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0374, train/total_loss: 0.0001, train/total_loss/avg: 0.0374, max mem: 19034.0, experiment: run, epoch: 129, num_updates: 17100, iterations: 17100, max_updates: 22000, lr: 0.00001, ups: 0.68, time: 02m 26s 195ms, time_since_start: 07h 09m 49s 738ms, eta: 02h 20s 872ms
2023-04-25T11:20:48 | INFO | mmf.trainers.callbacks.logistics : progress: 17200/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0372, train/total_loss: 0.0001, train/total_loss/avg: 0.0372, max mem: 19034.0, experiment: run, epoch: 130, num_updates: 17200, iterations: 17200, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 954ms, time_since_start: 07h 12m 15s 692ms, eta: 01h 57m 41s 847ms
2023-04-25T11:23:14 | INFO | mmf.trainers.callbacks.logistics : progress: 17300/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0369, train/total_loss: 0.0001, train/total_loss/avg: 0.0369, max mem: 19034.0, experiment: run, epoch: 131, num_updates: 17300, iterations: 17300, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 760ms, time_since_start: 07h 14m 41s 453ms, eta: 01h 55m 05s 563ms
2023-04-25T11:25:39 | INFO | mmf.trainers.callbacks.logistics : progress: 17400/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0367, train/total_loss: 0.0001, train/total_loss/avg: 0.0367, max mem: 19034.0, experiment: run, epoch: 131, num_updates: 17400, iterations: 17400, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 855ms, time_since_start: 07h 17m 06s 309ms, eta: 01h 51m 56s 674ms
2023-04-25T11:28:04 | INFO | mmf.trainers.callbacks.logistics : progress: 17500/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0365, train/total_loss: 0.0001, train/total_loss/avg: 0.0365, max mem: 19034.0, experiment: run, epoch: 132, num_updates: 17500, iterations: 17500, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 840ms, time_since_start: 07h 19m 32s 150ms, eta: 01h 50m 15s 347ms
2023-04-25T11:30:30 | INFO | mmf.trainers.callbacks.logistics : progress: 17600/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0363, train/total_loss: 0.0001, train/total_loss/avg: 0.0363, max mem: 19034.0, experiment: run, epoch: 133, num_updates: 17600, iterations: 17600, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 831ms, time_since_start: 07h 21m 57s 981ms, eta: 01h 47m 47s 925ms
2023-04-25T11:32:56 | INFO | mmf.trainers.callbacks.logistics : progress: 17700/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0361, train/total_loss: 0.0001, train/total_loss/avg: 0.0361, max mem: 19034.0, experiment: run, epoch: 134, num_updates: 17700, iterations: 17700, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 306ms, time_since_start: 07h 24m 23s 288ms, eta: 01h 44m 58s 160ms
2023-04-25T11:35:21 | INFO | mmf.trainers.callbacks.logistics : progress: 17800/22000, train/hateful_memes/cross_entropy: 0.0001, train/hateful_memes/cross_entropy/avg: 0.0359, train/total_loss: 0.0001, train/total_loss/avg: 0.0359, max mem: 19034.0, experiment: run, epoch: 134, num_updates: 17800, iterations: 17800, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 346ms, time_since_start: 07h 26m 48s 634ms, eta: 01h 42m 33s 379ms
2023-04-25T11:37:46 | INFO | mmf.trainers.callbacks.logistics : progress: 17900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0357, train/total_loss: 0.0000, train/total_loss/avg: 0.0357, max mem: 19034.0, experiment: run, epoch: 135, num_updates: 17900, iterations: 17900, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 553ms, time_since_start: 07h 29m 13s 188ms, eta: 01h 39m 34s 121ms
2023-04-25T11:40:11 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T11:40:11 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T11:40:49 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T11:40:56 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T11:40:56 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0355, train/total_loss: 0.0000, train/total_loss/avg: 0.0355, max mem: 19034.0, experiment: run, epoch: 136, num_updates: 18000, iterations: 18000, max_updates: 22000, lr: 0.00001, ups: 0.53, time: 03m 10s 407ms, time_since_start: 07h 32m 23s 595ms, eta: 02h 07m 57s 231ms
2023-04-25T11:40:56 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T11:40:56 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T11:40:56 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T11:41:04 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T11:41:04 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T11:41:04 | INFO | mmf.trainers.callbacks.logistics : progress: 18000/22000, val/hateful_memes/cross_entropy: 3.9573, val/total_loss: 3.9573, val/hateful_memes/accuracy: 0.5820, val/hateful_memes/binary_f1: 0.4456, val/hateful_memes/roc_auc: 0.6099, num_updates: 18000, epoch: 136, iterations: 18000, max_updates: 22000, val_time: 08s 449ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T11:43:31 | INFO | mmf.trainers.callbacks.logistics : progress: 18100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0353, train/total_loss: 0.0000, train/total_loss/avg: 0.0353, max mem: 19034.0, experiment: run, epoch: 137, num_updates: 18100, iterations: 18100, max_updates: 22000, lr: 0.00001, ups: 0.68, time: 02m 26s 309ms, time_since_start: 07h 34m 58s 357ms, eta: 01h 35m 51s 737ms
2023-04-25T11:45:57 | INFO | mmf.trainers.callbacks.logistics : progress: 18200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0351, train/total_loss: 0.0000, train/total_loss/avg: 0.0351, max mem: 19034.0, experiment: run, epoch: 137, num_updates: 18200, iterations: 18200, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 815ms, time_since_start: 07h 37m 24s 172ms, eta: 01h 33m 05s 309ms
2023-04-25T11:48:22 | INFO | mmf.trainers.callbacks.logistics : progress: 18300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0349, train/total_loss: 0.0000, train/total_loss/avg: 0.0349, max mem: 19034.0, experiment: run, epoch: 138, num_updates: 18300, iterations: 18300, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 132ms, time_since_start: 07h 39m 49s 304ms, eta: 01h 30m 12s 847ms
2023-04-25T11:50:47 | INFO | mmf.trainers.callbacks.logistics : progress: 18400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0347, train/total_loss: 0.0000, train/total_loss/avg: 0.0347, max mem: 19034.0, experiment: run, epoch: 139, num_updates: 18400, iterations: 18400, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 198ms, time_since_start: 07h 42m 14s 503ms, eta: 01h 27m 48s 966ms
2023-04-25T11:53:12 | INFO | mmf.trainers.callbacks.logistics : progress: 18500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0345, train/total_loss: 0.0000, train/total_loss/avg: 0.0345, max mem: 19034.0, experiment: run, epoch: 140, num_updates: 18500, iterations: 18500, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 489ms, time_since_start: 07h 44m 39s 993ms, eta: 01h 25m 32s 884ms
2023-04-25T11:55:38 | INFO | mmf.trainers.callbacks.logistics : progress: 18600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0344, train/total_loss: 0.0000, train/total_loss/avg: 0.0344, max mem: 19034.0, experiment: run, epoch: 140, num_updates: 18600, iterations: 18600, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 488ms, time_since_start: 07h 47m 05s 481ms, eta: 01h 23m 06s 171ms
2023-04-25T11:58:04 | INFO | mmf.trainers.callbacks.logistics : progress: 18700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0342, train/total_loss: 0.0000, train/total_loss/avg: 0.0342, max mem: 19034.0, experiment: run, epoch: 141, num_updates: 18700, iterations: 18700, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 823ms, time_since_start: 07h 49m 31s 304ms, eta: 01h 20m 50s 663ms
2023-04-25T12:00:28 | INFO | mmf.trainers.callbacks.logistics : progress: 18800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0340, train/total_loss: 0.0000, train/total_loss/avg: 0.0340, max mem: 19034.0, experiment: run, epoch: 142, num_updates: 18800, iterations: 18800, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 824ms, time_since_start: 07h 51m 56s 129ms, eta: 01h 17m 51s 461ms
2023-04-25T12:02:54 | INFO | mmf.trainers.callbacks.logistics : progress: 18900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0338, train/total_loss: 0.0000, train/total_loss/avg: 0.0338, max mem: 19034.0, experiment: run, epoch: 143, num_updates: 18900, iterations: 18900, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 565ms, time_since_start: 07h 54m 21s 695ms, eta: 01h 15m 48s 640ms
2023-04-25T12:05:20 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T12:05:20 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T12:05:44 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T12:05:52 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T12:05:52 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0336, train/total_loss: 0.0000, train/total_loss/avg: 0.0336, max mem: 19034.0, experiment: run, epoch: 143, num_updates: 19000, iterations: 19000, max_updates: 22000, lr: 0.00001, ups: 0.56, time: 02m 58s 105ms, time_since_start: 07h 57m 19s 801ms, eta: 01h 29m 45s 925ms
2023-04-25T12:05:52 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T12:05:52 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T12:05:52 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T12:06:01 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T12:06:01 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T12:06:01 | INFO | mmf.trainers.callbacks.logistics : progress: 19000/22000, val/hateful_memes/cross_entropy: 3.8307, val/total_loss: 3.8307, val/hateful_memes/accuracy: 0.5920, val/hateful_memes/binary_f1: 0.4660, val/hateful_memes/roc_auc: 0.6314, num_updates: 19000, epoch: 143, iterations: 19000, max_updates: 22000, val_time: 09s 106ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T12:08:27 | INFO | mmf.trainers.callbacks.logistics : progress: 19100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0335, train/total_loss: 0.0000, train/total_loss/avg: 0.0335, max mem: 19034.0, experiment: run, epoch: 144, num_updates: 19100, iterations: 19100, max_updates: 22000, lr: 0.00001, ups: 0.68, time: 02m 26s 064ms, time_since_start: 07h 59m 54s 974ms, eta: 01h 11m 09s 762ms
2023-04-25T12:10:53 | INFO | mmf.trainers.callbacks.logistics : progress: 19200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0333, train/total_loss: 0.0000, train/total_loss/avg: 0.0333, max mem: 19034.0, experiment: run, epoch: 145, num_updates: 19200, iterations: 19200, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 260ms, time_since_start: 08h 02m 20s 234ms, eta: 01h 08m 19s 839ms
2023-04-25T12:13:18 | INFO | mmf.trainers.callbacks.logistics : progress: 19300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0331, train/total_loss: 0.0000, train/total_loss/avg: 0.0331, max mem: 19034.0, experiment: run, epoch: 146, num_updates: 19300, iterations: 19300, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 424ms, time_since_start: 08h 04m 45s 659ms, eta: 01h 05m 57s 885ms
2023-04-25T12:15:44 | INFO | mmf.trainers.callbacks.logistics : progress: 19400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0329, train/total_loss: 0.0000, train/total_loss/avg: 0.0329, max mem: 19034.0, experiment: run, epoch: 146, num_updates: 19400, iterations: 19400, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 765ms, time_since_start: 08h 07m 11s 425ms, eta: 01h 03m 40s 228ms
2023-04-25T12:18:09 | INFO | mmf.trainers.callbacks.logistics : progress: 19500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0328, train/total_loss: 0.0000, train/total_loss/avg: 0.0328, max mem: 19034.0, experiment: run, epoch: 147, num_updates: 19500, iterations: 19500, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 670ms, time_since_start: 08h 09m 37s 095ms, eta: 01h 01m 10s 891ms
2023-04-25T12:20:34 | INFO | mmf.trainers.callbacks.logistics : progress: 19600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0326, train/total_loss: 0.0000, train/total_loss/avg: 0.0326, max mem: 19034.0, experiment: run, epoch: 148, num_updates: 19600, iterations: 19600, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 979ms, time_since_start: 08h 12m 02s 075ms, eta: 58m 27s 348ms
2023-04-25T12:23:00 | INFO | mmf.trainers.callbacks.logistics : progress: 19700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0324, train/total_loss: 0.0000, train/total_loss/avg: 0.0324, max mem: 19034.0, experiment: run, epoch: 149, num_updates: 19700, iterations: 19700, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 154ms, time_since_start: 08h 14m 27s 229ms, eta: 56m 05s 252ms
2023-04-25T12:25:25 | INFO | mmf.trainers.callbacks.logistics : progress: 19800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0323, train/total_loss: 0.0000, train/total_loss/avg: 0.0323, max mem: 19034.0, experiment: run, epoch: 149, num_updates: 19800, iterations: 19800, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 25s 693ms, time_since_start: 08h 16m 52s 923ms, eta: 53m 50s 906ms
2023-04-25T12:27:50 | INFO | mmf.trainers.callbacks.logistics : progress: 19900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0321, train/total_loss: 0.0000, train/total_loss/avg: 0.0321, max mem: 19034.0, experiment: run, epoch: 150, num_updates: 19900, iterations: 19900, max_updates: 22000, lr: 0.00001, ups: 0.69, time: 02m 24s 749ms, time_since_start: 08h 19m 17s 673ms, eta: 51m 04s 065ms
2023-04-25T12:30:16 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T12:30:16 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T12:30:39 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T12:30:46 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T12:30:46 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0320, train/total_loss: 0.0000, train/total_loss/avg: 0.0320, max mem: 19034.0, experiment: run, epoch: 151, num_updates: 20000, iterations: 20000, max_updates: 22000, lr: 0.00001, ups: 0.57, time: 02m 55s 970ms, time_since_start: 08h 22m 13s 644ms, eta: 59m 07s 573ms
2023-04-25T12:30:46 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T12:30:46 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T12:30:46 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T12:30:55 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T12:30:55 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T12:30:55 | INFO | mmf.trainers.callbacks.logistics : progress: 20000/22000, val/hateful_memes/cross_entropy: 3.9467, val/total_loss: 3.9467, val/hateful_memes/accuracy: 0.5720, val/hateful_memes/binary_f1: 0.4022, val/hateful_memes/roc_auc: 0.6251, num_updates: 20000, epoch: 151, iterations: 20000, max_updates: 22000, val_time: 08s 812ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T12:33:22 | INFO | mmf.trainers.callbacks.logistics : progress: 20100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0318, train/total_loss: 0.0000, train/total_loss/avg: 0.0318, max mem: 19034.0, experiment: run, epoch: 152, num_updates: 20100, iterations: 20100, max_updates: 22000, lr: 0., ups: 0.68, time: 02m 27s 073ms, time_since_start: 08h 24m 49s 532ms, eta: 46m 56s 751ms
2023-04-25T12:35:47 | INFO | mmf.trainers.callbacks.logistics : progress: 20200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0316, train/total_loss: 0.0000, train/total_loss/avg: 0.0316, max mem: 19034.0, experiment: run, epoch: 152, num_updates: 20200, iterations: 20200, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 110ms, time_since_start: 08h 27m 14s 643ms, eta: 43m 52s 892ms
2023-04-25T12:38:12 | INFO | mmf.trainers.callbacks.logistics : progress: 20300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0315, train/total_loss: 0.0000, train/total_loss/avg: 0.0315, max mem: 19034.0, experiment: run, epoch: 153, num_updates: 20300, iterations: 20300, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 338ms, time_since_start: 08h 29m 39s 981ms, eta: 41m 30s 517ms
2023-04-25T12:40:37 | INFO | mmf.trainers.callbacks.logistics : progress: 20400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0313, train/total_loss: 0.0000, train/total_loss/avg: 0.0313, max mem: 19034.0, experiment: run, epoch: 154, num_updates: 20400, iterations: 20400, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 24s 718ms, time_since_start: 08h 32m 04s 700ms, eta: 38m 54s 020ms
2023-04-25T12:43:02 | INFO | mmf.trainers.callbacks.logistics : progress: 20500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0312, train/total_loss: 0.0000, train/total_loss/avg: 0.0312, max mem: 19034.0, experiment: run, epoch: 155, num_updates: 20500, iterations: 20500, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 24s 920ms, time_since_start: 08h 34m 29s 620ms, eta: 36m 31s 192ms
2023-04-25T12:45:28 | INFO | mmf.trainers.callbacks.logistics : progress: 20600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0310, train/total_loss: 0.0000, train/total_loss/avg: 0.0310, max mem: 19034.0, experiment: run, epoch: 155, num_updates: 20600, iterations: 20600, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 708ms, time_since_start: 08h 36m 55s 328ms, eta: 34m 16s 241ms
2023-04-25T12:47:53 | INFO | mmf.trainers.callbacks.logistics : progress: 20700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0309, train/total_loss: 0.0000, train/total_loss/avg: 0.0309, max mem: 19034.0, experiment: run, epoch: 156, num_updates: 20700, iterations: 20700, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 207ms, time_since_start: 08h 39m 20s 536ms, eta: 31m 42s 795ms
2023-04-25T12:50:18 | INFO | mmf.trainers.callbacks.logistics : progress: 20800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0307, train/total_loss: 0.0000, train/total_loss/avg: 0.0307, max mem: 19034.0, experiment: run, epoch: 157, num_updates: 20800, iterations: 20800, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 24s 979ms, time_since_start: 08h 41m 45s 515ms, eta: 29m 13s 666ms
2023-04-25T12:52:43 | INFO | mmf.trainers.callbacks.logistics : progress: 20900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0306, train/total_loss: 0.0000, train/total_loss/avg: 0.0306, max mem: 19034.0, experiment: run, epoch: 158, num_updates: 20900, iterations: 20900, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 24s 855ms, time_since_start: 08h 44m 10s 370ms, eta: 26m 46s 161ms
2023-04-25T12:55:08 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T12:55:08 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T12:55:35 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T12:55:41 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T12:55:41 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0304, train/total_loss: 0.0000, train/total_loss/avg: 0.0304, max mem: 19034.0, experiment: run, epoch: 158, num_updates: 21000, iterations: 21000, max_updates: 22000, lr: 0., ups: 0.56, time: 02m 57s 815ms, time_since_start: 08h 47m 08s 186ms, eta: 29m 52s 377ms
2023-04-25T12:55:41 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T12:55:41 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T12:55:41 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T12:55:49 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T12:55:49 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T12:55:49 | INFO | mmf.trainers.callbacks.logistics : progress: 21000/22000, val/hateful_memes/cross_entropy: 3.7883, val/total_loss: 3.7883, val/hateful_memes/accuracy: 0.5860, val/hateful_memes/binary_f1: 0.4450, val/hateful_memes/roc_auc: 0.6314, num_updates: 21000, epoch: 158, iterations: 21000, max_updates: 22000, val_time: 08s 318ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T12:58:16 | INFO | mmf.trainers.callbacks.logistics : progress: 21100/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0303, train/total_loss: 0.0000, train/total_loss/avg: 0.0303, max mem: 19034.0, experiment: run, epoch: 159, num_updates: 21100, iterations: 21100, max_updates: 22000, lr: 0., ups: 0.68, time: 02m 27s 052ms, time_since_start: 08h 49m 43s 559ms, eta: 22m 14s 062ms
2023-04-25T13:00:41 | INFO | mmf.trainers.callbacks.logistics : progress: 21200/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0302, train/total_loss: 0.0000, train/total_loss/avg: 0.0302, max mem: 19034.0, experiment: run, epoch: 160, num_updates: 21200, iterations: 21200, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 149ms, time_since_start: 08h 52m 08s 709ms, eta: 19m 30s 483ms
2023-04-25T13:03:05 | INFO | mmf.trainers.callbacks.logistics : progress: 21300/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0300, train/total_loss: 0.0000, train/total_loss/avg: 0.0300, max mem: 19034.0, experiment: run, epoch: 161, num_updates: 21300, iterations: 21300, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 24s 284ms, time_since_start: 08h 54m 32s 993ms, eta: 16m 58s 068ms
2023-04-25T13:05:31 | INFO | mmf.trainers.callbacks.logistics : progress: 21400/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0299, train/total_loss: 0.0000, train/total_loss/avg: 0.0299, max mem: 19034.0, experiment: run, epoch: 161, num_updates: 21400, iterations: 21400, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 499ms, time_since_start: 08h 56m 58s 492ms, eta: 14m 39s 980ms
2023-04-25T13:07:55 | INFO | mmf.trainers.callbacks.logistics : progress: 21500/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0297, train/total_loss: 0.0000, train/total_loss/avg: 0.0297, max mem: 19034.0, experiment: run, epoch: 162, num_updates: 21500, iterations: 21500, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 24s 569ms, time_since_start: 08h 59m 23s 061ms, eta: 12m 08s 628ms
2023-04-25T13:10:20 | INFO | mmf.trainers.callbacks.logistics : progress: 21600/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0296, train/total_loss: 0.0000, train/total_loss/avg: 0.0296, max mem: 19034.0, experiment: run, epoch: 163, num_updates: 21600, iterations: 21600, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 078ms, time_since_start: 09h 01m 48s 140ms, eta: 09m 44s 957ms
2023-04-25T13:12:46 | INFO | mmf.trainers.callbacks.logistics : progress: 21700/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0295, train/total_loss: 0.0000, train/total_loss/avg: 0.0295, max mem: 19034.0, experiment: run, epoch: 164, num_updates: 21700, iterations: 21700, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 466ms, time_since_start: 09h 04m 13s 606ms, eta: 07m 19s 889ms
2023-04-25T13:15:11 | INFO | mmf.trainers.callbacks.logistics : progress: 21800/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0293, train/total_loss: 0.0000, train/total_loss/avg: 0.0293, max mem: 19034.0, experiment: run, epoch: 164, num_updates: 21800, iterations: 21800, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 24s 793ms, time_since_start: 09h 06m 38s 400ms, eta: 04m 51s 904ms
2023-04-25T13:17:36 | INFO | mmf.trainers.callbacks.logistics : progress: 21900/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0292, train/total_loss: 0.0000, train/total_loss/avg: 0.0292, max mem: 19034.0, experiment: run, epoch: 165, num_updates: 21900, iterations: 21900, max_updates: 22000, lr: 0., ups: 0.69, time: 02m 25s 033ms, time_since_start: 09h 09m 03s 434ms, eta: 02m 26s 193ms
2023-04-25T13:20:00 | INFO | mmf.trainers.callbacks.checkpoint : Checkpoint time. Saving a checkpoint.
2023-04-25T13:20:00 | INFO | mmf.utils.checkpoint : Checkpoint save operation started!
2023-04-25T13:20:34 | INFO | mmf.utils.checkpoint : Saving current checkpoint
2023-04-25T13:20:40 | INFO | mmf.utils.checkpoint : Checkpoint save operation finished!
2023-04-25T13:20:40 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, train/hateful_memes/cross_entropy: 0.0000, train/hateful_memes/cross_entropy/avg: 0.0291, train/total_loss: 0.0000, train/total_loss/avg: 0.0291, max mem: 19034.0, experiment: run, epoch: 166, num_updates: 22000, iterations: 22000, max_updates: 22000, lr: 0., ups: 0.54, time: 03m 04s 379ms, time_since_start: 09h 12m 07s 813ms, eta: 0ms
2023-04-25T13:20:40 | INFO | mmf.trainers.core.training_loop : Evaluation time. Running on full validation set...
2023-04-25T13:20:40 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T13:20:40 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T13:20:49 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T13:20:49 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T13:20:49 | INFO | mmf.trainers.callbacks.logistics : progress: 22000/22000, val/hateful_memes/cross_entropy: 3.8710, val/total_loss: 3.8710, val/hateful_memes/accuracy: 0.5800, val/hateful_memes/binary_f1: 0.4355, val/hateful_memes/roc_auc: 0.6308, num_updates: 22000, epoch: 166, iterations: 22000, max_updates: 22000, val_time: 08s 473ms, best_update: 3000, best_iteration: 3000, best_val/hateful_memes/roc_auc: 0.650998
2023-04-25T13:20:49 | INFO | mmf.trainers.core.training_loop : Stepping into final validation check
2023-04-25T13:20:49 | INFO | mmf.utils.checkpoint : Restoring checkpoint
2023-04-25T13:20:49 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-25T13:20:52 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-25T13:20:52 | INFO | mmf.utils.checkpoint : Current num updates: 3000
2023-04-25T13:20:52 | INFO | mmf.utils.checkpoint : Current iteration: 3000
2023-04-25T13:20:52 | INFO | mmf.utils.checkpoint : Current epoch: 23
2023-04-25T13:21:05 | INFO | mmf.trainers.mmf_trainer : Starting inference on val set
2023-04-25T13:21:05 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T13:21:05 | WARNING | mmf.utils.build : persistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False
2023-04-25T13:21:13 | INFO | mmf.trainers.core.evaluation_loop : Finished evaluation inference. Loaded 8
2023-04-25T13:21:13 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T13:21:13 | INFO | mmf.trainers.callbacks.logistics : progress: 3000/22000, val/hateful_memes/cross_entropy: 2.2826, val/total_loss: 2.2826, val/hateful_memes/accuracy: 0.5860, val/hateful_memes/binary_f1: 0.4298, val/hateful_memes/roc_auc: 0.6510
2023-04-25T13:21:13 | INFO | mmf.trainers.callbacks.logistics : Finished run in 09h 12m 40s 679ms
2023-04-25T13:21:23 | INFO | mmf : Logging to: ./save/train.log
2023-04-25T13:21:23 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.max_to_keep=1', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'dataset_config.hateful_memes.features.train[0]=/content/gdrive/MyDrive/vmb_x_152_detectron_100/', 'dataset_config.hateful_memes.features.val[0]=/content/gdrive/MyDrive/vmb_x_152_detectron_100/', 'dataset_config.hateful_memes.features.test[0]=/content/gdrive/MyDrive/vmb_x_152_detectron_100/', 'evaluation.predict=true'])
2023-04-25T13:21:23 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-25T13:21:23 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-25T13:21:23 | INFO | mmf_cli.run : Using seed 24164116
2023-04-25T13:21:23 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-25T13:21:25 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T13:21:25 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T13:21:25 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T13:21:25 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-25T13:21:25 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpl6blikp4
2023-04-25T13:21:25 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmpl6blikp4/_remote_module_non_scriptable.py
2023-04-25T13:21:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T13:21:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T13:21:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T13:21:25 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T13:21:32 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-25T13:21:32 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-25T13:21:32 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-25T13:21:33 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-25T13:21:33 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-25T13:21:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T13:21:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T13:21:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T13:21:34 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T13:21:34 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-25T13:21:34 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-25T13:21:34 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-25T13:21:34 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-25T13:21:34 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-25T13:21:34 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T13:21:40 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_24164116/reports/hateful_memes_run_test_2023-04-25T13:21:40.csv
2023-04-25T13:21:40 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 16
2023-04-25T13:21:40 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
2023-04-25T14:13:42 | INFO | mmf : Logging to: ./save/train.log
2023-04-25T14:13:42 | INFO | mmf_cli.run : Namespace(config_override=None, local_rank=None, opts=['config=configs/experiments/concat_bert_ex/defaults.yaml', 'model=concat_bert_ex', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.max_to_keep=1', 'env.user_dir=/content/gdrive/MyDrive/hm/HatefulMemes', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/dev.jsonl', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev.jsonl', 'checkpoint.resume_file=/content/gdrive/MyDrive/hm/HatefulMemes/save/concat_bert_ex_final.pth', 'checkpoint.resume_pretrained=False', 'dataset_config.hateful_memes.features.train[0]=', 'dataset_config.hateful_memes.features.val[0]=', 'dataset_config.hateful_memes.features.test[0]=', 'evaluation.predict=true'])
2023-04-25T14:13:42 | INFO | mmf_cli.run : Torch version: 2.0.0+cu118
2023-04-25T14:13:42 | INFO | mmf.utils.general : CUDA Device 0 is: NVIDIA A100-SXM4-40GB
2023-04-25T14:13:42 | INFO | mmf_cli.run : Using seed 41947977
2023-04-25T14:13:42 | INFO | mmf.trainers.mmf_trainer : Loading datasets
2023-04-25T14:13:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T14:13:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T14:13:44 | INFO | mmf.datasets.multi_datamodule : Multitasking disabled by default for single dataset training
2023-04-25T14:13:44 | INFO | mmf.trainers.mmf_trainer : Loading model
2023-04-25T14:13:44 | INFO | torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmppavbl9b2
2023-04-25T14:13:44 | INFO | torch.distributed.nn.jit.instantiator : Writing /tmp/tmppavbl9b2/_remote_module_non_scriptable.py
2023-04-25T14:13:44 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T14:13:44 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(

2023-04-25T14:13:44 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T14:13:44 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)

2023-04-25T14:14:04 | INFO | mmf.trainers.mmf_trainer : Loading optimizer
2023-04-25T14:14:04 | INFO | mmf.trainers.mmf_trainer : Loading metrics
2023-04-25T14:14:04 | INFO | mmf.utils.checkpoint : Loading checkpoint
2023-04-25T14:14:08 | WARNING | mmf : Key data_parallel is not present in registry, returning default value of None
2023-04-25T14:14:08 | WARNING | mmf : Key distributed is not present in registry, returning default value of None
2023-04-25T14:14:08 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T14:14:08 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:344: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.
  warnings.warn(

2023-04-25T14:14:08 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T14:14:08 | WARNING | py.warnings : /usr/local/lib/python3.9/dist-packages/mmf/utils/checkpoint.py:393: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.
  warnings.warn(

2023-04-25T14:14:08 | INFO | mmf.utils.checkpoint : Checkpoint loaded.
2023-04-25T14:14:08 | INFO | mmf.utils.checkpoint : Current num updates: 0
2023-04-25T14:14:08 | INFO | mmf.utils.checkpoint : Current iteration: 0
2023-04-25T14:14:08 | INFO | mmf.utils.checkpoint : Current epoch: 0
2023-04-25T14:14:08 | INFO | mmf.trainers.core.evaluation_loop : Starting test inference predictions
2023-04-25T14:14:08 | INFO | mmf.common.test_reporter : Predicting for hateful_memes
2023-04-25T14:14:21 | INFO | mmf.common.test_reporter : Wrote predictions for hateful_memes to /content/gdrive/MyDrive/hm/HatefulMemes/save/hateful_memes_concat_bert_ex_41947977/reports/hateful_memes_run_test_2023-04-25T14:14:21.csv
2023-04-25T14:14:21 | INFO | mmf.trainers.core.evaluation_loop : Finished predicting. Loaded 8
2023-04-25T14:14:21 | INFO | mmf.trainers.core.evaluation_loop :  -- skipped 0 batches.
